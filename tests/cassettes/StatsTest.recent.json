{
  "http_interactions": [
    {
      "recorded_at": "2016-06-19T20:27:58",
      "request": {
        "body": {
          "encoding": "utf-8",
          "string": "grant_type=password&password=<PASSWORD>&username=<USERNAME>"
        },
        "headers": {
          "Accept": "*/*",
          "Accept-Encoding": "identity",
          "Authorization": "Basic <BASIC_AUTH>",
          "Connection": "keep-alive",
          "Content-Length": "57",
          "Content-Type": "application/x-www-form-urlencoded",
          "User-Agent": "prawtools/0.19 PRAW/4.0.0b4 prawcore/0.0.8"
        },
        "method": "POST",
        "uri": "https://www.reddit.com/api/v1/access_token"
      },
      "response": {
        "body": {
          "encoding": "UTF-8",
          "string": "{\"access_token\": \"WlbqUCMDinklXWcXaK_r1K8vOus\", \"token_type\": \"bearer\", \"expires_in\": 3600, \"scope\": \"*\"}"
        },
        "headers": {
          "CF-RAY": "2b59b98501d42276-LAX",
          "Connection": "keep-alive",
          "Content-Length": "105",
          "Content-Type": "application/json; charset=UTF-8",
          "Date": "Sun, 19 Jun 2016 20:27:58 GMT",
          "Server": "cloudflare-nginx",
          "Set-Cookie": "__cfduid=d0e2852c5ce2df04394b838f8c8e095651466368077; expires=Mon, 19-Jun-17 20:27:57 GMT; path=/; domain=.reddit.com; HttpOnly",
          "Strict-Transport-Security": "max-age=15552000; includeSubDomains; preload",
          "X-Moose": "majestic",
          "cache-control": "max-age=0, must-revalidate",
          "x-content-type-options": "nosniff",
          "x-frame-options": "SAMEORIGIN",
          "x-xss-protection": "1; mode=block"
        },
        "status": {
          "code": 200,
          "message": "OK"
        },
        "url": "https://www.reddit.com/api/v1/access_token"
      }
    },
    {
      "recorded_at": "2016-06-19T20:27:59",
      "request": {
        "body": {
          "encoding": "utf-8",
          "string": ""
        },
        "headers": {
          "Accept": "*/*",
          "Accept-Encoding": "identity",
          "Authorization": "bearer WlbqUCMDinklXWcXaK_r1K8vOus",
          "Connection": "keep-alive",
          "Cookie": "loid=RGjIZeS49eKcGuXCXk; loidcreated=2016-06-19T20%3A27%3A57.632Z; __cfduid=d0e2852c5ce2df04394b838f8c8e095651466368077",
          "User-Agent": "prawtools/0.19 PRAW/4.0.0b4 prawcore/0.0.8"
        },
        "method": "GET",
        "uri": "https://oauth.reddit.com/r/redditdev/new?limit=1024&raw_json=1"
      },
      "response": {
        "body": {
          "encoding": "UTF-8",
          "string": "{\"kind\": \"Listing\", \"data\": {\"modhash\": null, \"children\": [{\"kind\": \"t3\", \"data\": {\"domain\": \"kbo.tw\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ov0vy\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Puipuibi\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": true, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": false, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ov0vy/\\u5feb\\u770b\\u9019\\u4f4d\\u56db\\u773c\\u4ed4\\u771f\\u7684\\u5f88\\u8b8a\\u614b\\u6ce8\\u610f\\u4ed6\\u5230\\u5e95\\u4e7e\\u4e86\\u4ec0\\u9ebc\\u597d\\u4e8b\\u9694\\u58c1\\u5973\\u5b50\\u7684\\u8868\\u60c5\\u597d\\u7121\\u5948\\u554a/\", \"locked\": false, \"name\": \"t3_4ov0vy\", \"created\": 1466396810.0, \"url\": \"http://kbo.tw/fI3U\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"\\u5feb\\u770b\\u3010\\u9019\\u4f4d\\u56db\\u773c\\u4ed4\\u771f\\u7684\\u5f88\\u8b8a\\u614b\\u3011\\u6ce8\\u610f\\u4ed6\\u5230\\u5e95\\u4e7e\\u4e86\\u4ec0\\u9ebc\\u597d\\u4e8b\\uff1f\\u9694\\u58c1\\u5973\\u5b50\\u7684\\u8868\\u60c5\\u597d\\u7121\\u5948\\u554a\\uff01\", \"created_utc\": 1466368010.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI was recently made aware of an interesting dynamic: subreddits which are blocked by a large number of users may find it easier to hit the front page, as their content is not seen by these users and is therefore not subject to their downvotes.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI thought about this issue and had a weird idea: what if someone were to create some kind of service (maybe a browser extension?) that would enable a user\\u0026#39;s \\u0026quot;don\\u0026#39;t show me submissions after I\\u0026#39;ve downvoted them\\u0026quot; setting and then auto-downvote any front-page posts from that subreddit, allowing the user to hide the subreddit while also registering their disapproval of that sub\\u0026#39;s content.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThis idea seems to exist in an ethically gray area, and I was curious if it was even allowed from the standpoint of Reddit\\u0026#39;s TOS. What do you guys think? Would this app be ethical, or even allowed at all?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I was recently made aware of an interesting dynamic: subreddits which are blocked by a large number of users may find it easier to hit the front page, as their content is not seen by these users and is therefore not subject to their downvotes.\\n\\nI thought about this issue and had a weird idea: what if someone were to create some kind of service (maybe a browser extension?) that would enable a user's \\\"don't show me submissions after I've downvoted them\\\" setting and then auto-downvote any front-page posts from that subreddit, allowing the user to hide the subreddit while also registering their disapproval of that sub's content.\\n\\nThis idea seems to exist in an ethically gray area, and I was curious if it was even allowed from the standpoint of Reddit's TOS. What do you guys think? Would this app be ethical, or even allowed at all?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ouzjt\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"tacobellscannon\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": true, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ouzjt/would_it_be_against_the_rules_andor_unethical_to/\", \"locked\": false, \"name\": \"t3_4ouzjt\", \"created\": 1466396311.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ouzjt/would_it_be_against_the_rules_andor_unethical_to/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Would it be against the rules and/or unethical to create a service that allows individual users to auto-downvote front page posts from subreddits of their choosing?\", \"created_utc\": 1466367511.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EGood afternoon,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EToday I would like to present the Sandstorm, since I met I realized that would be the future. Sandstorm is an open source operating system for personal and private clouds, easy to deploy and manage apps.\\nAnd I believe that with community efforts can easily launch the package.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESome interesting links:\\nLink to the Sanstorm -https site : //sandstorm.io/\\nLink to the Sandstorm Vagrant SPK documentation - \\u003Ca href=\\\"https://docs.sandstorm.io/en/latest/vagrant-spk/packaging-tutorial/\\\"\\u003Ehttps://docs.sandstorm.io/en/latest/vagrant-spk/packaging-tutorial/\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESome tasks need to be completed to function. As:\\n- Unique Login with Sandstorm ( \\u003Ca href=\\\"https://docs.sandstorm.io/en/latest/developing/auth/\\\"\\u003Ehttps://docs.sandstorm.io/en/latest/developing/auth/\\u003C/a\\u003E )\\nAnd some others that we can start to discussion here.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIn return Sandstorm offers Ossis which is the Sandstorm hosted on their server, we can use to center the community.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhat do you think about?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Good afternoon,\\n\\nToday I would like to present the Sandstorm, since I met I realized that would be the future. Sandstorm is an open source operating system for personal and private clouds, easy to deploy and manage apps.\\nAnd I believe that with community efforts can easily launch the package.\\n\\nSome interesting links:\\nLink to the Sanstorm -https site : //sandstorm.io/\\nLink to the Sandstorm Vagrant SPK documentation - https://docs.sandstorm.io/en/latest/vagrant-spk/packaging-tutorial/\\n\\nSome tasks need to be completed to function. As:\\n- Unique Login with Sandstorm ( https://docs.sandstorm.io/en/latest/developing/auth/ )\\nAnd some others that we can start to discussion here.\\n\\nIn return Sandstorm offers Ossis which is the Sandstorm hosted on their server, we can use to center the community.\\n\\nWhat do you think about?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oussd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"mv-matheusvieira\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": true, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oussd/sandstorm_vagrant_package/\", \"locked\": false, \"name\": \"t3_4oussd\", \"created\": 1466393841.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oussd/sandstorm_vagrant_package/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Sandstorm Vagrant Package\", \"created_utc\": 1466365041.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m working on a bot written in Java using JRAW and \\u003Ca href=\\\"https://github.com/janpetryk/reddit-bot\\\"\\u003Ethis TweetInCommentsBot\\u003C/a\\u003E code. Whenever I try to reply to a comment I get a RATELIMIT error back, while I\\u0026#39;m only sending 1 request. (I think)\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThese are the methods where I reply to comments:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E@Override\\n    public PostCommentResult replyToComment(String parentCommentFullName, String responseCommentBody) throws NetworkConnectionException, RedditApiException{\\n        try {\\n            RedditResponse response = redditClient.execute(redditClient.request()\\n                .endpoint(Endpoints.COMMENT)\\n                .post(JrawUtils.args(\\n                    \\u0026quot;api_type\\u0026quot;, \\u0026quot;json\\u0026quot;,\\n                    \\u0026quot;text\\u0026quot;, responseCommentBody,\\n                    \\u0026quot;thing_id\\u0026quot;, parentCommentFullName))\\n                .build());\\n            return processResponse(response);\\n        } catch (NetworkException e) {\\n            if (e.getCode() == 403) {\\n                return PostCommentResult.bannedFromThisSub();\\n            }\\n            throw new NetworkConnectionException(e);\\n        }\\n    }\\n\\n    private PostCommentResult processResponse(RedditResponse response) {\\n        if (response.hasErrors()) {\\n            String message = response.getErrors()[0].getMessage();\\n            if (message.contains(\\u0026quot;DELETED_COMMENT\\u0026quot;)) {\\n                return PostCommentResult.commentDeleted();\\n            } else {\\n                return PostCommentResult.unsuccessful(message);\\n            }\\n\\n        } else {\\n            return PostCommentResult.successful(response.getJson().get(\\u0026quot;json\\u0026quot;).get(\\u0026quot;data\\u0026quot;).get(\\u0026quot;things\\u0026quot;).get(0)\\n                .get(\\u0026quot;data\\u0026quot;).get(\\u0026quot;id\\u0026quot;).toString().substring(3));\\n        }\\n    }    \\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI run a task every 30 seconds to let the bot get new posts:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Etimer = new Timer();\\ntimer.schedule(new ExecuteBot(), 30000);\\nSystem.out.println(\\u0026quot;Start bot.\\u0026quot;);\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIn executebot I login using oAuth:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ERedditPost rp;\\n\\npublic ExecuteBot()\\n{\\n\\n}\\n\\n@Override\\npublic void run()\\n{\\n    if (rp == null)\\n    {\\n        rp = new RedditPost(\\u0026quot;desktop:beans.redditbean:v0.1 (by /u/HenkDeVries013)\\u0026quot;, \\u0026quot;user\\u0026quot;, \\u0026quot;hunter2\\u0026quot;, \\u0026quot;secret/id\\u0026quot;, \\u0026quot;secret/id\\u0026quot;);\\n    }\\n    rp.getStreamNameFromComment();\\n}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnd my RedditPost method to login:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E    @Inject\\n    public RedditPost(@Named(\\u0026quot;reddit-useragent\\u0026quot;) String userAgent,\\n        @Named(\\u0026quot;reddit-login\\u0026quot;) String login,\\n        @Named(\\u0026quot;reddit-password\\u0026quot;) String password,\\n        @Named(\\u0026quot;reddit-client-id\\u0026quot;) String clientId,\\n        @Named(\\u0026quot;reddit-client-secret\\u0026quot;) String clientSecret) {\\n        redditClient = new RedditClient(userAgent, 60);\\n        loginOAuth(login, password, clientId, clientSecret);\\n    }\\n\\n    void loginOAuth(String username, String password, String clientId, String clientSecret) {\\n        try {\\n            redditClient.login(Credentials.webapp(username, password, clientId, clientSecret));\\n        } catch (NetworkException ex) {\\n            Logger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n        } catch (ApiException ex) {\\n            Logger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n        }\\n\\n    }\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EWhere do I make the mistake? I have no clue why I get the RATELIMIT since in my understanding I can make up to 60 requests per minute and I\\u0026#39;m no where near that amount..\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi,\\n\\nI'm working on a bot written in Java using JRAW and [this TweetInCommentsBot](https://github.com/janpetryk/reddit-bot) code. Whenever I try to reply to a comment I get a RATELIMIT error back, while I'm only sending 1 request. (I think)\\n\\nThese are the methods where I reply to comments:\\n    \\n    @Override\\n    \\tpublic PostCommentResult replyToComment(String parentCommentFullName, String responseCommentBody) throws NetworkConnectionException, RedditApiException{\\n    \\t\\ttry {\\n    \\t\\t\\tRedditResponse response = redditClient.execute(redditClient.request()\\n    \\t\\t\\t\\t.endpoint(Endpoints.COMMENT)\\n    \\t\\t\\t\\t.post(JrawUtils.args(\\n    \\t\\t\\t\\t\\t\\\"api_type\\\", \\\"json\\\",\\n    \\t\\t\\t\\t\\t\\\"text\\\", responseCommentBody,\\n    \\t\\t\\t\\t\\t\\\"thing_id\\\", parentCommentFullName))\\n    \\t\\t\\t\\t.build());\\n    \\t\\t\\treturn processResponse(response);\\n    \\t\\t} catch (NetworkException e) {\\n    \\t\\t\\tif (e.getCode() == 403) {\\n    \\t\\t\\t\\treturn PostCommentResult.bannedFromThisSub();\\n    \\t\\t\\t}\\n    \\t\\t\\tthrow new NetworkConnectionException(e);\\n    \\t\\t}\\n    \\t}\\n    \\n    \\tprivate PostCommentResult processResponse(RedditResponse response) {\\n    \\t\\tif (response.hasErrors()) {\\n    \\t\\t\\tString message = response.getErrors()[0].getMessage();\\n    \\t\\t\\tif (message.contains(\\\"DELETED_COMMENT\\\")) {\\n    \\t\\t\\t\\treturn PostCommentResult.commentDeleted();\\n    \\t\\t\\t} else {\\n    \\t\\t\\t\\treturn PostCommentResult.unsuccessful(message);\\n    \\t\\t\\t}\\n    \\n    \\t\\t} else {\\n    \\t\\t\\treturn PostCommentResult.successful(response.getJson().get(\\\"json\\\").get(\\\"data\\\").get(\\\"things\\\").get(0)\\n    \\t\\t\\t\\t.get(\\\"data\\\").get(\\\"id\\\").toString().substring(3));\\n    \\t\\t}\\n    \\t}    \\n\\nI run a task every 30 seconds to let the bot get new posts:\\n\\n    timer = new Timer();\\n    timer.schedule(new ExecuteBot(), 30000);\\n    System.out.println(\\\"Start bot.\\\");\\n\\nIn executebot I login using oAuth:\\n\\n    RedditPost rp;\\n\\t\\n\\tpublic ExecuteBot()\\n\\t{\\n\\t\\t\\n\\t}\\n\\t\\n\\t@Override\\n\\tpublic void run()\\n\\t{\\n\\t\\tif (rp == null)\\n\\t\\t{\\n\\t\\t\\trp = new RedditPost(\\\"desktop:beans.redditbean:v0.1 (by /u/HenkDeVries013)\\\", \\\"user\\\", \\\"hunter2\\\", \\\"secret/id\\\", \\\"secret/id\\\");\\n\\t\\t}\\n\\t\\trp.getStreamNameFromComment();\\n\\t}\\n\\nAnd my RedditPost method to login:\\n    \\n    \\t@Inject\\n    \\tpublic RedditPost(@Named(\\\"reddit-useragent\\\") String userAgent,\\n    \\t\\t@Named(\\\"reddit-login\\\") String login,\\n    \\t\\t@Named(\\\"reddit-password\\\") String password,\\n    \\t\\t@Named(\\\"reddit-client-id\\\") String clientId,\\n    \\t\\t@Named(\\\"reddit-client-secret\\\") String clientSecret) {\\n    \\t\\tredditClient = new RedditClient(userAgent, 60);\\n    \\t\\tloginOAuth(login, password, clientId, clientSecret);\\n    \\t}\\n    \\n    \\tvoid loginOAuth(String username, String password, String clientId, String clientSecret) {\\n    \\t\\ttry {\\n    \\t\\t\\tredditClient.login(Credentials.webapp(username, password, clientId, clientSecret));\\n    \\t\\t} catch (NetworkException ex) {\\n    \\t\\t\\tLogger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n    \\t\\t} catch (ApiException ex) {\\n    \\t\\t\\tLogger.getLogger(RedditPost.class.getName()).log(Level.SEVERE, null, ex);\\n    \\t\\t}\\n    \\n    \\t}\\n\\nWhere do I make the mistake? I have no clue why I get the RATELIMIT since in my understanding I can make up to 60 requests per minute and I'm no where near that amount..\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4osr3v\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"HenkDeVries013\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4osr3v/ratelimit_when_i_try_to_reply_on_someones_comment/\", \"locked\": false, \"name\": \"t3_4osr3v\", \"created\": 1466359957.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4osr3v/ratelimit_when_i_try_to_reply_on_someones_comment/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"RATELIMIT when I try to reply on someone's comment\", \"created_utc\": 1466331157.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m writing a bot to do minor mod work for me. I\\u0026#39;ve managed to login using oauth, but with the wrong permissions, how can I update the permissions? I tried to follow the same steps as the first time, and add  \\u003Ccode\\u003Emodconfig\\u003C/code\\u003E to the scope, but it throws \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Epraw.errors.OAuthInvalidGrant: invalid_grant on url https://api.reddit.com/api/v1/access_token/\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThis is what I use:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er = praw.Reddit(user_agent=user_agent)\\nr.set_oauth_app_info(CLIENT_ID, CLIEAND_SECRET, REDIRECT_URI)\\n#authenticating\\naccess_information = r.get_access_information(AUTH_CODE)\\nr.set_access_credentials(**access_information)\\nurl = r.get_authorize_url(\\u0026#39;uniqueKey identity read modconfig\\u0026#39;,True)\\nimport webbrowser\\nwebbrowser.open(url)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnd the line that throws the error is the third code line (the one starting with \\u003Ccode\\u003Eaccess_information\\u003C/code\\u003E.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow should I do this properly? \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi. \\n\\nI'm writing a bot to do minor mod work for me. I've managed to login using oauth, but with the wrong permissions, how can I update the permissions? I tried to follow the same steps as the first time, and add  ``modconfig`` to the scope, but it throws \\n\\n    praw.errors.OAuthInvalidGrant: invalid_grant on url https://api.reddit.com/api/v1/access_token/\\n\\n\\nThis is what I use:\\n\\n    r = praw.Reddit(user_agent=user_agent)\\n    r.set_oauth_app_info(CLIENT_ID, CLIEAND_SECRET, REDIRECT_URI)\\n    #authenticating\\n    access_information = r.get_access_information(AUTH_CODE)\\n    r.set_access_credentials(**access_information)\\n    url = r.get_authorize_url('uniqueKey identity read modconfig',True)\\n    import webbrowser\\n    webbrowser.open(url)\\n\\nAnd the line that throws the error is the third code line (the one starting with ``access_information``.\\n\\nHow should I do this properly? \\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4opvn9\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"yotama9\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 10, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4opvn9/how_do_i_set_a_bot_to_connect_via_oauth2_and_edit/\", \"locked\": false, \"name\": \"t3_4opvn9\", \"created\": 1466306347.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4opvn9/how_do_i_set_a_bot_to_connect_via_oauth2_and_edit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"how do I set a bot to connect via oauth2 and edit subreddit sidebar\", \"created_utc\": 1466277547.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am using praw to get submission id of a post through a url entered by a user. I can\\u0026#39;t understand why the r.get_submission method is failing. Can someone suggest any improvements?\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E     def UrlRoutine(thrd_url):\\n            \\u0026quot;\\u0026quot;\\u0026quot; Returns the unique submission id from the match thread url \\u0026quot;\\u0026quot;\\u0026quot;\\n            football_url = urlparse(thrd_url)\\n            submission_id =  r.get_submission(football_url.path.split(\\u0026#39;/\\u0026#39;)[4])\\n            return submission_id\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am using praw to get submission id of a post through a url entered by a user. I can't understand why the r.get_submission method is failing. Can someone suggest any improvements?\\n\\n\\n\\n\\n\\n         def UrlRoutine(thrd_url):\\n                \\\"\\\"\\\" Returns the unique submission id from the match thread url \\\"\\\"\\\"\\n                football_url = urlparse(thrd_url)\\n                submission_id =  r.get_submission(football_url.path.split('/')[4])\\n                return submission_id\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4onn23\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"theresasnakeinmysuit\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4onn23/trying_to_get_submission_id_from_url/\", \"locked\": false, \"name\": \"t3_4onn23\", \"created\": 1466264935.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4onn23/trying_to_get_submission_id_from_url/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Trying to get submission id from url\", \"created_utc\": 1466236135.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I have a message in my inbox... I can get it using \\u003Ccode\\u003Er.get_messages()\\u003C/code\\u003E and iterating of them... but I can\\u0026#39;t delete it as \\u003Ccode\\u003Epraw.objects.Messages has no attribute \\u0026#39;delete\\u003C/code\\u003E. What\\u0026#39;s the best way to delete messages?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I have a message in my inbox... I can get it using `r.get_messages()` and iterating of them... but I can't delete it as `praw.objects.Messages has no attribute 'delete`. What's the best way to delete messages?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4omaac\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hinayu\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4omaac/praw_deleting_messages_from_inbox/\", \"locked\": false, \"name\": \"t3_4omaac\", \"created\": 1466238915.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4omaac/praw_deleting_messages_from_inbox/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Deleting messages from inbox\", \"created_utc\": 1466210115.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Ch1\\u003EDISCLAIMER:\\u003C/h1\\u003E\\n\\n\\u003Cp\\u003EThis is literally the first program I have ever written in \\u003Cem\\u003Eany\\u003C/em\\u003E programming language. I\\u0026#39;m pretty proud of it despite its flaws.\\u003C/p\\u003E\\n\\n\\u003Ch1\\u003EThe Code:\\u003C/h1\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Eimport praw\\nimport pdb\\nimport re\\nimport os\\nimport time\\nimport markovify\\nfrom ConfigBot import *\\n\\n\\nr = praw.Reddit(user_agent = \\u0026quot;A chatbot by /u/Gingerale947 that just wants to say stupid things :)\\u0026quot;)\\nr.login(REDDIT_USERNAME, REDDIT_PASS)\\nprint(\\u0026quot;Logging in...\\u0026quot;)\\n\\nalready_read = []\\nmatch = [\\u0026quot;SHITPOST\\u0026quot;]\\nmy_name = [\\u0026quot;GAs_ShitPostBot\\u0026quot;]\\n\\ndef run_bot():\\n    print(\\u0026quot;Connecting to /r/Homestuck\\u0026quot;)\\n    subreddit = r.get_subreddit(\\u0026quot;\\u0026lt;My test subreddit\\u0026gt;\\u0026quot;)\\n    for submission in subreddit.get_hot(limit=5):\\n        if submission.id not in already_read:\\n            r.search(\\u0026#39;flair:\\u0026quot;SHITPOST\\u0026quot;\\u0026#39;, submission.link_flair_text)\\n            if submission.link_flair_text in match:\\n                print(\\u0026quot;Title: \\u0026quot;, submission.title)\\n                print(\\u0026quot;Text: \\u0026quot;, submission.selftext)\\n                print(\\u0026quot;Score: \\u0026quot;, submission.score)\\n                print(\\u0026quot;Author: \\u0026quot;, submission.author)\\n                print(submission.link_flair_css_class)\\n                print(\\u0026quot;---------------------------------\\\\n\\u0026quot;)\\n                already_read.append(submission.id)\\n                print(\\u0026quot;SHITPOSTING...\\u0026quot;)\\n                submission.add_comment(text_model.make_short_sentence(500))\\n                time.sleep(180)\\n\\ndef find_replies():\\n    print(\\u0026quot;Checking replies\\u0026quot;)\\n    subreddit = r.get_subreddit(\\u0026quot;\\u0026lt;My test subreddit\\u0026gt;\\u0026quot;)\\n    comment = subreddit.get_comments(limit=25)\\n    for comment in comments:\\n        comment_text = comment.body.lower()\\n        if comment.parent_id in my_name:\\n            comment.reply(text_model.make_short_sentence(500))\\n            time.sleep(5)\\n\\nwith open(\\u0026#39;C:/Users/Ginge/Desktop/GAs_ShitCommentBot/ShitPostComments.txt\\u0026#39;, encoding=\\u0026quot;utf-8\\u0026quot;) as f:\\n    text = f.read()\\n\\ntext_model = markovify.Text(text, state_size=1)\\n\\nwhile True:\\n    run_bot()\\n    find_replies()\\n    time.sleep(20)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003E(\\u0026quot;\\u0026lt;My test subreddit\\u0026gt;\\u0026quot; isnt actually part of the code its just where I put the name of my test subreddit)\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe run_bot() function works perfectly, it\\u0026#39;s set to find all the posts on a given subreddit that are labeled \\u0026quot;SHITPOST\\u0026quot; (/r/homestuck has a lot of these), and reply with a comment generated with \\u003Ca href=\\\"https://github.com/jsvine/markovify\\\"\\u003Emarkovify\\u003C/a\\u003E. The find_replies() function doesn\\u0026#39;t work at all, sadly, but it\\u0026#39;s intended function is to reply to any comment that replied to the bot\\u0026#39;s comment. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe sad thing is, I want this bot to say MORE things, and I\\u0026#39;m at a loss as to how to do it. I know that putting \\u0026quot;text_model.make_short_sentence(500)\\u0026quot; in the \\u0026quot;submission.add_comment()\\u0026quot; field will make it generate a sentence, but I was hoping it would generate a whole paragraph rather than single sentences. Is this even possible with markovify? \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso, the subreddit that I want to use this bot on allows emotes (formatted like \\u0026quot;[](/emote)\\u0026quot;), but as far as I know, markovify only looks at alphanumeric characters in the source text, so generating the brackets and parentheses needed to type an emote just isn\\u0026#39;t possible. Has anyone figured out how to do something like this? Is markovify just a bad program to use for the task I want my bot to perform?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"#DISCLAIMER:\\n\\nThis is literally the first program I have ever written in *any* programming language. I'm pretty proud of it despite its flaws.\\n\\n#The Code:\\n\\n    import praw\\n    import pdb\\n    import re\\n    import os\\n    import time\\n    import markovify\\n    from ConfigBot import *\\n    \\n    \\n    r = praw.Reddit(user_agent = \\\"A chatbot by /u/Gingerale947 that just wants to say stupid things :)\\\")\\n    r.login(REDDIT_USERNAME, REDDIT_PASS)\\n    print(\\\"Logging in...\\\")\\n    \\n    already_read = []\\n    match = [\\\"SHITPOST\\\"]\\n    my_name = [\\\"GAs_ShitPostBot\\\"]\\n    \\n    def run_bot():\\n        print(\\\"Connecting to /r/Homestuck\\\")\\n        subreddit = r.get_subreddit(\\\"\\u003CMy test subreddit\\u003E\\\")\\n        for submission in subreddit.get_hot(limit=5):\\n            if submission.id not in already_read:\\n                r.search('flair:\\\"SHITPOST\\\"', submission.link_flair_text)\\n                if submission.link_flair_text in match:\\n                    print(\\\"Title: \\\", submission.title)\\n                    print(\\\"Text: \\\", submission.selftext)\\n                    print(\\\"Score: \\\", submission.score)\\n                    print(\\\"Author: \\\", submission.author)\\n                    print(submission.link_flair_css_class)\\n                    print(\\\"---------------------------------\\\\n\\\")\\n                    already_read.append(submission.id)\\n                    print(\\\"SHITPOSTING...\\\")\\n                    submission.add_comment(text_model.make_short_sentence(500))\\n                    time.sleep(180)\\n    \\n    def find_replies():\\n        print(\\\"Checking replies\\\")\\n        subreddit = r.get_subreddit(\\\"\\u003CMy test subreddit\\u003E\\\")\\n        comment = subreddit.get_comments(limit=25)\\n        for comment in comments:\\n            comment_text = comment.body.lower()\\n            if comment.parent_id in my_name:\\n                comment.reply(text_model.make_short_sentence(500))\\n                time.sleep(5)\\n    \\n    with open('C:/Users/Ginge/Desktop/GAs_ShitCommentBot/ShitPostComments.txt', encoding=\\\"utf-8\\\") as f:\\n        text = f.read()\\n    \\n    text_model = markovify.Text(text, state_size=1)\\n    \\n    while True:\\n        run_bot()\\n        find_replies()\\n        time.sleep(20)\\n(\\\"\\u003CMy test subreddit\\u003E\\\" isnt actually part of the code its just where I put the name of my test subreddit)\\n\\nThe run_bot() function works perfectly, it's set to find all the posts on a given subreddit that are labeled \\\"SHITPOST\\\" (\\\\/r/homestuck has a lot of these), and reply with a comment generated with [markovify](https://github.com/jsvine/markovify). The find_replies() function doesn't work at all, sadly, but it's intended function is to reply to any comment that replied to the bot's comment. \\n\\nThe sad thing is, I want this bot to say MORE things, and I'm at a loss as to how to do it. I know that putting \\\"text_model.make_short_sentence(500)\\\" in the \\\"submission.add_comment()\\\" field will make it generate a sentence, but I was hoping it would generate a whole paragraph rather than single sentences. Is this even possible with markovify? \\n\\nAlso, the subreddit that I want to use this bot on allows emotes (formatted like \\\"\\\\[](/emote)\\\"), but as far as I know, markovify only looks at alphanumeric characters in the source text, so generating the brackets and parentheses needed to type an emote just isn't possible. Has anyone figured out how to do something like this? Is markovify just a bad program to use for the task I want my bot to perform?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4okv1u\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Gingerale947\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4okv1u/xpost_from_rcritiquemycode_making_a_reddit_bot/\", \"locked\": false, \"name\": \"t3_4okv1u\", \"created\": 1466219579.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4okv1u/xpost_from_rcritiquemycode_making_a_reddit_bot/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"(Xpost from /r/CritiqueMyCode) Making a reddit bot that generates inane and stupid sentences with markov chains, can anyone help me improve it?\", \"created_utc\": 1466190779.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Ewhen would one justify webscraping instead of using the API?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"when would one justify webscraping instead of using the API?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4okh65\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"fantapeach1\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4okh65/webscraping_vs_api/\", \"locked\": false, \"name\": \"t3_4okh65\", \"created\": 1466214976.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4okh65/webscraping_vs_api/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Webscraping vs API\", \"created_utc\": 1466186176.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello, I\\u0026#39;m trying to add an attribute (multi) to a class (ListingChooser) in \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/lib/pages/pages.py#L5546\\\"\\u003Epages.py\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI changed \\u003Ccode\\u003Eclass ListingChooser(Templated): def __init__(self):\\u003C/code\\u003E to  \\u003Ccode\\u003Eclass ListingChooser(Templated): def __init__(self, multi):\\u003C/code\\u003E but I when I do I get \\u003Ccode\\u003ETypeError: __init__() takes exactly 2 arguments (1 given)\\u003C/code\\u003E. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI fooled around with the few lines of code for the Class ListingChooser in pages.py but wasn\\u0026#39;t able to fix it. I\\u0026#39;ve already defined \\u003Cem\\u003Einit\\u003C/em\\u003E to take 2 arguments, but where  is it only giving the 1 argument instead of the 2 needed?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello, I'm trying to add an attribute (multi) to a class (ListingChooser) in [pages.py](https://github.com/reddit/reddit/blob/master/r2/r2/lib/pages/pages.py#L5546)\\n\\nI changed `class ListingChooser(Templated): def __init__(self):` to  `class ListingChooser(Templated): def __init__(self, multi):` but I when I do I get `TypeError: __init__() takes exactly 2 arguments (1 given)`. \\n\\nI fooled around with the few lines of code for the Class ListingChooser in pages.py but wasn't able to fix it. I've already defined _init_ to take 2 arguments, but where  is it only giving the 1 argument instead of the 2 needed?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ofttl\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"devnoob23\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ofttl/typeerror_init_takes_exactly_2_arguments_1_given/\", \"locked\": false, \"name\": \"t3_4ofttl\", \"created\": 1466141926.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ofttl/typeerror_init_takes_exactly_2_arguments_1_given/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"\\\"TypeError: __init__() takes exactly 2 arguments (1 given)\\\" when adding an attribute to existing object\", \"created_utc\": 1466113126.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI have a local install of reddit that for some reason has links that are both SSL and Non-SSL.  The links to comment, submit a new post and many others.  Its causing an issue with my SSO implementation.  In my ini I have the scheme set to https but that doesn\\u0026#39;t seem to have any impact.  What controls the build of the pages so the actual href\\u0026#39;s on pages are https:// and not http://\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I have a local install of reddit that for some reason has links that are both SSL and Non-SSL.  The links to comment, submit a new post and many others.  Its causing an issue with my SSO implementation.  In my ini I have the scheme set to https but that doesn't seem to have any impact.  What controls the build of the pages so the actual href's on pages are https:// and not http://\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oe67r\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"toddh13\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1466094758.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oe67r/local_install_has_mixed_sslnonssl_links/\", \"locked\": false, \"name\": \"t3_4oe67r\", \"created\": 1466122908.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oe67r/local_install_has_mixed_sslnonssl_links/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Local install has mixed SSL/non-ssl links\", \"created_utc\": 1466094108.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am not a developer myself but I was facing a problem . I am using \\u0026quot;redditor\\u0026quot; client on my iPhone up to a week ago when the app started showing \\u0026quot;there doesn\\u0026#39;t seem to be anything here\\u0026quot; on all the subreddits and front page , after investigation I found that the app is getting message \\u0026quot;Request forbidden by administrative rules\\u0026quot; from \\n\\u003Ca href=\\\"https://www.reddit.com/message/unread.json?limit=100\\\"\\u003Ehttps://www.reddit.com/message/unread.json?limit=100\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI am trying to figure out a solution for this problem ? is there anything can be done ?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am not a developer myself but I was facing a problem . I am using \\\"redditor\\\" client on my iPhone up to a week ago when the app started showing \\\"there doesn't seem to be anything here\\\" on all the subreddits and front page , after investigation I found that the app is getting message \\\"Request forbidden by administrative rules\\\" from \\nhttps://www.reddit.com/message/unread.json?limit=100\\n\\nI am trying to figure out a solution for this problem ? is there anything can be done ?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ocunh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Maxwell500\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ocunh/request_forbidden_by_administrative_rules/\", \"locked\": false, \"name\": \"t3_4ocunh\", \"created\": 1466105366.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ocunh/request_forbidden_by_administrative_rules/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Request forbidden by administrative rules ?\", \"created_utc\": 1466076566.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cpre\\u003E\\u003Ccode\\u003ESo I\\u0026#39;m completely new at this, I need to program a Reddit Bot using Java. I am using the JRAW and am developing in Netbeans. I use messagedriven beans to communicate with another application, but when I try to create a RedditClient it won\\u0026#39;t work and give me a AccessControlException:\\n\\n*SNIP*\\n\\nHere is the code I use to create the client (pretty straight forward): \\n\\nUserAgent myUserAgent = UserAgent.of(\\u0026quot;desktop\\u0026quot;, \\u0026quot;beans.redditbean\\u0026quot;, \\u0026quot;v0.1\\u0026quot;, \\u0026quot;DPIBot\\u0026quot;);\\nRedditClient redditClient;\\nredditClient = new RedditClient(myUserAgent);    \\n\\nI have absolutely no clue why it won\\u0026#39;t work. I don\\u0026#39;t know if it is a configuration error or if it is just my code. Could someone point me in the right way? \\n\\nI\\u0026#39;m sorry if this isn\\u0026#39;t the place to ask this question. ~~\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003ESolved the above problem, onto a new one. I needed to disable the security manager in my glassfish server. Only now I have a new problem.\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ECredentials credentials = Credentials.script(\\u0026quot;*username*\\u0026quot;, \\u0026quot;*hunter2(\\u0026quot;, \\u0026quot;stuff\\u0026quot;, \\u0026quot;otherstuff\\u0026quot;);\\n            OAuthData authData = redditClient.getOAuthHelper().easyAuth(credentials);\\n            redditClient.authenticate(authData);\\n            System.out.println(redditClient.me());\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EWhen I run the code above in a simple Java application everything works, but when I use this in a MessageDriven Bean I get the following exception:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EWarning:   MQJMSRA_MR2001: run:Caught Exception from onMessage():Redelivering:\\njavax.ejb.EJBException: message-driven bean method public abstract void javax.jms.MessageListener.onMessage(javax.jms.Message) system exception\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1254)\\n    at org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    at com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    at com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    at com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    at com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\nCaused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    at net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    at net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    at net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    at service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    at beans.RedditBean.onMessage(RedditBean.java:43)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    at com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    at com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    at org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    at org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    at com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    at com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    ... 7 more\\n\\nInfo:   MQJMSRA_MR1101: run:Message returned \\u0026amp; marked for routing to the DMQ\\nWarning:   MDB00037: [WebTwitchScraper:RedditBean]: Message-driven bean invocation exception: [javax.ejb.EJBException]\\nWarning:   javax.ejb.EJBException\\njavax.ejb.EJBException\\n    at com.sun.ejb.containers.EJBContainerTransactionManager.processSystemException(EJBContainerTransactionManager.java:750)\\n    at com.sun.ejb.containers.EJBContainerTransactionManager.completeNewTx(EJBContainerTransactionManager.java:700)\\n    at com.sun.ejb.containers.EJBContainerTransactionManager.postInvokeTx(EJBContainerTransactionManager.java:505)\\n    at com.sun.ejb.containers.BaseContainer.postInvokeTx(BaseContainer.java:4566)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDeliveryInternal(MessageBeanContainer.java:1326)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDelivery(MessageBeanContainer.java:1301)\\n    at org.glassfish.ejb.mdb.MessageBeanListenerImpl.afterMessageDelivery(MessageBeanListenerImpl.java:86)\\n    at com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:143)\\n    at com.sun.proxy.$Proxy345.afterDelivery(Unknown Source)\\n    at com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:361)\\n    at com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    at com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\nCaused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    at net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    at net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    at net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    at net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    at service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    at beans.RedditBean.onMessage(RedditBean.java:43)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    at org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    at com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    at com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    at org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    at org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    at java.lang.reflect.Method.invoke(Method.java:497)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    at com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    at com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    at com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    at com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    at org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    at org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    at com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    at com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    at com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    ... 3 more\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EIs this something I need to disable somewhere in my config? I don\\u0026#39;t care about the security since that isn\\u0026#39;t really important in my case.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"    So I'm completely new at this, I need to program a Reddit Bot using Java. I am using the JRAW and am developing in Netbeans. I use messagedriven beans to communicate with another application, but when I try to create a RedditClient it won't work and give me a AccessControlException:\\n\\n    *SNIP*\\n\\n    Here is the code I use to create the client (pretty straight forward): \\n\\n    UserAgent myUserAgent = UserAgent.of(\\\"desktop\\\", \\\"beans.redditbean\\\", \\\"v0.1\\\", \\\"DPIBot\\\");\\n    RedditClient redditClient;\\n    redditClient = new RedditClient(myUserAgent);    \\n\\n    I have absolutely no clue why it won't work. I don't know if it is a configuration error or if it is just my code. Could someone point me in the right way? \\n\\n    I'm sorry if this isn't the place to ask this question. ~~\\n\\nSolved the above problem, onto a new one. I needed to disable the security manager in my glassfish server. Only now I have a new problem.\\n\\n    Credentials credentials = Credentials.script(\\\"*username*\\\", \\\"*hunter2(\\\", \\\"stuff\\\", \\\"otherstuff\\\");\\n    \\t\\t\\tOAuthData authData = redditClient.getOAuthHelper().easyAuth(credentials);\\n    \\t\\t\\tredditClient.authenticate(authData);\\n    \\t\\t\\tSystem.out.println(redditClient.me());\\n\\nWhen I run the code above in a simple Java application everything works, but when I use this in a MessageDriven Bean I get the following exception:\\n\\n    Warning:   MQJMSRA_MR2001: run:Caught Exception from onMessage():Redelivering:\\n    javax.ejb.EJBException: message-driven bean method public abstract void javax.jms.MessageListener.onMessage(javax.jms.Message) system exception\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1254)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    \\tat com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    \\tat com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    \\tat com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    \\tat com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\n    Caused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    \\tat net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    \\tat service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    \\tat beans.RedditBean.onMessage(RedditBean.java:43)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    \\tat com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    \\tat com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    \\tat org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    \\tat org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    \\tat sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    \\tat com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    \\tat com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    \\t... 7 more\\n    \\n    Info:   MQJMSRA_MR1101: run:Message returned \\u0026 marked for routing to the DMQ\\n    Warning:   MDB00037: [WebTwitchScraper:RedditBean]: Message-driven bean invocation exception: [javax.ejb.EJBException]\\n    Warning:   javax.ejb.EJBException\\n    javax.ejb.EJBException\\n    \\tat com.sun.ejb.containers.EJBContainerTransactionManager.processSystemException(EJBContainerTransactionManager.java:750)\\n    \\tat com.sun.ejb.containers.EJBContainerTransactionManager.completeNewTx(EJBContainerTransactionManager.java:700)\\n    \\tat com.sun.ejb.containers.EJBContainerTransactionManager.postInvokeTx(EJBContainerTransactionManager.java:505)\\n    \\tat com.sun.ejb.containers.BaseContainer.postInvokeTx(BaseContainer.java:4566)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDeliveryInternal(MessageBeanContainer.java:1326)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.afterMessageDelivery(MessageBeanContainer.java:1301)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanListenerImpl.afterMessageDelivery(MessageBeanListenerImpl.java:86)\\n    \\tat com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:143)\\n    \\tat com.sun.proxy.$Proxy345.afterDelivery(Unknown Source)\\n    \\tat com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:361)\\n    \\tat com.sun.enterprise.connectors.work.OneWork.doWork(OneWork.java:107)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.performWork(ThreadPoolImpl.java:497)\\n    \\tat com.sun.corba.ee.impl.threadpool.ThreadPoolImpl$WorkerThread.run(ThreadPoolImpl.java:540)\\n    Caused by: java.lang.NoSuchMethodError: com.google.common.util.concurrent.RateLimiter.tryAcquire()Z\\n    \\tat net.dean.jraw.http.RestClient.execute(RestClient.java:106)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:143)\\n    \\tat net.dean.jraw.RedditClient.execute(RedditClient.java:137)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.doScriptApp(OAuthHelper.java:211)\\n    \\tat net.dean.jraw.http.oauth.OAuthHelper.easyAuth(OAuthHelper.java:186)\\n    \\tat service.RedditCommunicate.PostToReddit(RedditCommunicate.java:33)\\n    \\tat beans.RedditBean.onMessage(RedditBean.java:43)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n    \\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.runMethod(EJBSecurityManager.java:1081)\\n    \\tat org.glassfish.ejb.security.application.EJBSecurityManager.invoke(EJBSecurityManager.java:1153)\\n    \\tat com.sun.ejb.containers.BaseContainer.invokeBeanMethod(BaseContainer.java:4786)\\n    \\tat com.sun.ejb.EjbInvocation.invokeBeanMethod(EjbInvocation.java:656)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.EjbInvocation.proceed(EjbInvocation.java:608)\\n    \\tat org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:73)\\n    \\tat org.jboss.weld.ejb.SessionBeanInterceptor.aroundInvoke(SessionBeanInterceptor.java:52)\\n    \\tat sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)\\n    \\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n    \\tat java.lang.reflect.Method.invoke(Method.java:497)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeInterceptor.intercept(InterceptorManager.java:883)\\n    \\tat com.sun.ejb.containers.interceptors.AroundInvokeChainImpl.invokeNext(InterceptorManager.java:822)\\n    \\tat com.sun.ejb.containers.interceptors.InterceptorManager.intercept(InterceptorManager.java:369)\\n    \\tat com.sun.ejb.containers.BaseContainer.__intercept(BaseContainer.java:4758)\\n    \\tat com.sun.ejb.containers.BaseContainer.intercept(BaseContainer.java:4746)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanContainer.deliverMessage(MessageBeanContainer.java:1219)\\n    \\tat org.glassfish.ejb.mdb.MessageBeanListenerImpl.deliverMessage(MessageBeanListenerImpl.java:81)\\n    \\tat com.sun.enterprise.connectors.inbound.MessageEndpointInvocationHandler.invoke(MessageEndpointInvocationHandler.java:171)\\n    \\tat com.sun.proxy.$Proxy345.onMessage(Unknown Source)\\n    \\tat com.sun.messaging.jms.ra.OnMessageRunner.run(OnMessageRunner.java:283)\\n    \\t... 3 more\\n    \\n\\nIs this something I need to disable somewhere in my config? I don't care about the security since that isn't really important in my case.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ocqfu\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"HenkDeVries013\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1466079236.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ocqfu/java_jraw_exception_while_instantiating_new/\", \"locked\": false, \"name\": \"t3_4ocqfu\", \"created\": 1466103087.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ocqfu/java_jraw_exception_while_instantiating_new/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[Java] [JRAW] Exception while instantiating new RedditClient\", \"created_utc\": 1466074287.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ocq9v\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Le_9k_Redditor\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ocq9v/is_there_an_easy_praw_function_to_fetch_all/\", \"locked\": false, \"name\": \"t3_4ocq9v\", \"created\": 1466102992.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ocq9v/is_there_an_easy_praw_function_to_fetch_all/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there an easy praw function to fetch all comments from permalink/context url?\", \"created_utc\": 1466074192.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am a Redditor who is also a Voater and I\\u0026#39;ve noticed that Voat has lots of checks when you either login or create an account, especially the image CAPTCHA checks, whereas Reddit just allows one to click a few buttons and register.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow does Reddit ensure that a crawler or a bot doesn\\u0026#39;t programmatically register all the usernames, or cause a DDOS?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am a Redditor who is also a Voater and I've noticed that Voat has lots of checks when you either login or create an account, especially the image CAPTCHA checks, whereas Reddit just allows one to click a few buttons and register.\\n\\nHow does Reddit ensure that a crawler or a bot doesn't programmatically register all the usernames, or cause a DDOS?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4oc66k\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"prahladyeri\", \"media\": null, \"score\": 8, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 11, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4oc66k/what_does_reddit_use_for_ddos_protection/\", \"locked\": false, \"name\": \"t3_4oc66k\", \"created\": 1466091056.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4oc66k/what_does_reddit_use_for_ddos_protection/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"What does Reddit use for DDOS protection?\", \"created_utc\": 1466062256.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 8}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EOkay so I\\u0026#39;m completely new to scripting and I\\u0026#39;d like to create bot that I can run from my raspberry pi(2). web based or something like that. It\\u0026#39;s purpose will be to post about twice a week to a clan recruiting subreddit. But I have no idea where to start.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECould someone help me out?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Okay so I'm completely new to scripting and I'd like to create bot that I can run from my raspberry pi(2). web based or something like that. It's purpose will be to post about twice a week to a clan recruiting subreddit. But I have no idea where to start.\\n\\nCould someone help me out?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o9vqm\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"SnowFreak_\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o9vqm/creating_a_auto_posting_bot_for_reddit/\", \"locked\": false, \"name\": \"t3_4o9vqm\", \"created\": 1466055973.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o9vqm/creating_a_auto_posting_bot_for_reddit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Creating a auto posting bot for reddit\", \"created_utc\": 1466027173.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo, in trying to get the reddit open source stack deployed with the install-reddit.sh script on Ubuntu, I had to go in to the cassandra config and tweak a bit. It initially wouldn\\u0026#39;t start due to stack size and that was relatively straightfoward to \\u0026quot;fix\\u0026quot;, but left me wondering what the \\u0026quot;typical\\u0026quot; config is out there for people running the reddit stack (outside the massively scaled environment of reddit.com)  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThings like rpc_max_threads, MAX_HEAP_SIZE, the java memory config, and so forth. There\\u0026#39;s some \\u0026quot;automatic\\u0026quot; sizing stuff in cassandra-env.sh but again, somehow that didn\\u0026#39;t do the magic. Google search reveals interesting \\u003Cem\\u003Eleads\\u003C/em\\u003E, but it seems much more straightforward to just ask:  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026quot;Hey, what does your cassandra configuration look like?\\u0026quot; \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So, in trying to get the reddit open source stack deployed with the install-reddit.sh script on Ubuntu, I had to go in to the cassandra config and tweak a bit. It initially wouldn't start due to stack size and that was relatively straightfoward to \\\"fix\\\", but left me wondering what the \\\"typical\\\" config is out there for people running the reddit stack (outside the massively scaled environment of reddit.com)  \\n \\nThings like rpc_max_threads, MAX_HEAP_SIZE, the java memory config, and so forth. There's some \\\"automatic\\\" sizing stuff in cassandra-env.sh but again, somehow that didn't do the magic. Google search reveals interesting *leads*, but it seems much more straightforward to just ask:  \\n\\n\\\"Hey, what does your cassandra configuration look like?\\\" \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o95x7\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"L0AD_M0RE_C0MMENTS\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o95x7/cassandra_optimal_singleserver_config/\", \"locked\": false, \"name\": \"t3_4o95x7\", \"created\": 1466047872.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o95x7/cassandra_optimal_singleserver_config/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Cassandra \\\"optimal\\\" single-server config?\", \"created_utc\": 1466019072.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi, I\\u0026#39;m currently working on \\u003Ca href=\\\"http://www.saywhat.lol\\\"\\u003Ewww.saywhat.lol\\u003C/a\\u003E and one of our top priorities is getting links shared from our site to preview and autoplay on reddit (like the ones from imgur do). We\\u0026#39;ve followed all the instructions but we still can\\u0026#39;t get them to work. Here\\u0026#39;s a sample url to share a gif: \\u003Ca href=\\\"https://saywhat.lol/share-gif?id=the%20simpsons-s06e18-43\\u0026amp;st=206244\\u0026amp;d=3598\\\"\\u003Ehttps://saywhat.lol/share-gif?id=the%20simpsons-s06e18-43\\u0026amp;st=206244\\u0026amp;d=3598\\u003C/a\\u003E We do not even see reddit hitting our oembed endpoint to generate a preview. Any pointers as to what we may be doing wrong will be greatly appreciated.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi, I'm currently working on www.saywhat.lol and one of our top priorities is getting links shared from our site to preview and autoplay on reddit (like the ones from imgur do). We've followed all the instructions but we still can't get them to work. Here's a sample url to share a gif: https://saywhat.lol/share-gif?id=the%20simpsons-s06e18-43\\u0026st=206244\\u0026d=3598 We do not even see reddit hitting our oembed endpoint to generate a preview. Any pointers as to what we may be doing wrong will be greatly appreciated.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o7ng3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"elibud\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 7, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o7ng3/getting_gifs_and_mp4_videos_to_autoplay/\", \"locked\": false, \"name\": \"t3_4o7ng3\", \"created\": 1466030751.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o7ng3/getting_gifs_and_mp4_videos_to_autoplay/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting gifs and mp4 videos to autoplay\", \"created_utc\": 1466001951.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I\\u0026#39;ve been trying to make a bot with the \\u003Ca href=\\\"https://github.com/jcleblanc/reddit-php-sdk\\\"\\u003Ereddit php api\\u003C/a\\u003E, but I can\\u0026#39;t seem to get it working.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve created a personal script app on reddit, entered the client id and client secret in the config.php, but I can\\u0026#39;t do anything. The reply I get for any action I do is an empty string.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe code I am using to try to submit something is this:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Erequire_once(\\u0026#39;reddit.php\\u0026#39;);\\n$reddit = new reddit();\\n\\n$title = \\u0026#39;Test of my bot\\u0026#39;;\\n$link = \\u0026#39;http://example.com/\\u0026#39;;\\n$subreddit = \\u0026#39;test\\u0026#39;;\\n$response = $reddit-\\u0026gt;createStory($title, $link, $subreddit);\\necho $response . \\u0026quot;\\\\n\\u0026quot;;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAny help would be appreciated.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I've been trying to make a bot with the [reddit php api](https://github.com/jcleblanc/reddit-php-sdk), but I can't seem to get it working.\\n\\nI've created a personal script app on reddit, entered the client id and client secret in the config.php, but I can't do anything. The reply I get for any action I do is an empty string.\\n\\nThe code I am using to try to submit something is this:\\n\\n    require_once('reddit.php');\\n    $reddit = new reddit();\\n    \\n    $title = 'Test of my bot';\\n    $link = 'http://example.com/';\\n    $subreddit = 'test';\\n    $response = $reddit-\\u003EcreateStory($title, $link, $subreddit);\\n    echo $response . \\\"\\\\n\\\";\\n\\nAny help would be appreciated.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o703d\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"itchyDoggy\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o703d/help_with_the_reddit_php_api/\", \"locked\": false, \"name\": \"t3_4o703d\", \"created\": 1466021688.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o703d/help_with_the_reddit_php_api/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help with the reddit php api\", \"created_utc\": 1465992888.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey guys, I just graduated college with a double major in Bio and Economics and I am heading in to the finance field; specifically focusing on telecom, data, and cloud firms.  Turns out you don\\u0026#39;t learn much about technology in either of those fields.  One of the things I am trying to learn are the basics of tech including APIs, SaaS, CPaaS, and basic Cloud Services.  Could y\\u0026#39;all direct me to the right sub where I could learn about these things? I found this sub after trying to scan Reddit trying to learn about APIs and their functions.  \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey guys, I just graduated college with a double major in Bio and Economics and I am heading in to the finance field; specifically focusing on telecom, data, and cloud firms.  Turns out you don't learn much about technology in either of those fields.  One of the things I am trying to learn are the basics of tech including APIs, SaaS, CPaaS, and basic Cloud Services.  Could y'all direct me to the right sub where I could learn about these things? I found this sub after trying to scan Reddit trying to learn about APIs and their functions.  \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4o3uxy\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"3oh3banker\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4o3uxy/help_with_basic_tech_understanding/\", \"locked\": false, \"name\": \"t3_4o3uxy\", \"created\": 1465969208.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4o3uxy/help_with_basic_tech_understanding/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help with basic Tech understanding?\", \"created_utc\": 1465940408.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHere\\u0026#39;s what he told me:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026quot; It\\u0026#39;s   installed fine (apparently) and you can register, but that\\u0026#39;s about it. When you try to create a subreddit, for example, it gives this nasty error:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ENotImplementedError: Action u\\u0026#39;POST_submit\\u0026#39; is not implemented\\nWhich seems pretty odd. Debugging output is whargarble to me as it\\u0026#39;s just too specific to what\\u0026#39;s going on with this code, and google searches for that error seem to be about other servers/services.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso, the Submit a new... form won\\u0026#39;t let you select Text, AND the Create button for Link posts doesn\\u0026#39;t seem to trigger / \\u0026quot;do anything\\u0026quot; either. Just discovered that attempting to comment gives a similar \\u0026quot;post not implemented\\u0026quot; error that\\u0026#39;s visible via firebug.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAnyone have insight / clue / pointers / experience? If it were just Java, or just front-end / js code, or just SQL, I might have a fighting chance... but with all this fucking cassandra, rabbit, memcache stuff that I don\\u0026#39;t have experience with... whew. I don\\u0026#39;t know where to look.\\u0026quot;\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Here's what he told me:\\n\\n\\\" It's   installed fine (apparently) and you can register, but that's about it. When you try to create a subreddit, for example, it gives this nasty error:\\n\\nNotImplementedError: Action u'POST_submit' is not implemented\\nWhich seems pretty odd. Debugging output is whargarble to me as it's just too specific to what's going on with this code, and google searches for that error seem to be about other servers/services.\\n\\nAlso, the Submit a new... form won't let you select Text, AND the Create button for Link posts doesn't seem to trigger / \\\"do anything\\\" either. Just discovered that attempting to comment gives a similar \\\"post not implemented\\\" error that's visible via firebug.\\n\\nAnyone have insight / clue / pointers / experience? If it were just Java, or just front-end / js code, or just SQL, I might have a fighting chance... but with all this fucking cassandra, rabbit, memcache stuff that I don't have experience with... whew. I don't know where to look.\\\"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nzcwh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Francois_Rapiste\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 28, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nzcwh/friend_of_mine_is_trying_to_create_a_reddit_clone/\", \"locked\": false, \"name\": \"t3_4nzcwh\", \"created\": 1465901453.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nzcwh/friend_of_mine_is_trying_to_create_a_reddit_clone/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Friend of mine is trying to create a Reddit clone. Help?\", \"created_utc\": 1465872653.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m playing around with the reddit api using the \\u003Ca href=\\\"https://github.com/jcleblanc/reddit-php-sdk\\\"\\u003EReddit php skd\\u003C/a\\u003E and i want to make it so that i don\\u0026#39;t need to authorize every hour, like i need to do now.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks for any help!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm playing around with the reddit api using the [Reddit php skd](https://github.com/jcleblanc/reddit-php-sdk) and i want to make it so that i don't need to authorize every hour, like i need to do now.\\n\\nThanks for any help!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nvak7\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"theo65_theo01\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nvak7/reddit_php_sdk_can_i_make_it_so_that_i_dont_need/\", \"locked\": false, \"name\": \"t3_4nvak7\", \"created\": 1465848165.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nvak7/reddit_php_sdk_can_i_make_it_so_that_i_dont_need/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Reddit PHP SDK - Can i make it so that I don't need to authorize every hour?\", \"created_utc\": 1465819365.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EPRAW version is 3.5.0, I am 100% certain this is the issue. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"PRAW version is 3.5.0, I am 100% certain this is the issue. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nu8x1\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"thirdegree\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nu8x1/praw_edit_wiki_page_raising_forbidden_when/\", \"locked\": false, \"name\": \"t3_4nu8x1\", \"created\": 1465824771.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nu8x1/praw_edit_wiki_page_raising_forbidden_when/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW edit_wiki_page raising Forbidden when content is larger than 5120 chars\", \"created_utc\": 1465795971.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIs it possible to post a comment and distinguish it in one call?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://www.reddit.com/dev/api#POST_api_comment\\\"\\u003Ehttps://www.reddit.com/dev/api#POST_api_comment\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Is it possible to post a comment and distinguish it in one call?\\n\\nhttps://www.reddit.com/dev/api#POST_api_comment\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nsno2\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MystK\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nsno2/post_comment_and_distinguish_in_in_endpoint_call/\", \"locked\": false, \"name\": \"t3_4nsno2\", \"created\": 1465799649.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nsno2/post_comment_and_distinguish_in_in_endpoint_call/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Post comment and distinguish in in endpoint call\", \"created_utc\": 1465770849.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Ehitting up this endpoint without gold produces the following:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E{\\u0026quot;fields\\u0026quot;: [\\u0026quot;note\\u0026quot;], \\u0026quot;explanation\\u0026quot;: \\u0026quot;you must have an active reddit gold subscription to do that\\u0026quot;, \\u0026quot;reason\\u0026quot;: \\u0026quot;GOLD_REQUIRED\\u0026quot;}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003E(when trying to add a friend ^ )\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso (haven\\u0026#39;t fully investigated yet) but I\\u0026#39;m pretty sure \\u003Ccode\\u003E/api/friend\\u003C/code\\u003E doesn\\u0026#39;t work when authenticating with OAuth (same as \\u003Ccode\\u003E[/r/subreddit]/sidebar\\u003C/code\\u003E), they return 400\\u0026#39;s.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI could post examples but I don\\u0026#39;t want to divulge my access token, but if someone else wants to confirm these issues are live I would appreciate it!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"hitting up this endpoint without gold produces the following:\\n\\n    {\\\"fields\\\": [\\\"note\\\"], \\\"explanation\\\": \\\"you must have an active reddit gold subscription to do that\\\", \\\"reason\\\": \\\"GOLD_REQUIRED\\\"}\\n\\n(when trying to add a friend ^ )\\n\\nAlso (haven't fully investigated yet) but I'm pretty sure `/api/friend` doesn't work when authenticating with OAuth (same as `[/r/subreddit]/sidebar`), they return 400's.\\n\\nI could post examples but I don't want to divulge my access token, but if someone else wants to confirm these issues are live I would appreciate it!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nqx7z\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Macmee\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nqx7z/endpoint_erroneously_requires_gold_put/\", \"locked\": false, \"name\": \"t3_4nqx7z\", \"created\": 1465777013.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nqx7z/endpoint_erroneously_requires_gold_put/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Endpoint erroneously requires gold: PUT /api/v1/me/friends/username\", \"created_utc\": 1465748213.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m trying to edit a wiki with the Reddit API but I get a \\u0026quot;URI is too long\\u0026quot; error. I\\u0026#39;ve tried to add the wiki content as part of the body, but it\\u0026#39;s not working. Am I missing something?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://www.reddit.com/dev/api#POST_api_wiki_edit\\\"\\u003Ehttps://www.reddit.com/dev/api#POST_api_wiki_edit\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm trying to edit a wiki with the Reddit API but I get a \\\"URI is too long\\\" error. I've tried to add the wiki content as part of the body, but it's not working. Am I missing something?\\n\\nhttps://www.reddit.com/dev/api#POST_api_wiki_edit\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4noh3e\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MystK\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4noh3e/reddit_api_edit_wiki_large_data/\", \"locked\": false, \"name\": \"t3_4noh3e\", \"created\": 1465727866.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4noh3e/reddit_api_edit_wiki_large_data/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Reddit API Edit Wiki large data\", \"created_utc\": 1465699066.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cblockquote\\u003E\\n\\u003Cp\\u003EClients connecting via OAuth2 may make up to 60 requests per minute\\u003C/p\\u003E\\n\\u003C/blockquote\\u003E\\n\\n\\u003Cp\\u003Eis in the documentation.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EDoes this mean that I can have 60 requests per app on my Bot account, or 60 per account?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"\\u003EClients connecting via OAuth2 may make up to 60 requests per minute\\n\\nis in the documentation.\\n\\nDoes this mean that I can have 60 requests per app on my Bot account, or 60 per account?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nm7a6\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Shubbler\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nm7a6/q_60_requests_per_account_or_60_per_app/\", \"locked\": false, \"name\": \"t3_4nm7a6\", \"created\": 1465693236.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nm7a6/q_60_requests_per_account_or_60_per_app/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[Q] 60 requests per account or 60 per app?\", \"created_utc\": 1465664436.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI know you can send a PM via the API. Can you PM from the API as a subreddit you moderate? How?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I know you can send a PM via the API. Can you PM from the API as a subreddit you moderate? How?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4njb82\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"chef_boner\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 15, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4njb82/so_you_can_send_messages_as_the_subreddit_can_you/\", \"locked\": false, \"name\": \"t3_4njb82\", \"created\": 1465634449.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4njb82/so_you_can_send_messages_as_the_subreddit_can_you/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"So you can send messages as the subreddit. Can you do it via the API?\", \"created_utc\": 1465605649.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EDoes PRAW support Application Only OAuth? \\u003Ca href=\\\"https://praw.readthedocs.io/en/stable/pages/oauth.html\\\"\\u003EThe online documentation\\u003C/a\\u003E seems to cover only web apps and scripts. This is my first time getting into the reddit api, so I apologize in advance if there\\u0026#39;s something obvious I\\u0026#39;m missing here... Thanks in advance for your time!\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEDIT:\\u003C/p\\u003E\\n\\n\\u003Cblockquote\\u003E\\n\\u003Cp\\u003E[16:55] == tuxredux [a2dbb2ea@gateway/web/freenode/ip.162.219.178.234] has joined #reddit-dev\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E[16:55] \\u0026lt;tuxredux\\u0026gt; hello reddit-dev. quick question. does praw support application only oauth?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E[16:56] \\u0026lt;tuxredux\\u0026gt; \\u003Ca href=\\\"https://praw.readthedocs.io/en/stable/pages/oauth.html\\\"\\u003Ehttps://praw.readthedocs.io/en/stable/pages/oauth.html\\u003C/a\\u003E seems to only cover web apps and scripts\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E[17:09] \\u0026lt;amici_ursi\\u0026gt; tuxredux: kind of.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E[17:10] \\u0026lt;amici_ursi\\u0026gt; \\u003Ca href=\\\"https://github.com/praw-dev/praw/pull/606\\\"\\u003Ehttps://github.com/praw-dev/praw/pull/606\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/blockquote\\u003E\\n\\n\\u003Cp\\u003EEDIT2: Just figured this out in requests... going to see if I can do it with PRAW now. I\\u0026#39;ll post back!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Does PRAW support Application Only OAuth? [The online documentation](https://praw.readthedocs.io/en/stable/pages/oauth.html) seems to cover only web apps and scripts. This is my first time getting into the reddit api, so I apologize in advance if there's something obvious I'm missing here... Thanks in advance for your time!\\n\\nEDIT:\\n\\n\\u003E [16:55] == tuxredux [a2dbb2ea@gateway/web/freenode/ip.162.219.178.234] has joined #reddit-dev\\n\\n\\u003E [16:55] \\u003Ctuxredux\\u003E hello reddit-dev. quick question. does praw support application only oauth?\\n\\n\\u003E [16:56] \\u003Ctuxredux\\u003E https://praw.readthedocs.io/en/stable/pages/oauth.html seems to only cover web apps and scripts\\n\\n\\u003E [17:09] \\u003Camici_ursi\\u003E tuxredux: kind of.\\n\\n\\u003E [17:10] \\u003Camici_ursi\\u003E https://github.com/praw-dev/praw/pull/606\\n\\nEDIT2: Just figured this out in requests... going to see if I can do it with PRAW now. I'll post back!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4niqbs\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"tuxredux\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1465602031.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4niqbs/praw_application_only_oauth/\", \"locked\": false, \"name\": \"t3_4niqbs\", \"created\": 1465625354.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4niqbs/praw_application_only_oauth/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW Application Only OAuth\", \"created_utc\": 1465596554.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhat\\u0026#39;s the easiest way to get a count of the most popular words or topics within a given subreddit? Any help would be appreciated!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"What's the easiest way to get a count of the most popular words or topics within a given subreddit? Any help would be appreciated!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4niev4\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Stopwatch_\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4niev4/most_popular_words_or_phrases_within_a_given/\", \"locked\": false, \"name\": \"t3_4niev4\", \"created\": 1465621023.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4niev4/most_popular_words_or_phrases_within_a_given/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Most popular words or phrases within a given subreddit\", \"created_utc\": 1465592223.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m trying to post a comment, distinguish it, and sticky it.  Is the code below the correct process?  It seems like it\\u0026#39;s hit and miss (but mostly miss) unless I add a sleep() between the first distinguish and the refresh for 5 seconds or so.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThis feels like a hack, so I\\u0026#39;m guessing there\\u0026#39;s something I\\u0026#39;ve missed.  =) \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Ecomment = submission.add_comment(\\u0026quot;This is a stickied comment.\\u0026quot;)\\ncomment.distinguish()\\ncomment.refresh()\\ncomment.distinguish(sticky=True)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm trying to post a comment, distinguish it, and sticky it.  Is the code below the correct process?  It seems like it's hit and miss (but mostly miss) unless I add a sleep() between the first distinguish and the refresh for 5 seconds or so.\\n\\nThis feels like a hack, so I'm guessing there's something I've missed.  =) \\n\\n    comment = submission.add_comment(\\\"This is a stickied comment.\\\")\\n    comment.distinguish()\\n    comment.refresh()\\n    comment.distinguish(sticky=True)\\n    \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nhjxi\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"BadgerBalls\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nhjxi/praw3_stickying_a_comment_only_works_after_a_delay/\", \"locked\": false, \"name\": \"t3_4nhjxi\", \"created\": 1465610169.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nhjxi/praw3_stickying_a_comment_only_works_after_a_delay/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW3] Stickying a comment only works after a delay?\", \"created_utc\": 1465581369.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Eyes, it is not rocket science, but imho more comments more interest, more upvotes more diamonds... still do not know how to use weight of age of nick registration and current karma of poster to filtrate clickbeit marketing spam nsfw chat shitty threads... maybe like in soccer user have some red cards/day to give another user to his karma to kick this shitty ads users from reddit\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"yes, it is not rocket science, but imho more comments more interest, more upvotes more diamonds... still do not know how to use weight of age of nick registration and current karma of poster to filtrate clickbeit marketing spam nsfw chat shitty threads... maybe like in soccer user have some red cards/day to give another user to his karma to kick this shitty ads users from reddit\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4nhhj2\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"rovert13\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4nhhj2/sort_by_number_of_comments_thread_upvotes_comments/\", \"locked\": false, \"name\": \"t3_4nhhj2\", \"created\": 1465609348.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4nhhj2/sort_by_number_of_comments_thread_upvotes_comments/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"sort by number of comments (thread), upvotes (comments)\", \"created_utc\": 1465580548.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhen I checked out the reddit code, it was a delight to see a \\u003Ccode\\u003EVagrantfile\\u003C/code\\u003E in the root. I did the typical \\u003Ccode\\u003Evagrant up\\u003C/code\\u003E (and then waited a long time) and then read the docs to see what I should see. I \\u003Ccode\\u003Evagrant ssh\\u003C/code\\u003E\\u0026#39;d in and tried to \\u003Ccode\\u003Ecurl -v \\u0026#39;http://reddit.local\\u0026#39;\\u003C/code\\u003E and got a 503 in return. I figured this is because I didn\\u0026#39;t populate with demo data like \\u003Ccode\\u003Einstall/done.sh\\u003C/code\\u003E suggests, so i ran \\u003Ccode\\u003Ereddit-run scripts/inject_test_data.py -c \\u0026#39;inject_test_data()\\u0026#39;\\u003C/code\\u003E That failed with a neat, inscruitable traceback:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ETraceback (most recent call last):\\n  File \\u0026quot;/usr/bin/paster\\u0026quot;, line 4, in \\u0026lt;module\\u0026gt;\\n    command.run()\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/script/command.py\\u0026quot;, line 104, in run\\n    invoke(command, command_name, options, args[1:])\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/script/command.py\\u0026quot;, line 143, in invoke\\n    exit_code = runner.run(args)\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/script/command.py\\u0026quot;, line 238, in run\\n    result = self.command()\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/commands.py\\u0026quot;, line 68, in command\\n    config_name, relative_to=here_dir, global_conf=global_conf)\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\u0026quot;, line 247, in loadapp\\n    return loadobj(APP, uri, name=name, **kw)\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\u0026quot;, line 272, in loadobj\\n    return context.create()\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\u0026quot;, line 710, in create\\n    return self.object_type.invoke(self)\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\u0026quot;, line 146, in invoke\\n    return fix_call(context.object, context.global_conf, **context.local_conf)\\n  File \\u0026quot;/usr/lib/python2.7/dist-packages/paste/deploy/util.py\\u0026quot;, line 55, in fix_call\\n    val = callable(*args, **kw)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/__init__.py\\u0026quot;, line 41, in make_app\\n    return real_make_app(*args, **kwargs)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/config/middleware.py\\u0026quot;, line 513, in make_app\\n    config = load_environment(global_conf, app_conf)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/config/environment.py\\u0026quot;, line 78, in load_environment\\n    g.plugins.load_plugins(config)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/lib/plugin.py\\u0026quot;, line 147, in load_plugins\\n    g.config.add_spec(plugin.config)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/lib/configparse.py\\u0026quot;, line 116, in add_spec\\n    self._update_values(new_keys)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/lib/configparse.py\\u0026quot;, line 126, in _update_values\\n    value = parser(value, key)\\n  File \\u0026quot;/home/vagrant/src/reddit/r2/r2/lib/configparse.py\\u0026quot;, line 35, in int\\n    return int(v)\\nValueError: invalid literal for int() with base 10: \\u0026#39;\\u0026#39;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThat traceback is also littering the \\u003Ccode\\u003E/var/log/syslog\\u003C/code\\u003E file; it looks like nothing can run, because the configs are unreadable from init.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe lowest part in the traceback that makes sense to hack around is in \\u003Ccode\\u003Er2/r2/lib/plugin.py\\u003C/code\\u003E - adding a print statement to tell which plugin fails init shows:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E\\u0026lt;reddit_meatspace.Meatspace object at 0x7fe10a4f6110\\u0026gt;\\n\\u0026lt;reddit_meatspace.Meatspace object at 0x7fe10a4f6110\\u0026gt;\\n\\u0026lt;reddit_about.About object at 0x7fe10a4c84d0\\u0026gt;\\n\\u0026lt;reddit_about.About object at 0x7fe10a4c84d0\\u0026gt;\\n\\u0026lt;reddit_liveupdate.LiveUpdate object at 0x7fe10a4d1090\\u0026gt;\\n\\u0026lt;reddit_liveupdate.LiveUpdate object at 0x7fe10a4d1090\\u0026gt;\\n\\u0026lt;reddit_adzerk.Adzerk object at 0x7fe10a4d1a50\\u0026gt;\\nTraceback (most recent call last):\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI ran out of time to dig into figuring out what the adzerk plugin is expecting. I got as far as ye olde \\u003Ccode\\u003Eexample.ini\\u003C/code\\u003E and from the history, saw these somewhat-recent ad-related changes:\\u003C/p\\u003E\\n\\n\\u003Cul\\u003E\\n\\u003Cli\\u003E\\u003Ca href=\\\"https://github.com/reddit/reddit/commit/f9342bab8b78d61c69641e146cca686c13af49bc\\\"\\u003Ehttps://github.com/reddit/reddit/commit/f9342bab8b78d61c69641e146cca686c13af49bc\\u003C/a\\u003E\\u003C/li\\u003E\\n\\u003Cli\\u003E\\u003Ca href=\\\"https://github.com/reddit/reddit/commit/d067ce530f867a213cd911572183a11d063673cf\\\"\\u003Ehttps://github.com/reddit/reddit/commit/d067ce530f867a213cd911572183a11d063673cf\\u003C/a\\u003E\\u003C/li\\u003E\\n\\u003Cli\\u003E\\u003Ca href=\\\"https://github.com/reddit/reddit/commit/c66c3942c5151091e083d7b06e7972d270c79893\\\"\\u003Ehttps://github.com/reddit/reddit/commit/c66c3942c5151091e083d7b06e7972d270c79893\\u003C/a\\u003E\\u003C/li\\u003E\\n\\u003C/ul\\u003E\\n\\n\\u003Cp\\u003EI tried updating \\u003Ccode\\u003Eadzerk_url = http://example.com\\u003C/code\\u003E in the \\u003Ccode\\u003Edevelopment.update\\u003C/code\\u003E file, but running \\u003Ccode\\u003Emake\\u003C/code\\u003E currently fails in that directory:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ECompiling reddit-init.js...(node) util.debug is deprecated. Use console.error instead.\\nDEBUG: Error\\n    at new JS_Parse_Error (/usr/lib/nodejs/uglify-js/parse-js.js:263:18)\\n    at js_error (/usr/lib/nodejs/uglify-js/parse-js.js:271:11)\\n    at croak (/usr/lib/nodejs/uglify-js/parse-js.js:733:9)\\n    at token_error (/usr/lib/nodejs/uglify-js/parse-js.js:740:9)\\n    at unexpected (/usr/lib/nodejs/uglify-js/parse-js.js:746:9)\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:827:17\\n    at block_ (/usr/lib/nodejs/uglify-js/parse-js.js:1003:20)\\n    at try_ (/usr/lib/nodejs/uglify-js/parse-js.js:1036:20)\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:876:24\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:1297:20\\nDEBUG: JS_Parse_Error {\\n  message: \\u0026#39;Unexpected token: punc ())\\u0026#39;,\\n  line: 18064,\\n  col: 6,\\n  pos: 531251,\\n  stack: \\u0026#39;Error\\\\n    at new JS_Parse_Error (/usr/lib/nodejs/uglify-js/parse-js.js:263:18)\\\\n    at js_error (/usr/lib/nodejs/uglify-js/parse-js.js:271:11)\\\\n    at croak (/usr/lib/nodejs/uglify-js/parse-js.js:733:9)\\\\n    at token_error (/usr/lib/nodejs/uglify-js/parse-js.js:740:9)\\\\n    at unexpected (/usr/lib/nodejs/uglify-js/parse-js.js:746:9)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:827:17\\\\n    at block_ (/usr/lib/nodejs/uglify-js/parse-js.js:1003:20)\\\\n    at try_ (/usr/lib/nodejs/uglify-js/parse-js.js:1036:20)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:876:24\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:1297:20\\u0026#39; }\\nDEBUG: {\\u0026quot;message\\u0026quot;:\\u0026quot;Unexpected token: punc ())\\u0026quot;,\\u0026quot;line\\u0026quot;:18064,\\u0026quot;col\\u0026quot;:6,\\u0026quot;pos\\u0026quot;:531251,\\u0026quot;stack\\u0026quot;:\\u0026quot;Error\\\\n    at new JS_Parse_Error (/usr/lib/nodejs/uglify-js/parse-js.js:263:18)\\\\n    at js_error (/usr/lib/nodejs/uglify-js/parse-js.js:271:11)\\\\n    at croak (/usr/lib/nodejs/uglify-js/parse-js.js:733:9)\\\\n    at token_error (/usr/lib/nodejs/uglify-js/parse-js.js:740:9)\\\\n    at unexpected (/usr/lib/nodejs/uglify-js/parse-js.js:746:9)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:827:17\\\\n    at block_ (/usr/lib/nodejs/uglify-js/parse-js.js:1003:20)\\\\n    at try_ (/usr/lib/nodejs/uglify-js/parse-js.js:1036:20)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:876:24\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:1297:20\\u0026quot;}\\nTraceback (most recent call last):\\n  File \\u0026quot;r2/lib/js.py\\u0026quot;, line 800, in \\u0026lt;module\\u0026gt;\\n    commands[sys.argv[1]](*sys.argv[2:])\\n  File \\u0026quot;r2/lib/js.py\\u0026quot;, line 764, in wrapped\\n    fn(*args)\\n  File \\u0026quot;r2/lib/js.py\\u0026quot;, line 796, in build_module\\n    module[name].build(minifier)\\n  File \\u0026quot;r2/lib/js.py\\u0026quot;, line 373, in build\\n    Module.build(self, minifier)\\n  File \\u0026quot;r2/lib/js.py\\u0026quot;, line 182, in build\\n    minifier.compile(source, out)\\n  File \\u0026quot;r2/lib/js.py\\u0026quot;, line 61, in compile\\n    raise subprocess.CalledProcessError(process.returncode, \\u0026quot;uglifyjs\\u0026quot;)\\nsubprocess.CalledProcessError: Command \\u0026#39;uglifyjs\\u0026#39; returned non-zero exit status 1\\nmake: *** [/home/vagrant/src/reddit/r2/build/public/static/reddit-init.ar.js] Error 1\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnd then it\\u0026#39;s now. Out of time! Hopefully this helps debug new dev experience a little. I could be doing something egregiously incorrect, or there could be an adzerk config bug.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEDIT: also, \\u003Ccode\\u003Epaster serve --reload example.ini http_port=8081\\u003C/code\\u003E \\u003Cem\\u003Edoes\\u003C/em\\u003E work, just not the daemon modes.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"When I checked out the reddit code, it was a delight to see a `Vagrantfile` in the root. I did the typical `vagrant up` (and then waited a long time) and then read the docs to see what I should see. I `vagrant ssh`'d in and tried to `curl -v 'http://reddit.local'` and got a 503 in return. I figured this is because I didn't populate with demo data like `install/done.sh` suggests, so i ran `reddit-run scripts/inject_test_data.py -c 'inject_test_data()'` That failed with a neat, inscruitable traceback:\\n\\n    Traceback (most recent call last):\\n      File \\\"/usr/bin/paster\\\", line 4, in \\u003Cmodule\\u003E\\n        command.run()\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/script/command.py\\\", line 104, in run\\n        invoke(command, command_name, options, args[1:])\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/script/command.py\\\", line 143, in invoke\\n        exit_code = runner.run(args)\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/script/command.py\\\", line 238, in run\\n        result = self.command()\\n      File \\\"/home/vagrant/src/reddit/r2/r2/commands.py\\\", line 68, in command\\n        config_name, relative_to=here_dir, global_conf=global_conf)\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\\", line 247, in loadapp\\n        return loadobj(APP, uri, name=name, **kw)\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\\", line 272, in loadobj\\n        return context.create()\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\\", line 710, in create\\n        return self.object_type.invoke(self)\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/deploy/loadwsgi.py\\\", line 146, in invoke\\n        return fix_call(context.object, context.global_conf, **context.local_conf)\\n      File \\\"/usr/lib/python2.7/dist-packages/paste/deploy/util.py\\\", line 55, in fix_call\\n        val = callable(*args, **kw)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/__init__.py\\\", line 41, in make_app\\n        return real_make_app(*args, **kwargs)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/config/middleware.py\\\", line 513, in make_app\\n        config = load_environment(global_conf, app_conf)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/config/environment.py\\\", line 78, in load_environment\\n        g.plugins.load_plugins(config)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/lib/plugin.py\\\", line 147, in load_plugins\\n        g.config.add_spec(plugin.config)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/lib/configparse.py\\\", line 116, in add_spec\\n        self._update_values(new_keys)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/lib/configparse.py\\\", line 126, in _update_values\\n        value = parser(value, key)\\n      File \\\"/home/vagrant/src/reddit/r2/r2/lib/configparse.py\\\", line 35, in int\\n        return int(v)\\n    ValueError: invalid literal for int() with base 10: ''\\n\\nThat traceback is also littering the `/var/log/syslog` file; it looks like nothing can run, because the configs are unreadable from init.\\n\\nThe lowest part in the traceback that makes sense to hack around is in `r2/r2/lib/plugin.py` - adding a print statement to tell which plugin fails init shows:\\n\\n    \\u003Creddit_meatspace.Meatspace object at 0x7fe10a4f6110\\u003E\\n    \\u003Creddit_meatspace.Meatspace object at 0x7fe10a4f6110\\u003E\\n    \\u003Creddit_about.About object at 0x7fe10a4c84d0\\u003E\\n    \\u003Creddit_about.About object at 0x7fe10a4c84d0\\u003E\\n    \\u003Creddit_liveupdate.LiveUpdate object at 0x7fe10a4d1090\\u003E\\n    \\u003Creddit_liveupdate.LiveUpdate object at 0x7fe10a4d1090\\u003E\\n    \\u003Creddit_adzerk.Adzerk object at 0x7fe10a4d1a50\\u003E\\n    Traceback (most recent call last):\\n\\nI ran out of time to dig into figuring out what the adzerk plugin is expecting. I got as far as ye olde `example.ini` and from the history, saw these somewhat-recent ad-related changes:\\n\\n* https://github.com/reddit/reddit/commit/f9342bab8b78d61c69641e146cca686c13af49bc\\n* https://github.com/reddit/reddit/commit/d067ce530f867a213cd911572183a11d063673cf\\n* https://github.com/reddit/reddit/commit/c66c3942c5151091e083d7b06e7972d270c79893\\n\\nI tried updating `adzerk_url = http://example.com` in the `development.update` file, but running `make` currently fails in that directory:\\n\\n    Compiling reddit-init.js...(node) util.debug is deprecated. Use console.error instead.\\n    DEBUG: Error\\n        at new JS_Parse_Error (/usr/lib/nodejs/uglify-js/parse-js.js:263:18)\\n        at js_error (/usr/lib/nodejs/uglify-js/parse-js.js:271:11)\\n        at croak (/usr/lib/nodejs/uglify-js/parse-js.js:733:9)\\n        at token_error (/usr/lib/nodejs/uglify-js/parse-js.js:740:9)\\n        at unexpected (/usr/lib/nodejs/uglify-js/parse-js.js:746:9)\\n        at /usr/lib/nodejs/uglify-js/parse-js.js:827:17\\n        at block_ (/usr/lib/nodejs/uglify-js/parse-js.js:1003:20)\\n        at try_ (/usr/lib/nodejs/uglify-js/parse-js.js:1036:20)\\n        at /usr/lib/nodejs/uglify-js/parse-js.js:876:24\\n        at /usr/lib/nodejs/uglify-js/parse-js.js:1297:20\\n    DEBUG: JS_Parse_Error {\\n      message: 'Unexpected token: punc ())',\\n      line: 18064,\\n      col: 6,\\n      pos: 531251,\\n      stack: 'Error\\\\n    at new JS_Parse_Error (/usr/lib/nodejs/uglify-js/parse-js.js:263:18)\\\\n    at js_error (/usr/lib/nodejs/uglify-js/parse-js.js:271:11)\\\\n    at croak (/usr/lib/nodejs/uglify-js/parse-js.js:733:9)\\\\n    at token_error (/usr/lib/nodejs/uglify-js/parse-js.js:740:9)\\\\n    at unexpected (/usr/lib/nodejs/uglify-js/parse-js.js:746:9)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:827:17\\\\n    at block_ (/usr/lib/nodejs/uglify-js/parse-js.js:1003:20)\\\\n    at try_ (/usr/lib/nodejs/uglify-js/parse-js.js:1036:20)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:876:24\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:1297:20' }\\n    DEBUG: {\\\"message\\\":\\\"Unexpected token: punc ())\\\",\\\"line\\\":18064,\\\"col\\\":6,\\\"pos\\\":531251,\\\"stack\\\":\\\"Error\\\\n    at new JS_Parse_Error (/usr/lib/nodejs/uglify-js/parse-js.js:263:18)\\\\n    at js_error (/usr/lib/nodejs/uglify-js/parse-js.js:271:11)\\\\n    at croak (/usr/lib/nodejs/uglify-js/parse-js.js:733:9)\\\\n    at token_error (/usr/lib/nodejs/uglify-js/parse-js.js:740:9)\\\\n    at unexpected (/usr/lib/nodejs/uglify-js/parse-js.js:746:9)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:827:17\\\\n    at block_ (/usr/lib/nodejs/uglify-js/parse-js.js:1003:20)\\\\n    at try_ (/usr/lib/nodejs/uglify-js/parse-js.js:1036:20)\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:876:24\\\\n    at /usr/lib/nodejs/uglify-js/parse-js.js:1297:20\\\"}\\n    Traceback (most recent call last):\\n      File \\\"r2/lib/js.py\\\", line 800, in \\u003Cmodule\\u003E\\n        commands[sys.argv[1]](*sys.argv[2:])\\n      File \\\"r2/lib/js.py\\\", line 764, in wrapped\\n        fn(*args)\\n      File \\\"r2/lib/js.py\\\", line 796, in build_module\\n        module[name].build(minifier)\\n      File \\\"r2/lib/js.py\\\", line 373, in build\\n        Module.build(self, minifier)\\n      File \\\"r2/lib/js.py\\\", line 182, in build\\n        minifier.compile(source, out)\\n      File \\\"r2/lib/js.py\\\", line 61, in compile\\n        raise subprocess.CalledProcessError(process.returncode, \\\"uglifyjs\\\")\\n    subprocess.CalledProcessError: Command 'uglifyjs' returned non-zero exit status 1\\n    make: *** [/home/vagrant/src/reddit/r2/build/public/static/reddit-init.ar.js] Error 1\\n\\n\\nAnd then it's now. Out of time! Hopefully this helps debug new dev experience a little. I could be doing something egregiously incorrect, or there could be an adzerk config bug.\\n\\nEDIT: also, `paster serve --reload example.ini http_port=8081` *does* work, just not the daemon modes.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ndp3t\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"PoppiestPoppy\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1465517769.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ndp3t/clean_checkout_vagrant_build_appears_broken/\", \"locked\": false, \"name\": \"t3_4ndp3t\", \"created\": 1465545662.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ndp3t/clean_checkout_vagrant_build_appears_broken/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Clean checkout vagrant build appears broken (adzerk config?)\", \"created_utc\": 1465516862.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m currently working on an open source Reddit API wrapper and was wondering whether copy the official documentation from \\u003Ca href=\\\"https://github.com/reddit/reddit/wiki\\\"\\u003Ehttps://github.com/reddit/reddit/wiki\\u003C/a\\u003E, \\u003Ca href=\\\"https://www.reddit.com/dev/api\\\"\\u003Ehttps://www.reddit.com/dev/api\\u003C/a\\u003E and potentially anywhere else I find documentation from Reddit corp. will be allowed or does the Reddit license prevent me from doing this?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm currently working on an open source Reddit API wrapper and was wondering whether copy the official documentation from [https://github.com/reddit/reddit/wiki](https://github.com/reddit/reddit/wiki), [https://www.reddit.com/dev/api](https://www.reddit.com/dev/api) and potentially anywhere else I find documentation from Reddit corp. will be allowed or does the Reddit license prevent me from doing this?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ndgu9\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kingjulien1\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ndgu9/copying_api_documentation/\", \"locked\": false, \"name\": \"t3_4ndgu9\", \"created\": 1465542362.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ndgu9/copying_api_documentation/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Copying API documentation\", \"created_utc\": 1465513562.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI was hitting some obstacles with RedditSharp, so I started exploring different options. Apparently just going to \\u003Ca href=\\\"http://api.reddit.com\\\"\\u003Ehttp://api.reddit.com\\u003C/a\\u003E returns straight JSON, which I thought was pretty neat.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m looking at ways to query comments, and I\\u0026#39;ve seen the following address, which works fine:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"http://api.reddit.com/r/redditdev/comments?limit=100\\\"\\u003Ehttp://api.reddit.com/r/redditdev/comments?limit=100\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI would love to know what other query strings (if any) are available for this approach. If it\\u0026#39;s in the documentation somewhere, I couldn\\u0026#39;t quite find it, so any help is appreciated.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I was hitting some obstacles with RedditSharp, so I started exploring different options. Apparently just going to http://api.reddit.com returns straight JSON, which I thought was pretty neat.\\n\\nI'm looking at ways to query comments, and I've seen the following address, which works fine:\\n\\n  http://api.reddit.com/r/redditdev/comments?limit=100\\n\\nI would love to know what other query strings (if any) are available for this approach. If it's in the documentation somewhere, I couldn't quite find it, so any help is appreciated.\\n\\nThanks!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4n7ea7\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"schmaleo505\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4n7ea7/apiredditcom_query_strings/\", \"locked\": false, \"name\": \"t3_4n7ea7\", \"created\": 1465449209.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4n7ea7/apiredditcom_query_strings/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"api.reddit.com Query Strings\", \"created_utc\": 1465420409.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi ... I\\u0026#39;m trying to setup a reddit clone ... on a Windows 7 machine, using VirtualBox running Ubuntu 14.04 ...\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHappily get through the install (using the install script) ... but I can\\u0026#39;t get anything pointing my browser at reddit.local or localhost or 127.0.0.1 ... I did make the change in my etc/hosts to point reddit.local at 127.0.0.1 ... but still no dice. I haven\\u0026#39;t changed any config files ... so I\\u0026#39;m assuming the port is still set to 80 ... \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m a bit of an Ubuntu noob ... and I don\\u0026#39;t really see how the clone is running ... I don\\u0026#39;t see any processes running associated with the reddit install ... I can list the cron jobs, but as I understand it those are scheduled jobs ... what\\u0026#39;s the process\\\\job\\\\whatever that\\u0026#39;s dealing with the incoming http requests? Because to me it seems like the server isn\\u0026#39;t actually running, which is why I can\\u0026#39;t see anything ... but like I say, I\\u0026#39;m an Ubuntu noob!!\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAny help and\\\\or insight would be awesome :)\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi ... I'm trying to setup a reddit clone ... on a Windows 7 machine, using VirtualBox running Ubuntu 14.04 ...\\n\\n\\nHappily get through the install (using the install script) ... but I can't get anything pointing my browser at reddit.local or localhost or 127.0.0.1 ... I did make the change in my etc/hosts to point reddit.local at 127.0.0.1 ... but still no dice. I haven't changed any config files ... so I'm assuming the port is still set to 80 ... \\n\\nI'm a bit of an Ubuntu noob ... and I don't really see how the clone is running ... I don't see any processes running associated with the reddit install ... I can list the cron jobs, but as I understand it those are scheduled jobs ... what's the process\\\\job\\\\whatever that's dealing with the incoming http requests? Because to me it seems like the server isn't actually running, which is why I can't see anything ... but like I say, I'm an Ubuntu noob!!\\n\\nAny help and\\\\or insight would be awesome :)\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4n1f5q\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"bigolefake\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4n1f5q/trouble_setting_up_reddit_clone/\", \"locked\": false, \"name\": \"t3_4n1f5q\", \"created\": 1465363323.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4n1f5q/trouble_setting_up_reddit_clone/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Trouble setting up Reddit clone\", \"created_utc\": 1465334523.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ELooking to use praw to search a subreddit for posts where the title contains keywords, and the time is between a certain period. I seem to only be able to get one or the other. I\\u0026#39;m not new to programming, but new to cloudsearch syntax and the reddit API.\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er = praw.Reddit(user_agent=user_agent)\\n\\nstart_dt = datetime.datetime(year=2015, month=10, day=9, hour=20).timetuple()\\nend_dt = datetime.datetime(year=2015, month=10, day=10, hour=0).timetuple()\\n\\ns_t = time.mktime(start_dt)\\ne_t = time.mktime(end_dt)\\n\\n#below is something like what I want\\n#search_str = \\u0026quot;title contains:\\u0026#39;XXXXX\\u0026#39; and (timestamp:\\u0026quot; + str(int(s_t)) + \\u0026quot;..\\u0026quot; + str(int(e_t)) + \\u0026quot;)\\u0026quot;\\n\\n#below is what works for just the timestamp\\nsearch_str = \\u0026quot;timestamp:\\u0026quot; + str(int(s_t)) + \\u0026quot;..\\u0026quot; + str(int(e_t))\\n\\nthread_array = r.search(search_str, subreddit=\\u0026quot;YYYYY\\u0026quot;, limit=1000, syntax=\\u0026quot;cloudsearch\\u0026quot;)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAny help would be greatly appreciated!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Looking to use praw to search a subreddit for posts where the title contains keywords, and the time is between a certain period. I seem to only be able to get one or the other. I'm not new to programming, but new to cloudsearch syntax and the reddit API.\\n\\n    r = praw.Reddit(user_agent=user_agent)\\n\\n    start_dt = datetime.datetime(year=2015, month=10, day=9, hour=20).timetuple()\\n    end_dt = datetime.datetime(year=2015, month=10, day=10, hour=0).timetuple()\\n\\n    s_t = time.mktime(start_dt)\\n    e_t = time.mktime(end_dt)\\n\\n    #below is something like what I want\\n    #search_str = \\\"title contains:'XXXXX' and (timestamp:\\\" + str(int(s_t)) + \\\"..\\\" + str(int(e_t)) + \\\")\\\"\\n\\n    #below is what works for just the timestamp\\n    search_str = \\\"timestamp:\\\" + str(int(s_t)) + \\\"..\\\" + str(int(e_t))\\n\\n    thread_array = r.search(search_str, subreddit=\\\"YYYYY\\\", limit=1000, syntax=\\\"cloudsearch\\\")\\n\\nAny help would be greatly appreciated!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mzwga\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"schmaleo505\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mzwga/praw_search_title_keywords_and_timestamp/\", \"locked\": false, \"name\": \"t3_4mzwga\", \"created\": 1465345953.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mzwga/praw_search_title_keywords_and_timestamp/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW Search title keywords and timestamp\", \"created_utc\": 1465317153.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESet up a private reddit for work on an Amazon EC2 instance.  Most things are working and users are making posts, but no comments on posts are appearing.  It will list 2 comments, but then no comments are visible within the thread.  Help?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEDIT:  Thanks to the help of irc user bsimpson, I was able to get this working.  I had installed reddit from the install script, but RabbitMQ was not configured properly and I fixed it by simply following the steps in that section of the install guide. \\u003Ca href=\\\"https://github.com/reddit/reddit/wiki/Install-guide\\\"\\u003Ehttps://github.com/reddit/reddit/wiki/Install-guide\\u003C/a\\u003E \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Set up a private reddit for work on an Amazon EC2 instance.  Most things are working and users are making posts, but no comments on posts are appearing.  It will list 2 comments, but then no comments are visible within the thread.  Help?\\n\\nEDIT:  Thanks to the help of irc user bsimpson, I was able to get this working.  I had installed reddit from the install script, but RabbitMQ was not configured properly and I fixed it by simply following the steps in that section of the install guide. https://github.com/reddit/reddit/wiki/Install-guide \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mzext\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"rvictory1\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1465320636.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mzext/comments_not_appearing_in_my_selfhosted_reddit/\", \"locked\": false, \"name\": \"t3_4mzext\", \"created\": 1465340010.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mzext/comments_not_appearing_in_my_selfhosted_reddit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Comments not appearing in my self-hosted reddit\", \"created_utc\": 1465311210.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"stackoverflow.com\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4my6vh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MatthewMob\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": false, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4my6vh/getting_a_praw_subreddit_object_from_self_text/\", \"locked\": false, \"name\": \"t3_4my6vh\", \"created\": 1465319868.0, \"url\": \"http://stackoverflow.com/questions/37675116/getting-a-praw-subreddit-object-from-self-text-link-to-the-subreddit\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting a PRAW subreddit object from self text link to the subreddit\", \"created_utc\": 1465291068.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWould anyone be so kind as to make some sort of breakdown of all the services that Reddit relies on? AFAIK It uses Python, Cassandra, PostgreSQL, Cron, JSON, and I\\u0026#39;m not sure how these all relate to one another.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Would anyone be so kind as to make some sort of breakdown of all the services that Reddit relies on? AFAIK It uses Python, Cassandra, PostgreSQL, Cron, JSON, and I'm not sure how these all relate to one another.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mwxhf\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"sound_puppy\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mwxhf/i_fought_the_code_and_the_code_won/\", \"locked\": false, \"name\": \"t3_4mwxhf\", \"created\": 1465296751.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mwxhf/i_fought_the_code_and_the_code_won/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"I fought the code and the code won\", \"created_utc\": 1465267951.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m currently working on a bot that checks for revisions to wiki pages (namely mysub/wiki/config/automoderator) and posts those revisions to a Slack channel.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EUsing \\u003Ccode\\u003Ewiki = r.get_wiki_page(\\u0026#39;mysub\\u0026#39;, \\u0026#39;revisions/wikipage\\u0026#39;)\\u003C/code\\u003E works and I am able to parse the json, but when wikipage is moderator only, I get an error that looks like this:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Eraise OAuthInsufficientScope(\\u0026#39;insufficient_scope\\u0026#39;, response.url)\\npraw.errors.OAuthInsufficientScope: insufficient_scope on url https://oauth.reddit.com/r/mysub/wiki/revisions/config/automoderator.json\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve given the bot wikiedit, wikiread, and modwiki scopes, and the account I\\u0026#39;m using does have moderator wiki permissions on the subreddit.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm currently working on a bot that checks for revisions to wiki pages (namely mysub/wiki/config/automoderator) and posts those revisions to a Slack channel.\\n\\nUsing `wiki = r.get_wiki_page('mysub', 'revisions/wikipage')` works and I am able to parse the json, but when wikipage is moderator only, I get an error that looks like this:\\n\\n    raise OAuthInsufficientScope('insufficient_scope', response.url)\\n    praw.errors.OAuthInsufficientScope: insufficient_scope on url https://oauth.reddit.com/r/mysub/wiki/revisions/config/automoderator.json\\n\\nI've given the bot wikiedit, wikiread, and modwiki scopes, and the account I'm using does have moderator wiki permissions on the subreddit.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mvdqa\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hizinfiz\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mvdqa/insufficientscope_error_when_attempting_to_read/\", \"locked\": false, \"name\": \"t3_4mvdqa\", \"created\": 1465277119.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mvdqa/insufficientscope_error_when_attempting_to_read/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"InsufficientScope error when attempting to read mod-only wiki pages\", \"created_utc\": 1465248319.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI want to pull only text post via API. How do format my json url?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I want to pull only text post via API. How do format my json url?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mtq32\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"mutuku2030\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mtq32/how_to_list_only_text_reddits_via_api/\", \"locked\": false, \"name\": \"t3_4mtq32\", \"created\": 1465258326.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mtq32/how_to_list_only_text_reddits_via_api/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"how to list only text reddits via API\", \"created_utc\": 1465229526.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EForgive me if this is the wrong place to post this, but I need help making my own reddit hack.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI installed reddit on ubuntu 14.04 using this guide (\\u003Ca href=\\\"https://github.com/reddit/reddit/wiki/Install-guide\\\"\\u003Ehttps://github.com/reddit/reddit/wiki/Install-guide\\u003C/a\\u003E) and everything seemed to install correctly. I even was able to populate the DB with test data. But it does not seem like it\\u0026#39;s running as I cannot access reddit.local or anything on 127.0.0.1. I\\u0026#39;ve used apache on windows, so this is slightly new to me. Did the install script install apache or nginx? Also, what are the login details for the server and Cassandra? It doesn\\u0026#39;t seem like it\\u0026#39;s running any server when I look at the process manager, but python looks like it is. Halp?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Forgive me if this is the wrong place to post this, but I need help making my own reddit hack.\\n\\nI installed reddit on ubuntu 14.04 using this guide (https://github.com/reddit/reddit/wiki/Install-guide) and everything seemed to install correctly. I even was able to populate the DB with test data. But it does not seem like it's running as I cannot access reddit.local or anything on 127.0.0.1. I've used apache on windows, so this is slightly new to me. Did the install script install apache or nginx? Also, what are the login details for the server and Cassandra? It doesn't seem like it's running any server when I look at the process manager, but python looks like it is. Halp?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mn44c\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"sound_puppy\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mn44c/help_configuring_fresh_installation/\", \"locked\": false, \"name\": \"t3_4mn44c\", \"created\": 1465157396.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mn44c/help_configuring_fresh_installation/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help configuring fresh installation\", \"created_utc\": 1465128596.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003E\\u003Cstrong\\u003EEDIT:\\u003C/strong\\u003E Solved, api only lets you use https\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m trying to follow this wiki article here: \\u003Ca href=\\\"https://github.com/reddit/reddit/wiki/OAuth2-Quick-Start-Example\\\"\\u003Ehttps://github.com/reddit/reddit/wiki/OAuth2-Quick-Start-Example\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI tried getting the access token via curl and it worked fine, I got an access token. I used this curl to verify the headers and post body \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Ecurl -X POST -d \\u0026#39;grant_type=password\\u0026amp;username=jazzelhawk\\u0026amp;password=pass\\u0026#39; --user \\u0026#39;id:secret\\u0026#39; --user-agent \\u0026#39;linux:test:v1 by /u/Jazzelhawk\\u0026#39; https://httpbin.org/post\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Ewith the response\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E{\\n  \\u0026quot;args\\u0026quot;: {},\\n  \\u0026quot;data\\u0026quot;: \\u0026quot;\\u0026quot;,\\n  \\u0026quot;files\\u0026quot;: {},\\n  \\u0026quot;form\\u0026quot;: {\\n    \\u0026quot;grant_type\\u0026quot;: \\u0026quot;password\\u0026quot;,\\n    \\u0026quot;password\\u0026quot;: \\u0026quot;pass\\u0026quot;,\\n    \\u0026quot;username\\u0026quot;: \\u0026quot;jazzelhawk\\u0026quot;\\n  },\\n  \\u0026quot;headers\\u0026quot;: {\\n    \\u0026quot;Accept\\u0026quot;: \\u0026quot;*/*\\u0026quot;,\\n    \\u0026quot;Authorization\\u0026quot;: \\u0026quot;Basic aWQ6c2VjcmV0\\u0026quot;,\\n    \\u0026quot;Content-Length\\u0026quot;: \\u0026quot;53\\u0026quot;,\\n    \\u0026quot;Content-Type\\u0026quot;: \\u0026quot;application/x-www-form-urlencoded\\u0026quot;,\\n    \\u0026quot;Host\\u0026quot;: \\u0026quot;httpbin.org\\u0026quot;,\\n    \\u0026quot;User-Agent\\u0026quot;: \\u0026quot;linux:test:v1 by /u/Jazzelhawk\\u0026quot;\\n  },\\n  \\u0026quot;json\\u0026quot;: null,\\n  \\u0026quot;origin\\u0026quot;: \\u0026quot;***.***.***.***\\u0026quot;,\\n  \\u0026quot;url\\u0026quot;: \\u0026quot;https://httpbin.org/post\\u0026quot;\\n}    \\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003ETrying this lua script\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Elocal id = \\u0026quot;id\\u0026quot;\\nlocal secret = \\u0026quot;secret\\u0026quot;\\n\\nlocal http = require( \\u0026quot;socket.http\\u0026quot; )\\nlocal ltn12 = require( \\u0026quot;ltn12\\u0026quot; )\\nlocal mime = require( \\u0026quot;mime\\u0026quot; )\\n\\nlocal request = \\u0026quot;grant_type=password\\u0026amp;username=jazzelhawk\\u0026amp;password=pass\\u0026quot;\\nlocal headers = {\\n    [ \\u0026quot;User-Agent\\u0026quot; ] = \\u0026quot;windows:test:v1 by /u/Jazzelhawk\\u0026quot;,\\n    [ \\u0026quot;content-type\\u0026quot; ] = \\u0026quot;application/x-www-form-urlencoded\\u0026quot;,\\n    [ \\u0026quot;content-length\\u0026quot; ] = tostring( #request ),\\n    [ \\u0026quot;Authorization\\u0026quot; ] = \\u0026quot;Basic \\u0026quot; .. mime.b64( id .. \\u0026quot;:\\u0026quot; .. secret ),\\n    [ \\u0026quot;Accept\\u0026quot; ] = \\u0026quot;*/*\\u0026quot;\\n}\\n\\nlocal response = {}\\n\\nlocal body, code, h = http.request { \\n    method = \\u0026quot;POST\\u0026quot;,\\n    url = \\u0026quot;https://httpbin.org/post\\u0026quot;, \\n    sink = ltn12.sink.table( response ), \\n    headers = headers,\\n    source = ltn12.source.string( request ) \\n}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Egets the response\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E{\\n  \\u0026quot;args\\u0026quot;: {}, \\n  \\u0026quot;data\\u0026quot;: \\u0026quot;\\u0026quot;, \\n  \\u0026quot;files\\u0026quot;: {}, \\n  \\u0026quot;form\\u0026quot;: {\\n    \\u0026quot;grant_type\\u0026quot;: \\u0026quot;password\\u0026quot;, \\n    \\u0026quot;password\\u0026quot;: \\u0026quot;pass\\u0026quot;, \\n    \\u0026quot;username\\u0026quot;: \\u0026quot;jazzelhawk\\u0026quot;\\n  }, \\n  \\u0026quot;headers\\u0026quot;: {\\n    \\u0026quot;Accept\\u0026quot;: \\u0026quot;*/*\\u0026quot;, \\n    \\u0026quot;Authorization\\u0026quot;: \\u0026quot;Basic aWQ6c2VjcmV0\\u0026quot;, \\n    \\u0026quot;Content-Length\\u0026quot;: \\u0026quot;53\\u0026quot;, \\n    \\u0026quot;Content-Type\\u0026quot;: \\u0026quot;application/x-www-form-urlencoded\\u0026quot;, \\n    \\u0026quot;Host\\u0026quot;: \\u0026quot;httpbin.org\\u0026quot;, \\n    \\u0026quot;User-Agent\\u0026quot;: \\u0026quot;windows:test:v1 by /u/Jazzelhawk\\u0026quot;\\n  }, \\n  \\u0026quot;json\\u0026quot;: null, \\n  \\u0026quot;origin\\u0026quot;: \\u0026quot;***.***.***.***\\u0026quot;, \\n  \\u0026quot;url\\u0026quot;: \\u0026quot;http://httpbin.org/post\\u0026quot;\\n}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThe headers and post bodies are pretty much exactly the same yet with the lua script a 403 response is returned when using the correct information and url \\u003Ca href=\\\"https://www.reddit.com/api/v1/access_token\\\"\\u003Ehttps://www.reddit.com/api/v1/access_token\\u003C/a\\u003E. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe response headers when requesting reddit are\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E{\\n  [x-content-type-options] =\\u0026gt; \\u0026quot;nosniff\\u0026quot;\\n  [x-frame-options] =\\u0026gt; \\u0026quot;SAMEORIGIN\\u0026quot;\\n  [x-ua-compatible] =\\u0026gt; \\u0026quot;IE=edge\\u0026quot;\\n  [date] =\\u0026gt; \\u0026quot;Sun, 05 Jun 2016 11:51:59 GMT\\u0026quot;\\n  [x-xss-protection] =\\u0026gt; \\u0026quot;1; mode=block\\u0026quot;\\n  [connection] =\\u0026gt; \\u0026quot;close\\u0026quot;\\n  [content-type] =\\u0026gt; \\u0026quot;application/json; charset=UTF-8\\u0026quot;\\n  [set-cookie] =\\u0026gt; \\u0026quot;__cfduid=x; expires=Mon, 05-Jun-17 11:51:59 GMT; path=/; domain=.reddit.com; HttpOnly, loid=x; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Tue, 05-Jun-2018 11:51:59 GMT; secure, loidcreated=2016-06-05T11%3A51%3A59.635Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Tue, 05-Jun-2018 11:51:59 GMT; secure\\u0026quot;\\n  [cache-control] =\\u0026gt; \\u0026quot;max-age=0, must-revalidate\\u0026quot;\\n  [server] =\\u0026gt; \\u0026quot;cloudflare-nginx\\u0026quot;\\n  [content-length] =\\u0026gt; \\u0026quot;14\\u0026quot;\\n  [x-moose] =\\u0026gt; \\u0026quot;majestic\\u0026quot;\\n  [cf-ray] =\\u0026gt; \\u0026quot;2ae36a74e112146d-AMS\\u0026quot;\\n}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAny help? Thanks\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cstrong\\u003EEDIT:\\u003C/strong\\u003E I think this has something to do with luasocket not using https.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cstrong\\u003EEDIT2:\\u003C/strong\\u003E Yep, turns out the api doesn\\u0026#39;t work unless you use https\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"**EDIT:** Solved, api only lets you use https\\n\\nI'm trying to follow this wiki article here: https://github.com/reddit/reddit/wiki/OAuth2-Quick-Start-Example\\n\\nI tried getting the access token via curl and it worked fine, I got an access token. I used this curl to verify the headers and post body \\n\\n    curl -X POST -d 'grant_type=password\\u0026username=jazzelhawk\\u0026password=pass' --user 'id:secret' --user-agent 'linux:test:v1 by /u/Jazzelhawk' https://httpbin.org/post\\n\\nwith the response\\n\\n    {\\n      \\\"args\\\": {},\\n      \\\"data\\\": \\\"\\\",\\n      \\\"files\\\": {},\\n      \\\"form\\\": {\\n        \\\"grant_type\\\": \\\"password\\\",\\n        \\\"password\\\": \\\"pass\\\",\\n        \\\"username\\\": \\\"jazzelhawk\\\"\\n      },\\n      \\\"headers\\\": {\\n        \\\"Accept\\\": \\\"*/*\\\",\\n        \\\"Authorization\\\": \\\"Basic aWQ6c2VjcmV0\\\",\\n        \\\"Content-Length\\\": \\\"53\\\",\\n        \\\"Content-Type\\\": \\\"application/x-www-form-urlencoded\\\",\\n        \\\"Host\\\": \\\"httpbin.org\\\",\\n        \\\"User-Agent\\\": \\\"linux:test:v1 by /u/Jazzelhawk\\\"\\n      },\\n      \\\"json\\\": null,\\n      \\\"origin\\\": \\\"***.***.***.***\\\",\\n      \\\"url\\\": \\\"https://httpbin.org/post\\\"\\n    }    \\n\\n\\nTrying this lua script\\n\\n    local id = \\\"id\\\"\\n    local secret = \\\"secret\\\"\\n    \\n    local http = require( \\\"socket.http\\\" )\\n    local ltn12 = require( \\\"ltn12\\\" )\\n    local mime = require( \\\"mime\\\" )\\n    \\n    local request = \\\"grant_type=password\\u0026username=jazzelhawk\\u0026password=pass\\\"\\n    local headers = {\\n    \\t[ \\\"User-Agent\\\" ] = \\\"windows:test:v1 by /u/Jazzelhawk\\\",\\n    \\t[ \\\"content-type\\\" ] = \\\"application/x-www-form-urlencoded\\\",\\n    \\t[ \\\"content-length\\\" ] = tostring( #request ),\\n    \\t[ \\\"Authorization\\\" ] = \\\"Basic \\\" .. mime.b64( id .. \\\":\\\" .. secret ),\\n    \\t[ \\\"Accept\\\" ] = \\\"*/*\\\"\\n    }\\n    \\n    local response = {}\\n    \\n    local body, code, h = http.request { \\n    \\tmethod = \\\"POST\\\",\\n    \\turl = \\\"https://httpbin.org/post\\\", \\n    \\tsink = ltn12.sink.table( response ), \\n    \\theaders = headers,\\n    \\tsource = ltn12.source.string( request ) \\n    }\\n\\ngets the response\\n\\n    {\\n      \\\"args\\\": {}, \\n      \\\"data\\\": \\\"\\\", \\n      \\\"files\\\": {}, \\n      \\\"form\\\": {\\n        \\\"grant_type\\\": \\\"password\\\", \\n        \\\"password\\\": \\\"pass\\\", \\n        \\\"username\\\": \\\"jazzelhawk\\\"\\n      }, \\n      \\\"headers\\\": {\\n        \\\"Accept\\\": \\\"*/*\\\", \\n        \\\"Authorization\\\": \\\"Basic aWQ6c2VjcmV0\\\", \\n        \\\"Content-Length\\\": \\\"53\\\", \\n        \\\"Content-Type\\\": \\\"application/x-www-form-urlencoded\\\", \\n        \\\"Host\\\": \\\"httpbin.org\\\", \\n        \\\"User-Agent\\\": \\\"windows:test:v1 by /u/Jazzelhawk\\\"\\n      }, \\n      \\\"json\\\": null, \\n      \\\"origin\\\": \\\"***.***.***.***\\\", \\n      \\\"url\\\": \\\"http://httpbin.org/post\\\"\\n    }\\n\\nThe headers and post bodies are pretty much exactly the same yet with the lua script a 403 response is returned when using the correct information and url https://www.reddit.com/api/v1/access_token. \\n\\nThe response headers when requesting reddit are\\n\\n    {\\n      [x-content-type-options] =\\u003E \\\"nosniff\\\"\\n      [x-frame-options] =\\u003E \\\"SAMEORIGIN\\\"\\n      [x-ua-compatible] =\\u003E \\\"IE=edge\\\"\\n      [date] =\\u003E \\\"Sun, 05 Jun 2016 11:51:59 GMT\\\"\\n      [x-xss-protection] =\\u003E \\\"1; mode=block\\\"\\n      [connection] =\\u003E \\\"close\\\"\\n      [content-type] =\\u003E \\\"application/json; charset=UTF-8\\\"\\n      [set-cookie] =\\u003E \\\"__cfduid=x; expires=Mon, 05-Jun-17 11:51:59 GMT; path=/; domain=.reddit.com; HttpOnly, loid=x; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Tue, 05-Jun-2018 11:51:59 GMT; secure, loidcreated=2016-06-05T11%3A51%3A59.635Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Tue, 05-Jun-2018 11:51:59 GMT; secure\\\"\\n      [cache-control] =\\u003E \\\"max-age=0, must-revalidate\\\"\\n      [server] =\\u003E \\\"cloudflare-nginx\\\"\\n      [content-length] =\\u003E \\\"14\\\"\\n      [x-moose] =\\u003E \\\"majestic\\\"\\n      [cf-ray] =\\u003E \\\"2ae36a74e112146d-AMS\\\"\\n    }\\n\\nAny help? Thanks\\n\\n**EDIT:** I think this has something to do with luasocket not using https.\\n\\n**EDIT2:** Yep, turns out the api doesn't work unless you use https\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mn2mu\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"jazzelhawk\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1465164334.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mn2mu/403_response_when_trying_to_get_access_token/\", \"locked\": false, \"name\": \"t3_4mn2mu\", \"created\": 1465156546.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mn2mu/403_response_when_trying_to_get_access_token/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"403 response when trying to get access token\", \"created_utc\": 1465127746.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI want my bot to be able to respond to its keyword deep into comment threads on \\u003Ca href=\\\"/r/All\\\"\\u003E/r/All\\u003C/a\\u003E. How does the !remindme bot always seem to work no matter how deep into the comments I post?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I want my bot to be able to respond to its keyword deep into comment threads on /r/All. How does the !remindme bot always seem to work no matter how deep into the comments I post?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mgz2d\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Xander_The_Great\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 7, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mgz2d/best_way_to_have_a_bot_look_for_its_keyword_deep/\", \"locked\": false, \"name\": \"t3_4mgz2d\", \"created\": 1465046556.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mgz2d/best_way_to_have_a_bot_look_for_its_keyword_deep/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Best way to have a bot look for its keyword deep into comment sections.\", \"created_utc\": 1465017756.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo, I have a Python script that gets all posts from a subreddit and filters them, replying to ones that match certain criteria.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EDoes the API rate limit get requests from PRAW as well as replies?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEdit: My bot code: \\u003Ca href=\\\"http://pastebin.com/qCZp3J1A\\\"\\u003Ehttp://pastebin.com/qCZp3J1A\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So, I have a Python script that gets all posts from a subreddit and filters them, replying to ones that match certain criteria.\\n\\nDoes the API rate limit get requests from PRAW as well as replies?\\n\\nEdit: My bot code: http://pastebin.com/qCZp3J1A\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4mchkd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"SupremeRedditBot\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464955082.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4mchkd/praw_rate_limit/\", \"locked\": false, \"name\": \"t3_4mchkd\", \"created\": 1464983210.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4mchkd/praw_rate_limit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW Rate Limit\", \"created_utc\": 1464954410.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I\\u0026#39;m not quote sure what\\u0026#39;s going on here. \\u003Ca href=\\\"http://pastebin.com/ndyDZcw4\\\"\\u003EHere\\u003C/a\\u003E is the relevant script portion. I can open the URL in my browser and it works as expected. However, when I run the script I don\\u0026#39;t download an image, I download an HTML web page saying\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EPlease enable cookies.\\nError 1010 Ray ID: 2acbbc88xxxxxx \\u2022 2016-06-02 14:53:43 UTC\\nAccess denied\\nWhat happened?\\n\\nThe owner of this website (i.redd.it) has banned your access based on your browser\\u0026#39;s signature (2acbbc88axxxxxxx-xxxx).\\n\\nCloudFlare Ray ID: 2acbbc88xxxxxxx \\u2022 Your IP: 1.2.3.4 \\u2022 Performance \\u0026amp; security by CloudFlare\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003ENot sure what\\u0026#39;s going on here. It looks like CloudFlair checks my browser signature before redirecting me to the image, and if \\u003Cem\\u003Econditions\\u003C/em\\u003E aren\\u0026#39;t met I get the access denied page instead. What are \\u003Cem\\u003Econditions\\u003C/em\\u003E? I tried fucking around with the user-agent, but that didn\\u0026#39;t seem to work. Are there rules to scripting the download of images from i.redd.it that I don\\u0026#39;t know?\\u003C/p\\u003E\\n\\n\\u003Chr/\\u003E\\n\\n\\u003Cp\\u003EEDIT:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHere is some interesting stuff I\\u0026#39;ve found out. \\u003Ca href=\\\"http://pastebin.com/BMV49vvs\\\"\\u003EHere\\u003C/a\\u003E is the script I\\u0026#39;m working with. Findings:\\u003C/p\\u003E\\n\\n\\u003Col\\u003E\\n\\u003Cli\\u003ELine 8 is necessarily. You get 403 when you don\\u0026#39;t change the user-agent. This is probably why I was getting the HTML access denied page instead of the image.\\u003C/li\\u003E\\n\\u003Cli\\u003ELine 9 \\u003Cstrong\\u003Eneeds\\u003C/strong\\u003E the replacement of HTTP with HTTPS. Without the replacement you get a 404. Apparently their redirection is broken. You can see this more easily by just doing \\u0026quot;wget \\u003Ca href=\\\"http://i.redd.it/0583lecdrv0x.jpg\\\"\\u003Ehttp://i.redd.it/0583lecdrv0x.jpg\\u003C/a\\u003E\\u0026quot; which will 404, and \\u0026quot;wget \\u003Ca href=\\\"https://i.redd.it/0583lecdrv0x.jpg\\\"\\u003Ehttps://i.redd.it/0583lecdrv0x.jpg\\u003C/a\\u003E\\u0026quot; which will download the image.\\u003C/li\\u003E\\n\\u003C/ol\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m not sure why those two things are happening, but they are. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I'm not quote sure what's going on here. [Here](http://pastebin.com/ndyDZcw4) is the relevant script portion. I can open the URL in my browser and it works as expected. However, when I run the script I don't download an image, I download an HTML web page saying\\n\\n    Please enable cookies.\\n    Error 1010 Ray ID: 2acbbc88xxxxxx \\u2022 2016-06-02 14:53:43 UTC\\n    Access denied\\n    What happened?\\n\\n    The owner of this website (i.redd.it) has banned your access based on your browser's signature (2acbbc88axxxxxxx-xxxx).\\n\\n    CloudFlare Ray ID: 2acbbc88xxxxxxx \\u2022 Your IP: 1.2.3.4 \\u2022 Performance \\u0026 security by CloudFlare\\n\\nNot sure what's going on here. It looks like CloudFlair checks my browser signature before redirecting me to the image, and if *conditions* aren't met I get the access denied page instead. What are *conditions*? I tried fucking around with the user-agent, but that didn't seem to work. Are there rules to scripting the download of images from i.redd.it that I don't know?\\n\\n-------------------------------------\\n\\nEDIT:\\n\\nHere is some interesting stuff I've found out. [Here](http://pastebin.com/BMV49vvs) is the script I'm working with. Findings:\\n\\n1. Line 8 is necessarily. You get 403 when you don't change the user-agent. This is probably why I was getting the HTML access denied page instead of the image.\\n2. Line 9 **needs** the replacement of HTTP with HTTPS. Without the replacement you get a 404. Apparently their redirection is broken. You can see this more easily by just doing \\\"wget http://i.redd.it/0583lecdrv0x.jpg\\\" which will 404, and \\\"wget https://i.redd.it/0583lecdrv0x.jpg\\\" which will download the image.\\n\\nI'm not sure why those two things are happening, but they are. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m7kxj\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Pandemic21\", \"media\": null, \"score\": 7, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464886999.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m7kxj/whats_up_with_downloading_images_from_ireddit/\", \"locked\": false, \"name\": \"t3_4m7kxj\", \"created\": 1464908610.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m7kxj/whats_up_with_downloading_images_from_ireddit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"What's up with downloading images from i.redd.it?\", \"created_utc\": 1464879810.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 7}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I\\u0026#39;m trying to write a PHP bot for this sub [\\u003Ca href=\\\"/r/codinghelp\\\"\\u003E/r/codinghelp\\u003C/a\\u003E] and a few others, I\\u0026#39;ve tried multiple PHP wrappers, but I haven\\u0026#39;t gotten anywhere.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhat is the best way to connect to the reddit API with PHP, using [Username, Password, ClientID, ClientSecret] without user interaction, so I then have the ability to use the API to search and comment?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I'm trying to write a PHP bot for this sub [/r/codinghelp] and a few others, I've tried multiple PHP wrappers, but I haven't gotten anywhere.\\n\\nWhat is the best way to connect to the reddit API with PHP, using [Username, Password, ClientID, ClientSecret] without user interaction, so I then have the ability to use the API to search and comment?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m79l8\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"SupremeDesigner\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m79l8/xpost_rcodinghelp_php_how_to_connect_to_reddit/\", \"locked\": false, \"name\": \"t3_4m79l8\", \"created\": 1464904642.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m79l8/xpost_rcodinghelp_php_how_to_connect_to_reddit/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[X-Post /r/codinghelp] [PHP] How to connect to reddit API without user interaction?\", \"created_utc\": 1464875842.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo I\\u0026#39;ve been trying to write a bot in PHP.\\nI\\u0026#39;ve been using \\u003Ca href=\\\"https://github.com/jcleblanc/reddit-php-sdk/\\\"\\u003Ehttps://github.com/jcleblanc/reddit-php-sdk/\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAnd I found a couple of things.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhat should the ENDPOINT_OAUTH_REDIRECT be in the config, as the default one gives an error at reddit.com when initializing the script.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow do I make this run as a bot, as I presume currently it redirects to reddit to get a user input to allow permissions?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So I've been trying to write a bot in PHP.\\nI've been using https://github.com/jcleblanc/reddit-php-sdk/\\n\\nAnd I found a couple of things.\\n\\nWhat should the ENDPOINT_OAUTH_REDIRECT be in the config, as the default one gives an error at reddit.com when initializing the script.\\n\\nHow do I make this run as a bot, as I presume currently it redirects to reddit to get a user input to allow permissions?\\n\\nThanks.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m75lm\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"SupremeRedditBot\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 7, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m75lm/php_api_language/\", \"locked\": false, \"name\": \"t3_4m75lm\", \"created\": 1464903088.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m75lm/php_api_language/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PHP API Language\", \"created_utc\": 1464874288.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI know \\u003Ca href=\\\"https://www.reddit.com/r/redditdev/comments/1mpxwa/what_is_the_policy_on_bots_upvoting_posts/\\\"\\u003Ebots aren\\u0026#39;t allowed to vote on reddit\\u003C/a\\u003E but am I allowed to upvote the posts and comments made by my bot? \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI have a bot operating a time capsule scheme over at \\u003Ca href=\\\"/r/DearFuture\\\"\\u003Er/DearFuture\\u003C/a\\u003E and I occasionally upvote the bot\\u0026#39;s submissions with my normal account as a joke. Now I\\u0026#39;ve noticed that the votes sometimes don\\u0026#39;t count and I\\u0026#39;m worried reddit might flag me as a vote manipulator or a spammer. Is the fear justified?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I know [bots aren't allowed to vote on reddit](https://www.reddit.com/r/redditdev/comments/1mpxwa/what_is_the_policy_on_bots_upvoting_posts/) but am I allowed to upvote the posts and comments made by my bot? \\n\\nI have a bot operating a time capsule scheme over at r/DearFuture and I occasionally upvote the bot's submissions with my normal account as a joke. Now I've noticed that the votes sometimes don't count and I'm worried reddit might flag me as a vote manipulator or a spammer. Is the fear justified?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m690q\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Naurgul\", \"media\": null, \"score\": 11, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m690q/can_i_upvote_my_own_bot/\", \"locked\": false, \"name\": \"t3_4m690q\", \"created\": 1464885834.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m690q/can_i_upvote_my_own_bot/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Can I upvote my own bot?\", \"created_utc\": 1464857034.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 11}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EReproduce:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ccode\\u003Ecurl http://i.redd.it/zldsan2mcq0x.jpg\\u003C/code\\u003E\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EHTTP/1.1 404 Not Found\\nDate: Thu, 02 Jun 2016 00:47:36 GMT\\nContent-Type: application/xml\\nConnection: keep-alive\\nSet-Cookie: __cfduid=dcd4dbef859c4e07cea9ca66e29b7cbfa1464828456; expires=Fri, 02-Jun-17 00:47:36 GMT; path=/; domain=.redd.it; HttpOnly\\nx-amz-request-id: 88EF73A7E117A4C4\\nx-amz-id-2: j1HBaojloU3j3E2wYbL0Oex66M6Ay8PPxlp5CFGdcotrtzJWK/ZcZeflR7YlOmtKT53JssIRdmc=\\nCF-Cache-Status: HIT\\nX-Content-Type-Options: nosniff\\nServer: cloudflare-nginx\\nCF-RAY: 2ac6e51bacc407b5-MIA\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThis url works on chrome and gets redirected to \\u003Ccode\\u003EHTTPS\\u003C/code\\u003E: \\u003Ca href=\\\"http://i.redd.it/zldsan2mcq0x.jpg\\\"\\u003Ehttp://i.redd.it/zldsan2mcq0x.jpg\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Reproduce:\\n\\n`curl http://i.redd.it/zldsan2mcq0x.jpg`\\n\\n    HTTP/1.1 404 Not Found\\n    Date: Thu, 02 Jun 2016 00:47:36 GMT\\n    Content-Type: application/xml\\n    Connection: keep-alive\\n    Set-Cookie: __cfduid=dcd4dbef859c4e07cea9ca66e29b7cbfa1464828456; expires=Fri, 02-Jun-17 00:47:36 GMT; path=/; domain=.redd.it; HttpOnly\\n    x-amz-request-id: 88EF73A7E117A4C4\\n    x-amz-id-2: j1HBaojloU3j3E2wYbL0Oex66M6Ay8PPxlp5CFGdcotrtzJWK/ZcZeflR7YlOmtKT53JssIRdmc=\\n    CF-Cache-Status: HIT\\n    X-Content-Type-Options: nosniff\\n    Server: cloudflare-nginx\\n    CF-RAY: 2ac6e51bacc407b5-MIA\\n    \\nThis url works on chrome and gets redirected to `HTTPS`: http://i.redd.it/zldsan2mcq0x.jpg\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m4jeb\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"amleszk\", \"media\": null, \"score\": 8, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464828534.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m4jeb/http_for_ireddit_should_redirect_to_https_instead/\", \"locked\": false, \"name\": \"t3_4m4jeb\", \"created\": 1464856969.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m4jeb/http_for_ireddit_should_redirect_to_https_instead/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"HTTP for i.redd.it should redirect to HTTPS, instead returns 404\", \"created_utc\": 1464828169.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 8}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;ve forgotten an account\\u0026#39;s password (and didn\\u0026#39;t register an email address with it) but I have the account\\u0026#39;s access and refresh tokens and am wondering if there is some way to change a password with them\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I've forgotten an account's password (and didn't register an email address with it) but I have the account's access and refresh tokens and am wondering if there is some way to change a password with them\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m4c81\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"RedRavens\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m4c81/is_there_a_way_to_change_a_password_with_praw/\", \"locked\": false, \"name\": \"t3_4m4c81\", \"created\": 1464854123.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m4c81/is_there_a_way_to_change_a_password_with_praw/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there a way to change a password with PRAW?\", \"created_utc\": 1464825323.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWeb Designers of Reddit,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EContrary to the popular opinion, I\\u0026#39;m one of those who likes the html/css design of Reddit very much! Thing is that \\u003Cem\\u003Eminimalism\\u003C/em\\u003E is all but lost in webdev nowadays with the coming of Bootstrap, npm/bower and the ease with which folks can just download a plethora of bloated themes and libraries.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI think the success factor behind Reddit is not just the content, but also the content presentation. The site is simple and speedy, and yet provides all the professional look and feel a reader needs. It has sensible colors, fonts and layouts and yet doesn\\u0026#39;t need to fetch content from a plethora of CDNs and libraries like Bootstrap!\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECan you please provide me tips and guidelines about how can I learn this kind of minimalistic design? In fact I\\u0026#39;m not even a designer, I\\u0026#39;m just a backend dev who does php/mysql and python and just getting interested into web-designing. What tips have you got for me?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Web Designers of Reddit,\\n\\nContrary to the popular opinion, I'm one of those who likes the html/css design of Reddit very much! Thing is that *minimalism* is all but lost in webdev nowadays with the coming of Bootstrap, npm/bower and the ease with which folks can just download a plethora of bloated themes and libraries.\\n\\nI think the success factor behind Reddit is not just the content, but also the content presentation. The site is simple and speedy, and yet provides all the professional look and feel a reader needs. It has sensible colors, fonts and layouts and yet doesn't need to fetch content from a plethora of CDNs and libraries like Bootstrap!\\n\\nCan you please provide me tips and guidelines about how can I learn this kind of minimalistic design? In fact I'm not even a designer, I'm just a backend dev who does php/mysql and python and just getting interested into web-designing. What tips have you got for me?\\n\\nThanks.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m37j3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"rms_returns\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m37j3/web_designers_of_reddit_care_to_share_some/\", \"locked\": false, \"name\": \"t3_4m37j3\", \"created\": 1464839981.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m37j3/web_designers_of_reddit_care_to_share_some/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Web Designers of Reddit, care to share some tips/guidelines?\", \"created_utc\": 1464811181.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EMy reddit site went down if many users trying to access at one time, and the site threw a 503 error message. When I looked into db connection, I saw many idle connections (about 70). I wonder if this is the problem? Can anyone please help me fix it?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThank you for your help!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"My reddit site went down if many users trying to access at one time, and the site threw a 503 error message. When I looked into db connection, I saw many idle connections (about 70). I wonder if this is the problem? Can anyone please help me fix it?\\n\\nThank you for your help!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m2p0i\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"usaggie\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464813010.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m2p0i/site_went_down_if_there_were_many_access/\", \"locked\": false, \"name\": \"t3_4m2p0i\", \"created\": 1464834090.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m2p0i/site_went_down_if_there_were_many_access/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Site went down if there were many access\", \"created_utc\": 1464805290.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;ve seen articles discussing their sorting algorithm, but it seems very inefficient to load every post from their database and then applying it.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI couldn\\u0026#39;t find any info on this when looking through the source on github.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EDoes anyone know how they filter the post right out of the database?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I've seen articles discussing their sorting algorithm, but it seems very inefficient to load every post from their database and then applying it.\\n\\nI couldn't find any info on this when looking through the source on github.\\n\\nDoes anyone know how they filter the post right out of the database?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4m1aw0\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Xavierxf\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4m1aw0/how_does_reddit_filter_post_when_getting_them/\", \"locked\": false, \"name\": \"t3_4m1aw0\", \"created\": 1464817544.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4m1aw0/how_does_reddit_filter_post_when_getting_them/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How does reddit filter post when getting them from their database?\", \"created_utc\": 1464788744.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI really like the comments and subreddit systems from Reddit and I\\u0026#39;m considering using the source code for my future website (discussions around various topics).\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHowever, I will need to modify the code to add some functionalities like: login via Facebook account exclusively (no other registration way) and adding some features in post (polls and surveys). Do you think this will be an easy task or not ?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ei\\u0026#39;m not considering to use forum tempaltes (ipb, vbulletin) because the commenting form will be less practical for what i need.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESo my plan is either to 1) develop from scratch a website with a comment system and subreddit system like reddit or 2) use reddit source code and modify it for the things I need to add\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAlso, i\\u0026#39;m not a expert in dev, so I will probably outsource the development of these modifications.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThank you\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello,\\n\\nI really like the comments and subreddit systems from Reddit and I'm considering using the source code for my future website (discussions around various topics).\\n\\nHowever, I will need to modify the code to add some functionalities like: login via Facebook account exclusively (no other registration way) and adding some features in post (polls and surveys). Do you think this will be an easy task or not ?\\n\\ni'm not considering to use forum tempaltes (ipb, vbulletin) because the commenting form will be less practical for what i need.\\n\\nSo my plan is either to 1) develop from scratch a website with a comment system and subreddit system like reddit or 2) use reddit source code and modify it for the things I need to add\\n\\nAlso, i'm not a expert in dev, so I will probably outsource the development of these modifications.\\n\\nThank you\\n\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lzbku\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"cyriltra\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lzbku/considering_using_reddit_source_code_for_a_website/\", \"locked\": false, \"name\": \"t3_4lzbku\", \"created\": 1464781371.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lzbku/considering_using_reddit_source_code_for_a_website/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Considering using Reddit Source Code for a website\", \"created_utc\": 1464752571.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003E\\u003Ca href=\\\"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?s=c4bd4228dcf7989c419f1cdfee769aa8\\\"\\u003Ehttps://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?s=c4bd4228dcf7989c419f1cdfee769aa8\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"/r/AdviceAnimals/comments/4lwaxz/angry_turn_signal_advice_mallard/\\\"\\u003E/r/AdviceAnimals/comments/4lwaxz/angry_turn_signal_advice_mallard/\\u003C/a\\u003E\\nFor JSON\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ccode\\u003E\\n{\\nkind: \\u0026quot;t3\\u0026quot;,\\ndata: {\\ndomain: \\u0026quot;livememe.com\\u0026quot;,\\nbanned_by: null,\\nmedia_embed: { },\\nsubreddit: \\u0026quot;AdviceAnimals\\u0026quot;,\\nselftext_html: null,\\nselftext: \\u0026quot;\\u0026quot;,\\nlikes: null,\\nsuggested_sort: null,\\nuser_reports: [ ],\\nsecure_media: null,\\nlink_flair_text: null,\\nid: \\u0026quot;4lwaxz\\u0026quot;,\\nfrom_kind: null,\\ngilded: 0,\\narchived: false,\\nclicked: false,\\nreport_reasons: null,\\nauthor: \\u0026quot;platypus34\\u0026quot;,\\nmedia: null,\\nscore: 1283,\\napproved_by: null,\\nover_18: false,\\nhidden: false,\\npreview: {\\nimages: [\\n{\\nsource: {\\nurl: \\u0026quot;https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?s=c4bd4228dcf7989c419f1cdfee769aa8\\u0026quot;,\\nwidth: 652,\\nheight: 750\\n},\\nresolutions: [\\n{\\nurl: \\u0026quot;https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;amp;crop=faces%2Centropy\\u0026amp;amp;arh=2\\u0026amp;amp;w=108\\u0026amp;amp;s=451cb3bcb6bbe9074cf948f86f54fa43\\u0026quot;,\\nwidth: 108,\\nheight: 124\\n},\\n{\\nurl: \\u0026quot;https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;amp;crop=faces%2Centropy\\u0026amp;amp;arh=2\\u0026amp;amp;w=216\\u0026amp;amp;s=a07ff77839eff52ba2487d2a429240a3\\u0026quot;,\\nwidth: 216,\\nheight: 248\\n},\\n{\\nurl: \\u0026quot;https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;amp;crop=faces%2Centropy\\u0026amp;amp;arh=2\\u0026amp;amp;w=320\\u0026amp;amp;s=2d78d1dfd4b28dc88c375dd05757b139\\u0026quot;,\\nwidth: 320,\\nheight: 368\\n},\\n{\\nurl: \\u0026quot;https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;amp;crop=faces%2Centropy\\u0026amp;amp;arh=2\\u0026amp;amp;w=640\\u0026amp;amp;s=e6be0cc0138277c641954ca7370bafc8\\u0026quot;,\\nwidth: 640,\\nheight: 736\\n}\\n],\\nvariants: { },\\nid: \\u0026quot;D9bjAvL1U23OR-JONM0lZXkUxCEO1l3z8br-ZYdGty8\\u0026quot;\\n}\\n]\\n},\\nnum_comments: 54,\\nthumbnail: \\u0026quot;http://b.thumbs.redditmedia.com/6ZyrXPGoJ3DtTYq8bQ-PMWwh_BnUJCNnfzNACvV2N3g.jpg\\u0026quot;,\\nsubreddit_id: \\u0026quot;t5_2s7tt\\u0026quot;,\\nhide_score: false,\\nedited: false,\\nlink_flair_css_class: null,\\nauthor_flair_css_class: null,\\ndowns: 0,\\nsecure_media_embed: { },\\nsaved: false,\\nremoval_reason: null,\\npost_hint: \\u0026quot;link\\u0026quot;,\\nstickied: false,\\nfrom: null,\\nis_self: false,\\nfrom_id: null,\\npermalink: \\u0026quot;/r/AdviceAnimals/comments/4lwaxz/angry_turn_signal_advice_mallard/\\u0026quot;,\\nlocked: false,\\nname: \\u0026quot;t3_4lwaxz\\u0026quot;,\\ncreated: 1464743506,\\nurl: \\u0026quot;http://www.livememe.com/1fqh0td\\u0026quot;,\\nauthor_flair_text: null,\\nquarantine: false,\\ntitle: \\u0026quot;Angry Turn Signal Advice Mallard\\u0026quot;,\\ncreated_utc: 1464714706,\\ndistinguished: null,\\nmod_reports: [ ],\\nvisited: false,\\nnum_reports: null,\\nups: 1283\\n}\\n}\\n\\u003C/code\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?s=c4bd4228dcf7989c419f1cdfee769aa8\\n\\n/r/AdviceAnimals/comments/4lwaxz/angry_turn_signal_advice_mallard/\\nFor JSON\\n\\n```\\n{\\nkind: \\\"t3\\\",\\ndata: {\\ndomain: \\\"livememe.com\\\",\\nbanned_by: null,\\nmedia_embed: { },\\nsubreddit: \\\"AdviceAnimals\\\",\\nselftext_html: null,\\nselftext: \\\"\\\",\\nlikes: null,\\nsuggested_sort: null,\\nuser_reports: [ ],\\nsecure_media: null,\\nlink_flair_text: null,\\nid: \\\"4lwaxz\\\",\\nfrom_kind: null,\\ngilded: 0,\\narchived: false,\\nclicked: false,\\nreport_reasons: null,\\nauthor: \\\"platypus34\\\",\\nmedia: null,\\nscore: 1283,\\napproved_by: null,\\nover_18: false,\\nhidden: false,\\npreview: {\\nimages: [\\n{\\nsource: {\\nurl: \\\"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?s=c4bd4228dcf7989c419f1cdfee769aa8\\\",\\nwidth: 652,\\nheight: 750\\n},\\nresolutions: [\\n{\\nurl: \\\"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;crop=faces%2Centropy\\u0026amp;arh=2\\u0026amp;w=108\\u0026amp;s=451cb3bcb6bbe9074cf948f86f54fa43\\\",\\nwidth: 108,\\nheight: 124\\n},\\n{\\nurl: \\\"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;crop=faces%2Centropy\\u0026amp;arh=2\\u0026amp;w=216\\u0026amp;s=a07ff77839eff52ba2487d2a429240a3\\\",\\nwidth: 216,\\nheight: 248\\n},\\n{\\nurl: \\\"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;crop=faces%2Centropy\\u0026amp;arh=2\\u0026amp;w=320\\u0026amp;s=2d78d1dfd4b28dc88c375dd05757b139\\\",\\nwidth: 320,\\nheight: 368\\n},\\n{\\nurl: \\\"https://i.redditmedia.com/UKlR5a7NVi7sTp8AX-cVLFneF_NcZkJhcSO54B7z7Kk.jpg?fit=crop\\u0026amp;crop=faces%2Centropy\\u0026amp;arh=2\\u0026amp;w=640\\u0026amp;s=e6be0cc0138277c641954ca7370bafc8\\\",\\nwidth: 640,\\nheight: 736\\n}\\n],\\nvariants: { },\\nid: \\\"D9bjAvL1U23OR-JONM0lZXkUxCEO1l3z8br-ZYdGty8\\\"\\n}\\n]\\n},\\nnum_comments: 54,\\nthumbnail: \\\"http://b.thumbs.redditmedia.com/6ZyrXPGoJ3DtTYq8bQ-PMWwh_BnUJCNnfzNACvV2N3g.jpg\\\",\\nsubreddit_id: \\\"t5_2s7tt\\\",\\nhide_score: false,\\nedited: false,\\nlink_flair_css_class: null,\\nauthor_flair_css_class: null,\\ndowns: 0,\\nsecure_media_embed: { },\\nsaved: false,\\nremoval_reason: null,\\npost_hint: \\\"link\\\",\\nstickied: false,\\nfrom: null,\\nis_self: false,\\nfrom_id: null,\\npermalink: \\\"/r/AdviceAnimals/comments/4lwaxz/angry_turn_signal_advice_mallard/\\\",\\nlocked: false,\\nname: \\\"t3_4lwaxz\\\",\\ncreated: 1464743506,\\nurl: \\\"http://www.livememe.com/1fqh0td\\\",\\nauthor_flair_text: null,\\nquarantine: false,\\ntitle: \\\"Angry Turn Signal Advice Mallard\\\",\\ncreated_utc: 1464714706,\\ndistinguished: null,\\nmod_reports: [ ],\\nvisited: false,\\nnum_reports: null,\\nups: 1283\\n}\\n}\\n```\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lyme0\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"amleszk\", \"media\": null, \"score\": 8, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lyme0/redditmedia_is_returnng_error_header_overflow/\", \"locked\": false, \"name\": \"t3_4lyme0\", \"created\": 1464771538.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lyme0/redditmedia_is_returnng_error_header_overflow/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Redditmedia is returnng error 'Header overflow'\", \"created_utc\": 1464742738.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 8}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi,\\nI am using POST [\\u003Ca href=\\\"/r/subreddit\\\"\\u003E/r/subreddit\\u003C/a\\u003E]/api/flair to set user\\u0026#39;s flair in a subreddit, however, it is not updating flairs for existing comments from that user (it only sets it for future comments). How can I make it so that the flair gets applied to all comments?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks,\\nheat\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi,\\nI am using POST [/r/subreddit]/api/flair to set user's flair in a subreddit, however, it is not updating flairs for existing comments from that user (it only sets it for future comments). How can I make it so that the flair gets applied to all comments?\\n\\nThanks,\\nheat\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lxw6q\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"heat23\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lxw6q/help_needed_update_flair_on_existing_comments_via/\", \"locked\": false, \"name\": \"t3_4lxw6q\", \"created\": 1464761970.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lxw6q/help_needed_update_flair_on_existing_comments_via/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help needed - Update flair on existing comments via API?\", \"created_utc\": 1464733170.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHere\\u0026#39;s the TL:DR;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI want users to send PMs to a bot, requesting changes to their user flairs\\u0026#39; text, because some users have special limited edition flairs, so they can\\u0026#39;t change the text themselves because the flairs no longer appear in the selector.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThe syntax for the command is \\u003Ccode\\u003Eset_flair(subreddit, user, flair_text, flair_css_class)\\u003C/code\\u003E, so it\\u0026#39;s easy to get the username and flair text from the PM they send to the bot, but how can I get the CSS class they\\u0026#39;re currently using?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEDIT: Just to reiterate, I can\\u0026#39;t have users message the bot with the css class, because some flairs are special limited editions, so it would be easily exploitable.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Here's the TL:DR;\\n\\nI want users to send PMs to a bot, requesting changes to their user flairs' text, because some users have special limited edition flairs, so they can't change the text themselves because the flairs no longer appear in the selector.\\n\\nThe syntax for the command is `set_flair(subreddit, user, flair_text, flair_css_class)`, so it's easy to get the username and flair text from the PM they send to the bot, but how can I get the CSS class they're currently using?\\n\\nEDIT: Just to reiterate, I can't have users message the bot with the css class, because some flairs are special limited editions, so it would be easily exploitable.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lv0xz\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"DrYoshiyahu\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464698989.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lv0xz/can_i_request_the_css_class_of_the_user_flair_of/\", \"locked\": false, \"name\": \"t3_4lv0xz\", \"created\": 1464727497.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lv0xz/can_i_request_the_css_class_of_the_user_flair_of/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Can I request the CSS class of the user flair of the sender of a private message?\", \"created_utc\": 1464698697.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EMy main code goes:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er = praw.Reddit(user_agent=useragent)\\nprint \\u0026quot;About to try authenticating\\u0026quot;\\ntry:\\n    o = OAuth2Util.OAuth2Util(r, print_log=True)\\n    print \\u0026quot;Just created authentication object\\u0026quot;\\n    o.refresh(force=True)\\n    print \\u0026quot;Just refreshed token\\u0026quot;\\nexcept Exception as e:\\n        print e\\nprint \\u0026quot;Finished authenticating\\u0026quot;\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003E(comments are just there so I know where it\\u0026#39;s at for testing)\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhen I try to actually run it, I get:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003EAbout to try authenticating\\nRefresh Token\\nRequest new Token (REF)\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAnd then it hangs there, indefinitely.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EMy \\u003Ccode\\u003Eoauth.ini\\u003C/code\\u003E is as follows:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E[app]\\nscope=identity,account,edit,history,modself,mysubreddits,privatemessages,read,submit,wikiread\\nrefreshable = True\\napp_key = abcdefghijklmnop.......\\napp_secret = 1234567890..........\\n\\n[server]\\nserver_mode = False\\nurl = 127.0.0.1\\nport = 65010\\nredirect_path = authorize_callback\\nlink_path = oauth\\n\\n# Will be filled automatically\\n[token]\\ntoken=None\\nrefresh_token=None\\nvalid_until=0\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EAny advice? I\\u0026#39;ve had this bot running on username and password authentication for months now, but this is my first time trying to get it working using OAuth.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"My main code goes:\\n\\n    r = praw.Reddit(user_agent=useragent)\\n    print \\\"About to try authenticating\\\"\\n    try:\\n        o = OAuth2Util.OAuth2Util(r, print_log=True)\\n        print \\\"Just created authentication object\\\"\\n        o.refresh(force=True)\\n        print \\\"Just refreshed token\\\"\\n    except Exception as e:\\n            print e\\n    print \\\"Finished authenticating\\\"\\n\\n(comments are just there so I know where it's at for testing)\\n\\nWhen I try to actually run it, I get:\\n\\n    About to try authenticating\\n    Refresh Token\\n    Request new Token (REF)\\n\\nAnd then it hangs there, indefinitely.\\n\\nMy `oauth.ini` is as follows:\\n\\n    [app]\\n    scope=identity,account,edit,history,modself,mysubreddits,privatemessages,read,submit,wikiread\\n    refreshable = True\\n    app_key = abcdefghijklmnop.......\\n    app_secret = 1234567890..........\\n    \\n    [server]\\n    server_mode = False\\n    url = 127.0.0.1\\n    port = 65010\\n    redirect_path = authorize_callback\\n    link_path = oauth\\n    \\n    # Will be filled automatically\\n    [token]\\n    token=None\\n    refresh_token=None\\n    valid_until=0\\n\\nAny advice? I've had this bot running on username and password authentication for months now, but this is my first time trying to get it working using OAuth.\\n\\nThanks.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4luksa\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ParliamentPageBot\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4luksa/oauth2util_stuck_on_request_new_token_ref/\", \"locked\": false, \"name\": \"t3_4luksa\", \"created\": 1464719489.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4luksa/oauth2util_stuck_on_request_new_token_ref/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[OAuth2Util] Stuck on \\\"Request new Token (REF)\\\"\", \"created_utc\": 1464690689.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EEvening all,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve just updated my app \\u0026quot;Sync for reddit\\u0026quot; and I\\u0026#39;m being hit with 429 errors.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI respect the rate limiting headers, include the app version in the header etc. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAm I missing something or is this an issue with the API?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECheers\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ELaurence\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Evening all,\\n\\nI've just updated my app \\\"Sync for reddit\\\" and I'm being hit with 429 errors.\\n\\nI respect the rate limiting headers, include the app version in the header etc. \\n\\nAm I missing something or is this an issue with the API?\\n\\nCheers\\n\\nLaurence\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lr3pp\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ljdawson\", \"media\": null, \"score\": 48, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 9, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lr3pp/encountering_a_lot_of_429_errors/\", \"locked\": false, \"name\": \"t3_4lr3pp\", \"created\": 1464664495.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lr3pp/encountering_a_lot_of_429_errors/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Encountering a lot of 429 errors\", \"created_utc\": 1464635695.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 48}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIs there anyway to update/edit a reddit text post via API?\\nedit: answered - \\u003Ca href=\\\"https://www.reddit.com/dev/api#POST_api_editusertext\\\"\\u003Ehttps://www.reddit.com/dev/api#POST_api_editusertext\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Is there anyway to update/edit a reddit text post via API?\\nedit: answered - https://www.reddit.com/dev/api#POST_api_editusertext\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lph22\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"NunFur\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lph22/api_how_to_update_a_text_post/\", \"locked\": false, \"name\": \"t3_4lph22\", \"created\": 1464643061.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lph22/api_how_to_update_a_text_post/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"API - How to update a Text Post\", \"created_utc\": 1464614261.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m the mod over at \\u003Ca href=\\\"/r/AskOuija\\\"\\u003E/r/AskOuija\\u003C/a\\u003E. I have a bot that runs every hour and flairs threads that meet certain criteria. I have it pull the last 100 hot posts and iterate through, skipping those that are already flaired. This isn\\u0026#39;t too bad, but I was wondering if there was a way I could filter my query so that the Reddit API only returned unflaired posts. Is there a request parameter that would accomplish this?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm the mod over at /r/AskOuija. I have a bot that runs every hour and flairs threads that meet certain criteria. I have it pull the last 100 hot posts and iterate through, skipping those that are already flaired. This isn't too bad, but I was wondering if there was a way I could filter my query so that the Reddit API only returned unflaired posts. Is there a request parameter that would accomplish this?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lmwxd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"tacobellscannon\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lmwxd/is_there_a_way_to_filter_a_query_to_only_return/\", \"locked\": false, \"name\": \"t3_4lmwxd\", \"created\": 1464594794.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lmwxd/is_there_a_way_to_filter_a_query_to_only_return/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there a way to filter a query to only return unflaired posts?\", \"created_utc\": 1464565994.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIs this possible? Fetch the total number of unread messages/replies via the API? The reddit website obviously lists it next to the orangered envelope, but I can\\u0026#39;t find it anywhere in the API.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIt\\u0026#39;d be really great if \\u003Ccode\\u003Emessage/unread\\u003C/code\\u003E returned it as an additional value so it wouldn\\u0026#39;t require two API calls.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Is this possible? Fetch the total number of unread messages/replies via the API? The reddit website obviously lists it next to the orangered envelope, but I can't find it anywhere in the API.\\n\\nIt'd be really great if `message/unread` returned it as an additional value so it wouldn't require two API calls.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lm48p\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"iamthatis\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lm48p/is_it_possible_to_get_the_number_of_unread/\", \"locked\": false, \"name\": \"t3_4lm48p\", \"created\": 1464582963.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lm48p/is_it_possible_to_get_the_number_of_unread/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is it possible to get the number of unread messages via the API?\", \"created_utc\": 1464554163.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ETraceback - \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003ETraceback (most recent call last):\\n  File \\u0026quot;learn.py\\u0026quot;, line 17, in \\u0026lt;module\\u0026gt;\\n    for com in gen:\\n  File \\u0026quot;/Library/Python/2.7/site-packages/praw/__init__.py\\u0026quot;, line 567, in get_content\\n    page_data = self.request_json(url, params=params)\\n  File \\u0026quot;\\u0026lt;decorator-gen-8\\u0026gt;\\u0026quot;, line 2, in request_json\\n  File \\u0026quot;/Library/Python/2.7/site-packages/praw/decorators.py\\u0026quot;, line 116, in raise_api_exceptions\\n    return_value = function(*args, **kwargs)\\n  File \\u0026quot;/Library/Python/2.7/site-packages/praw/__init__.py\\u0026quot;, line 622, in request_json\\n    retry_on_error=retry_on_error)\\n  File \\u0026quot;/Library/Python/2.7/site-packages/praw/__init__.py\\u0026quot;, line 454, in _request\\n    _raise_response_exceptions(response)\\n  File \\u0026quot;/Library/Python/2.7/site-packages/praw/internal.py\\u0026quot;, line 210, in     _raise_response_exceptions\\nraise NotFound(_raw=response)\\npraw.errors.NotFound: HTTP error\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EHere is the gist - \\u003Ca href=\\\"https://gist.github.com/anonymous/6a4c2e92e9ef3a9094336b5108198b7c\\\"\\u003Ehttps://gist.github.com/anonymous/6a4c2e92e9ef3a9094336b5108198b7c\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI got the error after about an hour of running this loop, i think about 20 users were parsed.\\nWhen the number of users were 10 it worked fine, although in the current case when number of users were 100 I got this error.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECan some one tell me how to go about debugging it?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EBTW my internet was working fine the whole time, I was streaming stuff, so I know.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Traceback - \\n\\n    Traceback (most recent call last):\\n      File \\\"learn.py\\\", line 17, in \\u003Cmodule\\u003E\\n        for com in gen:\\n      File \\\"/Library/Python/2.7/site-packages/praw/__init__.py\\\", line 567, in get_content\\n        page_data = self.request_json(url, params=params)\\n      File \\\"\\u003Cdecorator-gen-8\\u003E\\\", line 2, in request_json\\n      File \\\"/Library/Python/2.7/site-packages/praw/decorators.py\\\", line 116, in raise_api_exceptions\\n        return_value = function(*args, **kwargs)\\n      File \\\"/Library/Python/2.7/site-packages/praw/__init__.py\\\", line 622, in request_json\\n        retry_on_error=retry_on_error)\\n      File \\\"/Library/Python/2.7/site-packages/praw/__init__.py\\\", line 454, in _request\\n        _raise_response_exceptions(response)\\n      File \\\"/Library/Python/2.7/site-packages/praw/internal.py\\\", line 210, in     _raise_response_exceptions\\n    raise NotFound(_raw=response)\\n    praw.errors.NotFound: HTTP error\\n\\nHere is the gist - https://gist.github.com/anonymous/6a4c2e92e9ef3a9094336b5108198b7c\\n\\nI got the error after about an hour of running this loop, i think about 20 users were parsed.\\nWhen the number of users were 10 it worked fine, although in the current case when number of users were 100 I got this error.\\n\\nCan some one tell me how to go about debugging it?\\n\\nBTW my internet was working fine the whole time, I was streaming stuff, so I know.\\n\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4llotu\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"advai_ta\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464548475.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4llotu/getting_http_error_while_trying_to_analyse/\", \"locked\": false, \"name\": \"t3_4llotu\", \"created\": 1464576904.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4llotu/getting_http_error_while_trying_to_analyse/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Getting HTTP error while trying to analyse redditors' comments\", \"created_utc\": 1464548104.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIt\\u0026#39;s weird, looking through PRAW\\u0026#39;s source code, I don\\u0026#39;t understand why my script breaks when I invoke python when the current working directory is not the same as the python script\\u0026#39;s location.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EMy bot has a python script and a local praw.ini file. Both live in the same directory. When I run \\u0026#39;python myscript.py\\u0026#39; from the directory they live in, everything works smoothly. I\\u0026#39;m now trying to invoke the script via PHP and/or CRON jobs and all of a sudden PRAW can\\u0026#39;t find my praw.ini file because the current working directory is not the same as the folder of the scripts. I\\u0026#39;ve even tried using os.chdir(os.path.dirname(os.path.realpath(\\u003Cstrong\\u003Efile\\u003C/strong\\u003E))) before calling any PRAW code to hopefully help but that hasn\\u0026#39;t worked.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAnyone have any tips out there? I\\u0026#39;d rather not modify my system-wide PRAW files for my script. The source code looks like it tries to do the same thing as my os.chdir code (by searching os.path.dirname(os.path.realpath(system.modules[\\u003Cstrong\\u003Ename\\u003C/strong\\u003E].\\u003Cstrong\\u003Efile\\u003C/strong\\u003E))  for praw.ini which should theoretically work.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEDIT:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve found a solution that may work long-term, I just find it a bit hacky. Before I invoke the python script via PHP, I\\u0026#39;ll cd into the correct directory first. Ideally, I should be able to specify a configuration file/path to PRAW, but it doesn\\u0026#39;t look like that functionality exists.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"It's weird, looking through PRAW's source code, I don't understand why my script breaks when I invoke python when the current working directory is not the same as the python script's location.\\n\\nMy bot has a python script and a local praw.ini file. Both live in the same directory. When I run 'python myscript.py' from the directory they live in, everything works smoothly. I'm now trying to invoke the script via PHP and/or CRON jobs and all of a sudden PRAW can't find my praw.ini file because the current working directory is not the same as the folder of the scripts. I've even tried using os.chdir(os.path.dirname(os.path.realpath(__file__))) before calling any PRAW code to hopefully help but that hasn't worked.\\n\\nAnyone have any tips out there? I'd rather not modify my system-wide PRAW files for my script. The source code looks like it tries to do the same thing as my os.chdir code (by searching os.path.dirname(os.path.realpath(system.modules[__name__].__file__))  for praw.ini which should theoretically work.\\n\\nEDIT:\\n\\nI've found a solution that may work long-term, I just find it a bit hacky. Before I invoke the python script via PHP, I'll cd into the correct directory first. Ideally, I should be able to specify a configuration file/path to PRAW, but it doesn't look like that functionality exists.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lk9es\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Enuratique\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 5, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464529130.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lk9es/praw_cant_find_prawini_when_python_script_invoked/\", \"locked\": false, \"name\": \"t3_4lk9es\", \"created\": 1464553868.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lk9es/praw_cant_find_prawini_when_python_script_invoked/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"PRAW can't find praw.ini when python script invoked from other \\\"working directory\\\"\", \"created_utc\": 1464525068.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI heard that reddit will be bringing in an image service to supersede Imgur.  Will the image url\\u0026#39;s be accessible via the reddit REST API?  \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I heard that reddit will be bringing in an image service to supersede Imgur.  Will the image url's be accessible via the reddit REST API?  \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4liqma\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"kiwiheretic\", \"media\": null, \"score\": 12, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4liqma/the_new_reddit_image_service/\", \"locked\": false, \"name\": \"t3_4liqma\", \"created\": 1464518108.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4liqma/the_new_reddit_image_service/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"The new reddit image service\", \"created_utc\": 1464489308.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 12}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI know I can get \\u003Cem\\u003Erecent\\u003C/em\\u003E traffic data from \\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://www.reddit.com/r/Physics/about/traffic/.json\\\"\\u003Ehttps://www.reddit.com/r/Physics/about/traffic/.json\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EBut it\\u0026#39;s not public, and AFAIK none of the other mods has been saving it.  I couldn\\u0026#39;t find anything in the API about it.  I tried searching this sub for relevant posts and found nothing.  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;m trying to measure the effect of past moderation policies on the health of the sub.  I have comment and post data.  But I really want \\u003Cem\\u003Eunique visitors\\u003C/em\\u003E and \\u003Cem\\u003Epage views\\u003C/em\\u003E.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAm I out of luck?  Thanks for any help!\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I know I can get *recent* traffic data from \\n\\nhttps://www.reddit.com/r/Physics/about/traffic/.json\\n\\nBut it's not public, and AFAIK none of the other mods has been saving it.  I couldn't find anything in the API about it.  I tried searching this sub for relevant posts and found nothing.  \\n\\nI'm trying to measure the effect of past moderation policies on the health of the sub.  I have comment and post data.  But I really want *unique visitors* and *page views*.\\n\\nAm I out of luck?  Thanks for any help!\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lh39w\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"CarbonRodOfPhysics\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lh39w/can_i_get_historical_traffic_data_for_my_sub/\", \"locked\": false, \"name\": \"t3_4lh39w\", \"created\": 1464491313.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lh39w/can_i_get_historical_traffic_data_for_my_sub/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Can I get historical traffic data for my sub?\", \"created_utc\": 1464462513.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo when trying to get a load of comments from a submission using \\u003Ccode\\u003Esubmission.comments\\u003C/code\\u003E, around 100 comments are returned, then a \\u0026#39;More Comments\\u0026#39; object.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve found \\u003Ca href=\\\"http://praw.readthedocs.io/en/stable/pages/code_overview.html#praw.objects.Submission.replace_more_comments\\\"\\u003Ethis\\u003C/a\\u003E, but cannot figure out how to use it.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAnyone help?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So when trying to get a load of comments from a submission using `submission.comments`, around 100 comments are returned, then a 'More Comments' object.\\n\\nI've found [this](http://praw.readthedocs.io/en/stable/pages/code_overview.html#praw.objects.Submission.replace_more_comments), but cannot figure out how to use it.\\n\\nAnyone help?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lgx9c\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Shubbler\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lgx9c/praw_someone_talk_me_through_getting_more/\", \"locked\": false, \"name\": \"t3_4lgx9c\", \"created\": 1464488823.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lgx9c/praw_someone_talk_me_through_getting_more/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Someone talk me through getting more comments from a 'More Comments' object?\", \"created_utc\": 1464460023.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello Reddit,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI try to set up cloud search for my clone and I follow this guide:\\n\\u003Ca href=\\\"https://www.reddit.com/r/redditdev/comments/20qudv/reddit_with_amazon_cloud_search/cg6k19r\\\"\\u003Ehttps://www.reddit.com/r/redditdev/comments/20qudv/reddit_with_amazon_cloud_search/cg6k19r\\u003C/a\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFirst of all, I do not found UINT type in \\u0026quot;indexing option\\u0026quot; but I supposed that is the same with \\u0026quot;INT\\u0026quot;. Let me if is not.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ELet me explain how I set a index line in aws:\\nWe took the ff line as example:\\nauthor                                          Active      literal (Search Result)\\nin AWS:\\nat name: author , at type: \\u0026quot;literal\\u0026quot; and at default value \\u0026quot;Search Result\\u0026quot;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EPlease let me know if is correct.\\nConsidering m set up correct....\\nFrom where on aws I can get the following info:\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u0026#39;CLOUDSEARCH_SEARCH_API =\\u0026#39; \\u0026#39;CLOUDSEARCH_DOC_API =\\u0026#39; \\u0026#39;CLOUDSEARCH_SUBREDDIT_SEARCH_API =\\u0026#39; and \\u0026#39;CLOUDSEARCH_SUBREDDIT_DOC_API =\\u0026#39;.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello Reddit,\\n\\nI try to set up cloud search for my clone and I follow this guide:\\nhttps://www.reddit.com/r/redditdev/comments/20qudv/reddit_with_amazon_cloud_search/cg6k19r\\n\\nFirst of all, I do not found UINT type in \\\"indexing option\\\" but I supposed that is the same with \\\"INT\\\". Let me if is not.\\n\\nLet me explain how I set a index line in aws:\\nWe took the ff line as example:\\nauthor                                          Active      literal (Search Result)\\nin AWS:\\nat name: author , at type: \\\"literal\\\" and at default value \\\"Search Result\\\"\\n\\nPlease let me know if is correct.\\nConsidering m set up correct....\\nFrom where on aws I can get the following info:\\n\\n'CLOUDSEARCH_SEARCH_API =' 'CLOUDSEARCH_DOC_API =' 'CLOUDSEARCH_SUBREDDIT_SEARCH_API =' and 'CLOUDSEARCH_SUBREDDIT_DOC_API ='.\\n\\nThanks.\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lgth1\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hhaevs\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lgth1/set_up_of_s3_how_to_get_these_info/\", \"locked\": false, \"name\": \"t3_4lgth1\", \"created\": 1464487248.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lgth1/set_up_of_s3_how_to_get_these_info/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Set up of S3. How to get these info ?\", \"created_utc\": 1464458448.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI set it up as instructed (Ubuntu Server 14.04 hosted on Azure), but I can\\u0026#39;t access it.\\nWindows ping shows this (from my local machine):\\nPinging \\u0026lt;REDACTED\\u0026gt; [REDACTED] with 32 bytes of data:\\nRequest timed out.\\nRequest timed out.\\nRequest timed out.\\nRequest timed out.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EPing statistics for \\u0026lt;REDACTED\\u0026gt;:\\n    Packets: Sent = 4, Received = 0, Lost = 4 (100% loss),\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Ecassandra -f shows this (from the host machine):\\nError: Exception thrown by the agent : java.rmi.server.ExportException: Port already in use: 7199; nested exception is:\\n        java.net.BindException: Address already in use\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ENow obviously the port is (for some odd reason) already in use, but why does ping fail? And how do I change the port Cassandra uses?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I set it up as instructed (Ubuntu Server 14.04 hosted on Azure), but I can't access it.\\nWindows ping shows this (from my local machine):\\nPinging \\u003CREDACTED\\u003E [REDACTED] with 32 bytes of data:\\nRequest timed out.\\nRequest timed out.\\nRequest timed out.\\nRequest timed out.\\n\\nPing statistics for \\u003CREDACTED\\u003E:\\n    Packets: Sent = 4, Received = 0, Lost = 4 (100% loss),\\n\\ncassandra -f shows this (from the host machine):\\nError: Exception thrown by the agent : java.rmi.server.ExportException: Port already in use: 7199; nested exception is:\\n        java.net.BindException: Address already in use\\n\\nNow obviously the port is (for some odd reason) already in use, but why does ping fail? And how do I change the port Cassandra uses?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4leu8s\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"eladkr85\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4leu8s/help_setting_up_a_reddit_clone/\", \"locked\": false, \"name\": \"t3_4leu8s\", \"created\": 1464447482.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4leu8s/help_setting_up_a_reddit_clone/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Help setting up a reddit clone\", \"created_utc\": 1464418682.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EWhenever you view a subreddit, you get \\u003Cstrong\\u003E~X users here now\\u003C/strong\\u003E info. Is it possible to get this info from the API? I am having trouble finding it in the subreddits section\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Whenever you view a subreddit, you get **~X users here now** info. Is it possible to get this info from the API? I am having trouble finding it in the subreddits section\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lbzt2\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"zachcowell\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lbzt2/get_number_of_users_currently_on_a_particular/\", \"locked\": false, \"name\": \"t3_4lbzt2\", \"created\": 1464400938.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lbzt2/get_number_of_users_currently_on_a_particular/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Get number of users currently on a particular subreddit?\", \"created_utc\": 1464372138.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EFor example, I want to get the flair of a user from \\u003Ca href=\\\"/r/askmen\\\"\\u003E/r/askmen\\u003C/a\\u003E. \\nI want to do this without logging in. According to the docs I need to use UnAuthenticatedReddit, but I\\u0026#39;m getting this error after using it \\n\\u0026quot;\\u0026#39;UnauthenticatedReddit\\u0026#39; object has no attribute \\u0026#39;has_scope\\u0026#39;\\u0026quot;\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHere\\u0026#39;s the gist \\u003Ca href=\\\"https://gist.github.com/anonymous/765bde5f9d083e62bb5865cf8638ee12\\\"\\u003Ehttps://gist.github.com/anonymous/765bde5f9d083e62bb5865cf8638ee12\\u003C/a\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"For example, I want to get the flair of a user from /r/askmen. \\nI want to do this without logging in. According to the docs I need to use UnAuthenticatedReddit, but I'm getting this error after using it \\n\\\"'UnauthenticatedReddit' object has no attribute 'has_scope'\\\"\\n\\nHere's the gist https://gist.github.com/anonymous/765bde5f9d083e62bb5865cf8638ee12\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4lb6uj\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"advai_ta\", \"media\": null, \"score\": 0, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4lb6uj/can_some_one_help_me_with_getting_flair_of_a_user/\", \"locked\": false, \"name\": \"t3_4lb6uj\", \"created\": 1464390929.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4lb6uj/can_some_one_help_me_with_getting_flair_of_a_user/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Can some one help me with getting flair of a user in a subreddit?\", \"created_utc\": 1464362129.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 0}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIn my all projects currently I am using mocks for db/external calls ,but I don\\u0026#39;t think that is the right way to gain confidence on code. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003Efor example currently I might use 1 version of DB and tomorrow morning I can use version 2 of DB and the response format of version 1 and 2 might be different but since I have mocked DB all tests will work fine but when my code runs on actual DB it will fail. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EPardon any mistakes I have done for posting. Please suggest me right way if I am doing anything wrong.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"\\n\\nIn my all projects currently I am using mocks for db/external calls ,but I don't think that is the right way to gain confidence on code. \\n\\nfor example currently I might use 1 version of DB and tomorrow morning I can use version 2 of DB and the response format of version 1 and 2 might be different but since I have mocked DB all tests will work fine but when my code runs on actual DB it will fail. \\n\\nPardon any mistakes I have done for posting. Please suggest me right way if I am doing anything wrong.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l9t3f\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"parinck\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l9t3f/q_should_i_mock_external_calls_like_dbrequests_to/\", \"locked\": false, \"name\": \"t3_4l9t3f\", \"created\": 1464365513.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l9t3f/q_should_i_mock_external_calls_like_dbrequests_to/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[Q] should I mock external calls like DB/Requests to external system in BDD/TDD ??\", \"created_utc\": 1464336713.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": null, \"selftext\": \"\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l7qyh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"licktheenvelopeoff\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l7qyh/how_can_i_use_proxies_when_using_prawpython_35/\", \"locked\": false, \"name\": \"t3_4l7qyh\", \"created\": 1464328775.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l7qyh/how_can_i_use_proxies_when_using_prawpython_35/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How can I use proxies when using praw/python 3.5?\", \"created_utc\": 1464299975.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI know it\\u0026#39;s brand-spanking new.  But can we have the API for \\u003Ca href=\\\"https://www.reddit.com/r/changelog/comments/4kuk2j/reddit_change_introducing_image_uploading_beta/\\\"\\u003Ethis\\u003C/a\\u003E please? Obviously not the actual endpoints before it\\u0026#39;s out of beta, but the doxygen/docstring/whatever-generated description?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I know it's brand-spanking new.  But can we have the API for [this](https://www.reddit.com/r/changelog/comments/4kuk2j/reddit_change_introducing_image_uploading_beta/) please? Obviously not the actual endpoints before it's out of beta, but the doxygen/docstring/whatever-generated description?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l7okc\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"CogitoErgoReddit\", \"media\": null, \"score\": 7, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l7okc/new_image_uploading_api/\", \"locked\": false, \"name\": \"t3_4l7okc\", \"created\": 1464327851.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l7okc/new_image_uploading_api/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"New image uploading API?\", \"created_utc\": 1464299051.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 7}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI saw tha are few admin pages for gold, ads etc, like:\\nadmingold.html in r2/r2/templates\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow can this pages accessed ? On what link ? Or whats the link for admins of ads, gold.. ?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi,\\n\\nI saw tha are few admin pages for gold, ads etc, like:\\nadmingold.html in r2/r2/templates\\n\\nHow can this pages accessed ? On what link ? Or whats the link for admins of ads, gold.. ?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l7exd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hhaevs\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l7exd/how_to_access_admin_pages/\", \"locked\": false, \"name\": \"t3_4l7exd\", \"created\": 1464324370.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l7exd/how_to_access_admin_pages/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to access admin pages ?\", \"created_utc\": 1464295570.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI have a personal Discord Bot, for me and my friends.\\nI want it to grab a Random Subreddit URL using \\u003Cstrong\\u003E\\u003Ca href=\\\"https://www.reddit.com/r/random\\\"\\u003Ehttps://www.reddit.com/r/random\\u003C/a\\u003E\\u003C/strong\\u003E\\u003Cbr/\\u003E\\nor for a Random thread URL within a Subreddit:\\u003Cbr/\\u003E\\n\\u003Cstrong\\u003E\\u003Ca href=\\\"https://www.reddit.com/r/redditdev/random\\\"\\u003Ehttps://www.reddit.com/r/redditdev/random\\u003C/a\\u003E\\u003C/strong\\u003E  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIs there a way to do this without needing to setup a Reddit API and OAuth2?\\u003Cbr/\\u003E\\nWhen I try to grab, I get a \\u0026quot;Too Many Requests\\u0026quot; error. (With a single request)  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;d also like to grab the \\u0026quot;Link\\u0026quot; that the post is talking of, if there is one.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEdit:\\u003Cbr/\\u003E\\nThanks to the help from everyone, especially \\u003Cstrong\\u003E\\u003Ca href=\\\"/u/JarOfHearts\\\"\\u003E/u/JarOfHearts\\u003C/a\\u003E\\u003C/strong\\u003E!  \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E@Override\\npublic void action(String[] args, MessageReceivedEvent event) {\\n    String link = \\u0026quot;https://www.reddit.com/r/\\u0026quot; + SUBREDDIT + \\u0026quot;/random\\u0026quot;;\\n    String title = null;\\n    String referencedLink = null;\\n    StringBuilder page = new StringBuilder();\\n\\n    try {\\n        HttpURLConnection con = (HttpURLConnection)(new URL(\\u0026quot;https://www.reddit.com/r/\\u0026quot; + SUBREDDIT + \\u0026quot;/random\\u0026quot;).openConnection());\\n        con.setRequestProperty(\\u0026quot;user-agent\\u0026quot;, Main.HTTP_USER_AGENT);\\n        con.setRequestMethod(\\u0026quot;GET\\u0026quot;);\\n        con.setInstanceFollowRedirects(true);\\n        con.connect();\\n        int responseCode = con.getResponseCode();\\n\\n        if(responseCode == 429) {\\n            Main.getBotListener().sendMessage(event, \\u0026quot;Error Response: 429, too many Requests!);\\n            return;\\n        }\\n\\n        System.out.println(\\u0026quot;Response Code: \\u0026quot; + responseCode);\\n\\n        link = con.getURL().toString();\\n\\n        con.disconnect();\\n    } catch(IOException e) {\\n        e.printStackTrace();\\n    }\\n\\n    final int COMMENTS_POS = link.indexOf(\\u0026quot;/comments/\\u0026quot;) + \\u0026quot;/comments/\\u0026quot;.length();\\n\\n    String urlCode = link.substring(COMMENTS_POS, link.indexOf(\\u0026#39;/\\u0026#39;, COMMENTS_POS));\\n    String jsonLink = \\u0026quot;https://www.reddit.com/api/info.json?id=t3_\\u0026quot;;\\n\\n    if(urlCode != null) {\\n        System.out.println(\\u0026quot;REDDIT THREAD CODE: \\u0026quot; + urlCode);\\n        jsonLink += urlCode;\\n\\n        try {\\n            HttpURLConnection con = (HttpURLConnection)(new URL(jsonLink).openConnection());\\n            con.setRequestProperty(\\u0026quot;user-agent\\u0026quot;, Main.HTTP_USER_AGENT);\\n            con.setRequestMethod(\\u0026quot;GET\\u0026quot;);\\n            con.setInstanceFollowRedirects(true);\\n            con.connect();\\n            int responseCode = con.getResponseCode();\\n\\n            System.out.println(\\u0026quot;JSON LINK \\u0026gt; Response Code: \\u0026quot; + responseCode);\\n\\n            if(responseCode == 429) {\\n                return;\\n            }\\n\\n            try {\\n                BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream(), \\u0026quot;UTF-8\\u0026quot;));\\n\\n                String line;\\n                while ((line = br.readLine()) != null) {\\n                    page.append(line + \\u0026quot;\\\\n\\u0026quot;);\\n                }\\n\\n                br.close();\\n            } catch (MalformedURLException MUE) {\\n                MUE.printStackTrace();\\n            } catch (IOException IOE) {\\n                IOE.printStackTrace();\\n            }\\n           con.disconnect();\\n        } catch(IOException e) {\\n            e.printStackTrace();\\n        }\\n    }\\n\\n    String jsonCode = page.toString();\\n    int startIndex = jsonCode.indexOf(\\u0026quot;t3_\\u0026quot; + urlCode);\\n    int urlIndex = jsonCode.indexOf(\\u0026quot;\\\\\\u0026quot;url\\\\\\u0026quot;:\\u0026quot;, startIndex) + (\\u0026quot;\\\\\\u0026quot;url\\\\\\u0026quot;: \\\\\\u0026quot;\\u0026quot;).length();\\n    int titleIndex = jsonCode.indexOf(\\u0026quot;\\\\\\u0026quot;title\\\\\\u0026quot;:\\u0026quot;) + (\\u0026quot;\\\\\\u0026quot;title\\\\\\u0026quot;: \\\\\\u0026quot;\\u0026quot;).length();\\n    referencedLink = jsonCode.substring(urlIndex, jsonCode.indexOf(\\u0026quot;\\\\\\u0026quot;,\\u0026quot;, urlIndex));\\n    title = \\u0026quot;_\\u0026quot; + jsonCode.substring(titleIndex, jsonCode.indexOf(\\u0026quot;\\\\\\u0026quot;,\\u0026quot;, titleIndex)) + \\u0026quot;_\\u0026quot;;\\n\\n    System.out.println(page.toString());\\n\\n    System.out.println(title + \\u0026quot;, \\u0026quot; + link + \\u0026quot;, \\u0026quot; + referencedLink);//\\\\n\\u0026lt;\\u0026quot; + link + \\u0026quot;\\u0026gt;\\n    Main.getBotListener().sendMessage(event, MESSAGE + \\u0026quot;\\\\n**\\u0026lt;\\u0026quot; + (referencedLink != null ? referencedLink : link) + \\u0026quot;\\u0026gt;** - \\u0026quot; + title);\\n\\n}\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I have a personal Discord Bot, for me and my friends.\\nI want it to grab a Random Subreddit URL using **https://www.reddit.com/r/random**  \\nor for a Random thread URL within a Subreddit:  \\n**https://www.reddit.com/r/redditdev/random**  \\n\\nIs there a way to do this without needing to setup a Reddit API and OAuth2?  \\nWhen I try to grab, I get a \\\"Too Many Requests\\\" error. (With a single request)  \\n\\nI'd also like to grab the \\\"Link\\\" that the post is talking of, if there is one.\\n\\nEdit:  \\nThanks to the help from everyone, especially **/u/JarOfHearts**!  \\n\\n    @Override\\n    public void action(String[] args, MessageReceivedEvent event) {\\n        String link = \\\"https://www.reddit.com/r/\\\" + SUBREDDIT + \\\"/random\\\";\\n        String title = null;\\n        String referencedLink = null;\\n        StringBuilder page = new StringBuilder();\\n        \\n        try {\\n            HttpURLConnection con = (HttpURLConnection)(new URL(\\\"https://www.reddit.com/r/\\\" + SUBREDDIT + \\\"/random\\\").openConnection());\\n            con.setRequestProperty(\\\"user-agent\\\", Main.HTTP_USER_AGENT);\\n            con.setRequestMethod(\\\"GET\\\");\\n            con.setInstanceFollowRedirects(true);\\n            con.connect();\\n            int responseCode = con.getResponseCode();\\n            \\n            if(responseCode == 429) {\\n                Main.getBotListener().sendMessage(event, \\\"Error Response: 429, too many Requests!);\\n                return;\\n            }\\n            \\n            System.out.println(\\\"Response Code: \\\" + responseCode);\\n            \\n            link = con.getURL().toString();\\n            \\n            con.disconnect();\\n        } catch(IOException e) {\\n            e.printStackTrace();\\n        }\\n        \\n        final int COMMENTS_POS = link.indexOf(\\\"/comments/\\\") + \\\"/comments/\\\".length();\\n        \\n        String urlCode = link.substring(COMMENTS_POS, link.indexOf('/', COMMENTS_POS));\\n        String jsonLink = \\\"https://www.reddit.com/api/info.json?id=t3_\\\";\\n        \\n        if(urlCode != null) {\\n            System.out.println(\\\"REDDIT THREAD CODE: \\\" + urlCode);\\n            jsonLink += urlCode;\\n            \\n            try {\\n                HttpURLConnection con = (HttpURLConnection)(new URL(jsonLink).openConnection());\\n                con.setRequestProperty(\\\"user-agent\\\", Main.HTTP_USER_AGENT);\\n                con.setRequestMethod(\\\"GET\\\");\\n                con.setInstanceFollowRedirects(true);\\n                con.connect();\\n                int responseCode = con.getResponseCode();\\n                \\n                System.out.println(\\\"JSON LINK \\u003E Response Code: \\\" + responseCode);\\n                \\n                if(responseCode == 429) {\\n                    return;\\n                }\\n                \\n                try {\\n                    BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream(), \\\"UTF-8\\\"));\\n                    \\n                    String line;\\n                    while ((line = br.readLine()) != null) {\\n                        page.append(line + \\\"\\\\n\\\");\\n                    }\\n                    \\n                    br.close();\\n                } catch (MalformedURLException MUE) {\\n                    MUE.printStackTrace();\\n                } catch (IOException IOE) {\\n                    IOE.printStackTrace();\\n                }\\n               con.disconnect();\\n            } catch(IOException e) {\\n                e.printStackTrace();\\n            }\\n        }\\n        \\n        String jsonCode = page.toString();\\n        int startIndex = jsonCode.indexOf(\\\"t3_\\\" + urlCode);\\n        int urlIndex = jsonCode.indexOf(\\\"\\\\\\\"url\\\\\\\":\\\", startIndex) + (\\\"\\\\\\\"url\\\\\\\": \\\\\\\"\\\").length();\\n        int titleIndex = jsonCode.indexOf(\\\"\\\\\\\"title\\\\\\\":\\\") + (\\\"\\\\\\\"title\\\\\\\": \\\\\\\"\\\").length();\\n        referencedLink = jsonCode.substring(urlIndex, jsonCode.indexOf(\\\"\\\\\\\",\\\", urlIndex));\\n        title = \\\"_\\\" + jsonCode.substring(titleIndex, jsonCode.indexOf(\\\"\\\\\\\",\\\", titleIndex)) + \\\"_\\\";\\n        \\n        System.out.println(page.toString());\\n        \\n        System.out.println(title + \\\", \\\" + link + \\\", \\\" + referencedLink);//\\\\n\\u003C\\\" + link + \\\"\\u003E\\n        Main.getBotListener().sendMessage(event, MESSAGE + \\\"\\\\n**\\u003C\\\" + (referencedLink != null ? referencedLink : link) + \\\"\\u003E** - \\\" + title);\\n        \\n    }\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l6biw\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"VenomousInc\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 10, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464951648.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l6biw/simple_random_subreddit_grab/\", \"locked\": false, \"name\": \"t3_4l6biw\", \"created\": 1464310955.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l6biw/simple_random_subreddit_grab/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Simple Random Subreddit Grab\", \"created_utc\": 1464282155.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey guys! \\u003C/p\\u003E\\n\\n\\u003Cp\\u003ESo what started as a simple script to log into my account became a large and fun app that flies orange envelopes across your screen whenever you get a notification. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI made \\u003Ca href=\\\"https://www.youtube.com/watch?v=dJA7WzcGM9I\\\"\\u003Ea demo video\\u003C/a\\u003E for you guys to checkout which explains more and shows the installations process.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThis project took me a while because I wanted it to install and update seamlessly, and I also wanted it to be extendable. You configure it to check different things on reddit and you can instantly notify yourself when something happens. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECheckout that video and \\u003Ca href=\\\"https://github.com/FlyingOranger/FlyingOranger\\\"\\u003Ethe github\\u003C/a\\u003E if you want.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks guys! Let me know what you think.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey guys! \\n\\nSo what started as a simple script to log into my account became a large and fun app that flies orange envelopes across your screen whenever you get a notification. \\n\\nI made [a demo video](https://www.youtube.com/watch?v=dJA7WzcGM9I) for you guys to checkout which explains more and shows the installations process.\\n\\nThis project took me a while because I wanted it to install and update seamlessly, and I also wanted it to be extendable. You configure it to check different things on reddit and you can instantly notify yourself when something happens. \\n\\nCheckout that video and [the github](https://github.com/FlyingOranger/FlyingOranger) if you want.\\n\\nThanks guys! Let me know what you think.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l62l5\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"JarofHearts\", \"media\": null, \"score\": 11, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l62l5/i_just_finished_my_first_app_for_reddit_flying/\", \"locked\": false, \"name\": \"t3_4l62l5\", \"created\": 1464307875.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l62l5/i_just_finished_my_first_app_for_reddit_flying/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"I just finished my first app for reddit, Flying Oranger! I'd really appreciate any feedback.\", \"created_utc\": 1464279075.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 11}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI am looking for a way to filter my get results so that only links from youtube are returned, and I am failing to do this whilst setting a subreddit...\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Er = praw.Reddit(user_agent=\\u0026#39;MBM.\\u0026#39;)\\nfor post in r.get_subreddit(\\u0026quot;listentothis\\u0026quot;) \\\\\\n         .get_new(limit=5):\\nprint(str(post))\\nprint(str(post.url))\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003Eits pretty simple because its my first praw app, I was wondering if anyone could give me a nudge in the right direction! thanks in advance.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I am looking for a way to filter my get results so that only links from youtube are returned, and I am failing to do this whilst setting a subreddit...\\n\\n    r = praw.Reddit(user_agent='MBM.')\\n    for post in r.get_subreddit(\\\"listentothis\\\") \\\\\\n             .get_new(limit=5):\\n    print(str(post))\\n    print(str(post.url))\\n\\nits pretty simple because its my first praw app, I was wondering if anyone could give me a nudge in the right direction! thanks in advance.\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l5v2q\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Milkybarman\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l5v2q/filtering_posts_by_domain/\", \"locked\": false, \"name\": \"t3_4l5v2q\", \"created\": 1464305424.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l5v2q/filtering_posts_by_domain/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Filtering posts by domain\", \"created_utc\": 1464276624.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIf I go to \\u003Ca href=\\\"/r/nosleep/top\\\"\\u003E/r/nosleep/top\\u003C/a\\u003E.json the result is 1.4 MB due to all the duplicated long stories that are for some reason included in the json (selftext + html version). For comparison, the html is 100 KB. So downloading 1 MB every time I want to look at this subreddit is kinda annoying since I only got 100 MB of data.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EIs there a way not to download the content of the posts? Parsing the html wouldn\\u0026#39;t work since in most cases it\\u0026#39;s bigger than the json.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"If I go to /r/nosleep/top.json the result is 1.4 MB due to all the duplicated long stories that are for some reason included in the json (selftext + html version). For comparison, the html is 100 KB. So downloading 1 MB every time I want to look at this subreddit is kinda annoying since I only got 100 MB of data.\\n\\nIs there a way not to download the content of the posts? Parsing the html wouldn't work since in most cases it's bigger than the json.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l5pj8\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Zezombye\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l5pj8/how_to_get_the_posts_of_a_subreddit_without_the/\", \"locked\": false, \"name\": \"t3_4l5pj8\", \"created\": 1464303606.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l5pj8/how_to_get_the_posts_of_a_subreddit_without_the/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to get the posts of a subreddit without the selftext?\", \"created_utc\": 1464274806.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;ve dug through the Praw methods and all I can find are ways to get a number of comments... I don\\u0026#39;t care for the specific comments, I\\u0026#39;m just trying to return the URL that brings you to ALL the comments. Anyone know?\\nI\\u0026#39;ve got this so far:  \\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Esubmissions = r.get_subreddit(\\u0026#39;redditdev\\u0026#39;).get_hot(limit=1)\\nfor entry in submissions: \\n    print entry.url\\n    #also, I want to print the link to the comments\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I've dug through the Praw methods and all I can find are ways to get a number of comments... I don't care for the specific comments, I'm just trying to return the URL that brings you to ALL the comments. Anyone know?\\nI've got this so far:  \\n\\n    submissions = r.get_subreddit('redditdev').get_hot(limit=1)\\n    for entry in submissions: \\n        print entry.url\\n        #also, I want to print the link to the comments\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l3ffl\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"fooshydoo\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464233196.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l3ffl/using_praw_how_to_returnget_the_url_to_the/\", \"locked\": false, \"name\": \"t3_4l3ffl\", \"created\": 1464261784.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l3ffl/using_praw_how_to_returnget_the_url_to_the/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Using PRAW how to return/get the URL to the comments of a post?\", \"created_utc\": 1464232984.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHi guys,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI set up the language for my site is something other than English in development.update, I do a \\u0026quot;make ini\\u0026quot; and restart reddit, but the site\\u0026#39;s language is still English. Is there anything else that I should do? Any hint will be very appreciated!\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks,\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hi guys,\\n\\nI set up the language for my site is something other than English in development.update, I do a \\\"make ini\\\" and restart reddit, but the site's language is still English. Is there anything else that I should do? Any hint will be very appreciated!\\n\\nThanks,\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l26y3\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ho4ngt\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l26y3/site_lang_setup_doesnt_work/\", \"locked\": false, \"name\": \"t3_4l26y3\", \"created\": 1464243457.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l26y3/site_lang_setup_doesnt_work/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"site_lang setup doesn't work\", \"created_utc\": 1464214657.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ELet\\u0026#39;s say I have an object of a comment and I want to retrieve the object of the thread in which this particular comment was posted. How do I do that?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Let's say I have an object of a comment and I want to retrieve the object of the thread in which this particular comment was posted. How do I do that?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l1b6t\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"asourceforyou\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l1b6t/how_can_i_retrieve_the_submission_object_from_a/\", \"locked\": false, \"name\": \"t3_4l1b6t\", \"created\": 1464232159.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l1b6t/how_can_i_retrieve_the_submission_object_from_a/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How can I retrieve the submission object from a comment object?\", \"created_utc\": 1464203359.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EHow can we change the name of subreddits in to our custom ?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFor example to create a subreddits at myredditclone.com/mycustom/create ?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello,\\n\\nHow can we change the name of subreddits in to our custom ?\\n\\nFor example to create a subreddits at myredditclone.com/mycustom/create ?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l183j\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hhaevs\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l183j/change_subreddits/\", \"locked\": false, \"name\": \"t3_4l183j\", \"created\": 1464231116.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l183j/change_subreddits/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Change subreddits ?\", \"created_utc\": 1464202316.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI\\u0026#39;m making a bot that submits images. As of now, I upload to imgur and then submit the link, but I\\u0026#39;d like to start using the reddit in house image hosting. How do I do this using praw? I don\\u0026#39;t think I saw anything in the documentation\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I'm making a bot that submits images. As of now, I upload to imgur and then submit the link, but I'd like to start using the reddit in house image hosting. How do I do this using praw? I don't think I saw anything in the documentation\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l17dd\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"GoddammitJosh\", \"media\": null, \"score\": 9, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l17dd/is_there_a_reddit_image_upload_api_for_using_the/\", \"locked\": false, \"name\": \"t3_4l17dd\", \"created\": 1464230854.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l17dd/is_there_a_reddit_image_upload_api_for_using_the/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there a reddit image upload API? (for using the i.reddituploads links)\", \"created_utc\": 1464202054.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 9}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESay I want to view \\u003Ca href=\\\"https://www.reddit.com/user/krispykrackers/\\\"\\u003Ekrispykrackers\\u0026#39;\\u003C/a\\u003E moderated subreddits. On the website I just go to the profile and they\\u0026#39;re listed on the right.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI can\\u0026#39;t find an API to access this information, however. Is it just missing?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Say I want to view [krispykrackers'](https://www.reddit.com/user/krispykrackers/) moderated subreddits. On the website I just go to the profile and they're listed on the right.\\n\\nI can't find an API to access this information, however. Is it just missing?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4l10iy\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"iamthatis\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4l10iy/is_there_an_api_to_get_the_list_of_subreddits_a/\", \"locked\": false, \"name\": \"t3_4l10iy\", \"created\": 1464228563.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4l10iy/is_there_an_api_to_get_the_list_of_subreddits_a/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Is there an API to get the list of subreddits a particular user moderates?\", \"created_utc\": 1464199763.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI use a Java app (inside Eclipse for now) to fetch the title, subreddit, author etc of each post of \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFor that I connect to \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E.json and parse the json. However it almost always returns me a 429 error (too many requests), even after 10 minutes spent waiting.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhy does it do that behavior? I am far under the 30 requests/minute.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I use a Java app (inside Eclipse for now) to fetch the title, subreddit, author etc of each post of /r/all.\\n\\nFor that I connect to /r/all.json and parse the json. However it almost always returns me a 429 error (too many requests), even after 10 minutes spent waiting.\\n\\nWhy does it do that behavior? I am far under the 30 requests/minute.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kz0oq\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Zezombye\", \"media\": null, \"score\": 5, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kz0oq/too_many_requests_almost_every_time/\", \"locked\": false, \"name\": \"t3_4kz0oq\", \"created\": 1464201627.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kz0oq/too_many_requests_almost_every_time/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"\\\"Too many requests\\\" almost every time\", \"created_utc\": 1464172827.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 5}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003Eis there a way to search reddit or subreddit for least number of votes or least attention and activity. preferably with preference to post that are quickly approaching infinite silence of archive lock. and an optional very rudimentary catchall spam filter would be perfect. something simple is better than nothing at all.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"is there a way to search reddit or subreddit for least number of votes or least attention and activity. preferably with preference to post that are quickly approaching infinite silence of archive lock. and an optional very rudimentary catchall spam filter would be perfect. something simple is better than nothing at all.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kxlrc\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"mobilizes\", \"media\": null, \"score\": 4, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kxlrc/sort_by_least_votes/\", \"locked\": false, \"name\": \"t3_4kxlrc\", \"created\": 1464173758.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kxlrc/sort_by_least_votes/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Sort by least votes\", \"created_utc\": 1464144958.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 4}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003E\\u003Cstrong\\u003ESOLVED\\u003C/strong\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Ca href=\\\"https://github.com/trevorsenior/snoocore/blob/master/src/RedditRequest.js#L360\\\"\\u003ESnoocore splits stickied posts from normal posts.\\u003C/a\\u003E I didn\\u0026#39;t know this.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThank-you all for your time.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cdel\\u003EGood day,\\u003C/del\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cdel\\u003EI run a small data analysis project in my free time collecting data from \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E. I scrape \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E multiple times an hour (well with-in the rate limit) and store the raw JSONs for later processing.\\u003C/del\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cdel\\u003EHowever I\\u2019ve been noticing a pattern recently where some posts from certain subreddits (mainly \\u003Ca href=\\\"/r/The_Donald\\\"\\u003E/r/The_Donald\\u003C/a\\u003E, but it could be other subs too) have been showing up on my personal Reddit \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E, but not in my scrapes. All the other posts show in the scrapes.\\u003C/del\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cdel\\u003EFor reference, I clearly recall seeing \\u003Ca href=\\\"https://www.reddit.com/r/The_Donald/comments/4kk3n1/donald_j_trump_on_twitter_how_can_crooked_hillary/\\\"\\u003Ethis post regarding one of Donald Trump\\u2019s tweets\\u003C/a\\u003E on \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E, but after \\u003Ccode\\u003Egrep\\u003C/code\\u003Eing through my \\u003Ca href=\\\"/r/all\\\"\\u003E/r/all\\u003C/a\\u003E listing JSONs for the post ID, it is no-where to be found.\\u003C/del\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cdel\\u003EHas anyone else experienced this?\\u003C/del\\u003E\\u003C/p\\u003E\\n\\n\\u003Cp\\u003E\\u003Cdel\\u003ERegards.\\u003C/del\\u003E\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"**SOLVED**\\n\\n[Snoocore splits stickied posts from normal posts.](https://github.com/trevorsenior/snoocore/blob/master/src/RedditRequest.js#L360) I didn't know this.\\n\\nThank-you all for your time.\\n\\n~~Good day,~~\\n\\n~~I run a small data analysis project in my free time collecting data from /r/all. I scrape /r/all multiple times an hour (well with-in the rate limit) and store the raw JSONs for later processing.~~\\n\\n~~However I\\u2019ve been noticing a pattern recently where some posts from certain subreddits (mainly /r/The_Donald, but it could be other subs too) have been showing up on my personal Reddit /r/all, but not in my scrapes. All the other posts show in the scrapes.~~\\n\\n~~For reference, I clearly recall seeing [this post regarding one of Donald Trump\\u2019s tweets](https://www.reddit.com/r/The_Donald/comments/4kk3n1/donald_j_trump_on_twitter_how_can_crooked_hillary/) on /r/all, but after `grep`ing through my /r/all listing JSONs for the post ID, it is no-where to be found.~~\\n\\n~~Has anyone else experienced this?~~\\n\\n~~Regards.~~\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kmyju\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"ZwPLYLWMOX97YO\", \"media\": null, \"score\": 9, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1464007129.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kmyju/some_posts_being_omitted_from_rall_listings/\", \"locked\": false, \"name\": \"t3_4kmyju\", \"created\": 1464019993.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kmyju/some_posts_being_omitted_from_rall_listings/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Some posts being omitted from /r/all listings?\", \"created_utc\": 1463991193.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 9}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello, I\\u0026#39;m having trouble making the left sidebar (listing-chooser) that appears in \\u003Ca href=\\\"/r/all\\\"\\u003Er/all\\u003C/a\\u003E for logged-in users also appear for non logged-in users. I tried messing around in pages.py (/reddit/r2/r2/lib/pages) but could only figure out how to make list elements in ul.multi (left sidebar) appear and disappear.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello, I'm having trouble making the left sidebar (listing-chooser) that appears in r/all for logged-in users also appear for non logged-in users. I tried messing around in pages.py (/reddit/r2/r2/lib/pages) but could only figure out how to make list elements in ul.multi (left sidebar) appear and disappear.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kl8wn\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Thalinan\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 8, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kl8wn/how_do_i_make_divlistingchooserinitialized_appear/\", \"locked\": false, \"name\": \"t3_4kl8wn\", \"created\": 1463990622.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kl8wn/how_do_i_make_divlistingchooserinitialized_appear/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How do I make div.listing-chooser.initialized appear for non-logged in users?\", \"created_utc\": 1463961822.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EAccording to \\u003Ca href=\\\"http://praw.readthedocs.io/en/latest/pages/code_overview.html#praw.objects.Submission.replace_more_comments\\\"\\u003Edocumentation\\u003C/a\\u003E:  \\u003C/p\\u003E\\n\\n\\u003Cblockquote\\u003E\\n\\u003Cp\\u003Eafter making this call, the comments attribute of the submission will no longer contain any MoreComments objects. Items that weren\\u2019t replaced are still removed from the tree, and will be included in the returned list.\\u003C/p\\u003E\\n\\u003C/blockquote\\u003E\\n\\n\\u003Cp\\u003EHow do I work around that? What do I need to do with the returned list to retrieve more comments? How do I put them back into the tree?\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EMy intention is to download an entire thread from Reddit, preferably as a tree, so I can later generate an HTML for offline reading.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EP.S. using \\u003Ca href=\\\"http://praw.readthedocs.io/en/latest/pages/comment_parsing.html\\\"\\u003Ethis\\u003C/a\\u003E as the starting point\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"According to [documentation](http://praw.readthedocs.io/en/latest/pages/code_overview.html#praw.objects.Submission.replace_more_comments):  \\n\\u003E after making this call, the comments attribute of the submission will no longer contain any MoreComments objects. Items that weren\\u2019t replaced are still removed from the tree, and will be included in the returned list.\\n\\nHow do I work around that? What do I need to do with the returned list to retrieve more comments? How do I put them back into the tree?\\n\\nMy intention is to download an entire thread from Reddit, preferably as a tree, so I can later generate an HTML for offline reading.\\n\\nP.S. using [this](http://praw.readthedocs.io/en/latest/pages/comment_parsing.html) as the starting point\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kl60z\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Zireael_N\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 4, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kl60z/praw_multiple_calls_of_replace_more_comments/\", \"locked\": false, \"name\": \"t3_4kl60z\", \"created\": 1463989426.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kl60z/praw_multiple_calls_of_replace_more_comments/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Multiple calls of replace_more_comments()?\", \"created_utc\": 1463960626.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EFixed: was just human error\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Fixed: was just human error\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kkjlq\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Shubbler\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 6, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1463962579.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kkjlq/praw_random_http_error/\", \"locked\": false, \"name\": \"t3_4kkjlq\", \"created\": 1463980558.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kkjlq/praw_random_http_error/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Random HTTP Error\", \"created_utc\": 1463951758.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cblockquote\\u003E\\n\\u003Cp\\u003EWaiting for cassandra to be available...\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Enc -vz localhost 9160\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Enc: connect to localhost port 9160 (tcp) failed: Connection refused\\u003C/p\\u003E\\n\\n\\u003Cp\\u003Esleep 1\\u003C/p\\u003E\\n\\u003C/blockquote\\u003E\\n\\n\\u003Cp\\u003EAny ideas on how to fix this? Using the automated install script. \\u0026quot;lsof -i :9160\\u0026quot; returns nothing.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"\\u003EWaiting for cassandra to be available...\\n\\n\\u003Enc -vz localhost 9160\\n\\n\\u003Enc: connect to localhost port 9160 (tcp) failed: Connection refused\\n\\n\\u003Esleep 1\\n\\n\\nAny ideas on how to fix this? Using the automated install script. \\\"lsof -i :9160\\\" returns nothing.\\n\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kk6da\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"MiseroMCS\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 1, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kk6da/waiting_for_cassandra_to_be_avaliable_fails/\", \"locked\": false, \"name\": \"t3_4kk6da\", \"created\": 1463975728.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kk6da/waiting_for_cassandra_to_be_avaliable_fails/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"\\\"Waiting for cassandra to be avaliable...\\\" fails.\", \"created_utc\": 1463946928.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EI know there is the json about which has the over 18 field, but I can\\u0026#39;t find its location strictly using the Praw wrapper. I can get the link to it, but I then have to go outside Praw and make a http request to retrieve the Json object. Am I just overlooking how to get the over 18 field for a sub, within Praw?  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EEdit: Don\\u0026#39;t know why this got marked NSFW\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"I know there is the json about which has the over 18 field, but I can't find its location strictly using the Praw wrapper. I can get the link to it, but I then have to go outside Praw and make a http request to retrieve the Json object. Am I just overlooking how to get the over 18 field for a sub, within Praw?  \\n\\nEdit: Don't know why this got marked NSFW\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kgyd8\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"HelioOne\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": 1463888193.0, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kgyd8/praw_determine_is_a_sub_is_nsfw/\", \"locked\": false, \"name\": \"t3_4kgyd8\", \"created\": 1463916753.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kgyd8/praw_determine_is_a_sub_is_nsfw/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"[PRAW] Determine is a Sub is NSFW\", \"created_utc\": 1463887953.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHey there,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EWhen creating a new subreddit, there are several (unlisted) limitations on the subreddit name (special characters, min length, max length).  The error that comes back with an invalid name is \\u0026quot;that name isn\\u0026#39;t going to work\\u0026quot; - which makes it a bit difficult to figure out WHY the name is invalid.  So I\\u0026#39;m looking at adding more accurate responses to the error \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/lib/validator/validator.py#L692\\\"\\u003Ein the VSubredditName class\\u003C/a\\u003E.  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EA set of more accurate error reasons exist for naming multi-reddits, \\u003Ca href=\\\"https://github.com/reddit/reddit/blob/master/r2/r2/lib/validator/validator.py#L3076\\\"\\u003Efound here\\u003C/a\\u003E and listed below.  So it shouldn\\u0026#39;t be too hard to drop similar logic into where the subreddit name has come back as invalid (and the text already exists for translations).\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E        invalid_char = multi_name_chars_rx.search(name)\\n        if invalid_char:\\n            char = invalid_char.group()\\n            if char == \\u0026#39; \\u0026#39;:\\n                reason = _(\\u0026#39;no spaces allowed\\u0026#39;)\\n            else:\\n                reason = _(\\u0026quot;invalid character: \\u0026#39;%s\\u0026#39;\\u0026quot;) % char\\n        elif name[0] == \\u0026#39;_\\u0026#39;:\\n            reason = _(\\u0026quot;can\\u0026#39;t start with a \\u0026#39;_\\u0026#39;\\u0026quot;)\\n        elif len(name) \\u0026lt; 2:\\n            reason = _(\\u0026#39;that name is too short\\u0026#39;)\\n        elif len(name) \\u0026gt; 21:\\n            reason = _(\\u0026#39;that name is too long\\u0026#39;)\\n        else:\\n            reason = _(\\u0026quot;that name isn\\u0026#39;t going to work\\u0026quot;)\\n\\n        self.set_error(\\u0026#39;BAD_MULTI_NAME\\u0026#39;, {\\u0026#39;reason\\u0026#39;: reason}, code=400)\\n        return\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThe thing that I\\u0026#39;m not sure about is the error statement.  The current error is \\u0026#39;BAD_SR_NAME\\u0026#39; and is the generic \\u0026quot;that name isn\\u0026#39;t going to work\\u0026quot; message.  Looking at the multi-reddit error \\u0026#39;BAD_MULTI_NAME\\u0026#39;, it passes a reason as well and that is the error message.  I\\u0026#39;m not sure the workflow for the errors though.  Should I create a new error (and is that as simple as adding a new entry to the error_list in errors.py?) like \\u0026#39;BAD_SR_NAME_REASON\\u0026#39; and have the message be \\u0026quot;%(reason)s\\u0026quot; ?  Would it be better to edit the \\u0026#39;BAD_SR_NAME\\u0026#39; to use a reason string (might require several edits to wherever that error is used)?  I\\u0026#39;m assuming that using the existing \\u0026#39;BAD_MULTI_NAME\\u0026#39; error for a subreddit name would be a bad idea for code tracability.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EAny advice on whats the \\u003Cem\\u003Eright way\\u003C/em\\u003E to add a reason to this error?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hey there,\\n\\nWhen creating a new subreddit, there are several (unlisted) limitations on the subreddit name (special characters, min length, max length).  The error that comes back with an invalid name is \\\"that name isn't going to work\\\" - which makes it a bit difficult to figure out WHY the name is invalid.  So I'm looking at adding more accurate responses to the error [in the VSubredditName class](https://github.com/reddit/reddit/blob/master/r2/r2/lib/validator/validator.py#L692).  \\n\\n\\nA set of more accurate error reasons exist for naming multi-reddits, [found here](https://github.com/reddit/reddit/blob/master/r2/r2/lib/validator/validator.py#L3076) and listed below.  So it shouldn't be too hard to drop similar logic into where the subreddit name has come back as invalid (and the text already exists for translations).\\n\\n            invalid_char = multi_name_chars_rx.search(name)\\n            if invalid_char:\\n                char = invalid_char.group()\\n                if char == ' ':\\n                    reason = _('no spaces allowed')\\n                else:\\n                    reason = _(\\\"invalid character: '%s'\\\") % char\\n            elif name[0] == '_':\\n                reason = _(\\\"can't start with a '_'\\\")\\n            elif len(name) \\u003C 2:\\n                reason = _('that name is too short')\\n            elif len(name) \\u003E 21:\\n                reason = _('that name is too long')\\n            else:\\n                reason = _(\\\"that name isn't going to work\\\")\\n\\n            self.set_error('BAD_MULTI_NAME', {'reason': reason}, code=400)\\n            return\\n\\n\\nThe thing that I'm not sure about is the error statement.  The current error is 'BAD_SR_NAME' and is the generic \\\"that name isn't going to work\\\" message.  Looking at the multi-reddit error 'BAD_MULTI_NAME', it passes a reason as well and that is the error message.  I'm not sure the workflow for the errors though.  Should I create a new error (and is that as simple as adding a new entry to the error_list in errors.py?) like 'BAD_SR_NAME_REASON' and have the message be \\\"%(reason)s\\\" ?  Would it be better to edit the 'BAD_SR_NAME' to use a reason string (might require several edits to wherever that error is used)?  I'm assuming that using the existing 'BAD_MULTI_NAME' error for a subreddit name would be a bad idea for code tracability.\\n\\nAny advice on whats the *right way* to add a reason to this error?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kehr1\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"skullkid2424\", \"media\": null, \"score\": 6, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 3, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kehr1/looking_to_add_better_error_responses_for_invalid/\", \"locked\": false, \"name\": \"t3_4kehr1\", \"created\": 1463880029.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kehr1/looking_to_add_better_error_responses_for_invalid/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Looking to add better error responses for invalid subreddit names\", \"created_utc\": 1463851229.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 6}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EHello,\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ECan someone provide a guide about how to handle Gold Extension like how to edit Gold frontpage, how to setup payment method.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThanks.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Hello,\\n\\nCan someone provide a guide about how to handle Gold Extension like how to edit Gold frontpage, how to setup payment method.\\n\\nThanks.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4ke0kh\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"hhaevs\", \"media\": null, \"score\": 1, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4ke0kh/how_to_handle_gold_extension/\", \"locked\": false, \"name\": \"t3_4ke0kh\", \"created\": 1463873296.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4ke0kh/how_to_handle_gold_extension/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How to handle Gold Extension.\", \"created_utc\": 1463844496.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 1}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003ESo apparently \\u003Ca href=\\\"https://github.com/reddit/reddit/wiki/API-Wrappers\\\"\\u003ERedditSharp supports OAuth2\\u003C/a\\u003E, but Redditsharp\\u0026#39;s readme says to login with username and password.  \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI\\u0026#39;ve tried that, but reddit stops working after a few calls (even if I try reinitializing it)\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E        reddit = new Reddit();\\n        user = reddit.LogIn(\\u0026quot;botthelawyer\\u0026quot;, \\u0026quot;password\\u0026quot;);\\n        subreddit = reddit.GetSubreddit(\\u0026quot;/r/bobthelawyer\\u0026quot;);\\n        wiki = subreddit.Wiki;\\n        wiki.EditPage(\\u0026quot;index\\u0026quot;, \\u0026quot;A\\u0026quot;);\\n        wiki.EditPage(\\u0026quot;index\\u0026quot;, \\u0026quot;B\\u0026quot;);\\n        wiki.EditPage(\\u0026quot;index\\u0026quot;, \\u0026quot;C\\u0026quot;);\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EThe code freezes and breaks when EditPage tries to change index to \\u0026quot;C\\u0026quot;.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI have followed other tutorials so I have my app secret, uri, account code, and refresh token.\\u003Cbr/\\u003E\\nNot sure where to use them, though.  Seems like I can use it in AuthProvider, but I can\\u0026#39;t figure out where that relates to the rest of the code.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EI can\\u0026#39;t find any tutorials for Redditsharp.  Anyone have any code samples for getting this working or know what I need to change?\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"So apparently [RedditSharp supports OAuth2](https://github.com/reddit/reddit/wiki/API-Wrappers), but Redditsharp's readme says to login with username and password.  \\n\\nI've tried that, but reddit stops working after a few calls (even if I try reinitializing it)\\n\\n            reddit = new Reddit();\\n            user = reddit.LogIn(\\\"botthelawyer\\\", \\\"password\\\");\\n            subreddit = reddit.GetSubreddit(\\\"/r/bobthelawyer\\\");\\n            wiki = subreddit.Wiki;\\n            wiki.EditPage(\\\"index\\\", \\\"A\\\");\\n            wiki.EditPage(\\\"index\\\", \\\"B\\\");\\n            wiki.EditPage(\\\"index\\\", \\\"C\\\");\\n\\nThe code freezes and breaks when EditPage tries to change index to \\\"C\\\".\\n\\nI have followed other tutorials so I have my app secret, uri, account code, and refresh token.     \\nNot sure where to use them, though.  Seems like I can use it in AuthProvider, but I can't figure out where that relates to the rest of the code.\\n\\nI can't find any tutorials for Redditsharp.  Anyone have any code samples for getting this working or know what I need to change?\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4kbx6s\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"BobTheLawyer\", \"media\": null, \"score\": 3, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4kbx6s/how_do_i_get_redditsharp_to_work/\", \"locked\": false, \"name\": \"t3_4kbx6s\", \"created\": 1463830163.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4kbx6s/how_do_i_get_redditsharp_to_work/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"How do I get Redditsharp to work?\", \"created_utc\": 1463801363.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 3}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EIn the past I made a score monitoring script to see how the score of my comments changed over time. What I noticed is that the scores wildly fluctuate between some specific values in a very weird way. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EFor example, a comment would show as +1 for the first 5-10 minutes, then show as +3, stay there for hours, then go to -1, stay like that for hours again before changing back to +3 again. At first I thought it was random fluctuations because of normal reddit use, just people voting. But encountering the same values for the same comments made me question that. After a while I started to think that it\\u0026#39;s because of some caching issue and later on I had the idea that it might have to do with reddit automatically detecting brigading attempts and removing their votes after the fact.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EYou can notice similar fluctuations if you visit your comments on the normal reddit webpages too, so I know this isn\\u0026#39;t something that only happens with the API. It\\u0026#39;s especially noticeable when you switch between your profile and the thread a comment is in, in that case you can see the comment having a different score in each. \\u003C/p\\u003E\\n\\n\\u003Cp\\u003EDoes anyone know what these fluctuations are about exactly? I want to create a script for automatic brigade detection but it\\u0026#39;s impossible without having a thorough understanding of all the possible things that can make a score fluctuate other than normal user votes. \\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"In the past I made a score monitoring script to see how the score of my comments changed over time. What I noticed is that the scores wildly fluctuate between some specific values in a very weird way. \\n\\nFor example, a comment would show as +1 for the first 5-10 minutes, then show as +3, stay there for hours, then go to -1, stay like that for hours again before changing back to +3 again. At first I thought it was random fluctuations because of normal reddit use, just people voting. But encountering the same values for the same comments made me question that. After a while I started to think that it's because of some caching issue and later on I had the idea that it might have to do with reddit automatically detecting brigading attempts and removing their votes after the fact.\\n\\nYou can notice similar fluctuations if you visit your comments on the normal reddit webpages too, so I know this isn't something that only happens with the API. It's especially noticeable when you switch between your profile and the thread a comment is in, in that case you can see the comment having a different score in each. \\n\\nDoes anyone know what these fluctuations are about exactly? I want to create a script for automatic brigade detection but it's impossible without having a thorough understanding of all the possible things that can make a score fluctuate other than normal user votes. \", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4k9mzq\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"Naurgul\", \"media\": null, \"score\": 2, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 2, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4k9mzq/suspicious_score_fluctuations/\", \"locked\": false, \"name\": \"t3_4k9mzq\", \"created\": 1463797594.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4k9mzq/suspicious_score_fluctuations/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"Suspicious score fluctuations\", \"created_utc\": 1463768794.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 2}}, {\"kind\": \"t3\", \"data\": {\"domain\": \"self.redditdev\", \"banned_by\": null, \"media_embed\": {}, \"subreddit\": \"redditdev\", \"selftext_html\": \"\\u003C!-- SC_OFF --\\u003E\\u003Cdiv class=\\\"md\\\"\\u003E\\u003Cp\\u003EReddit can produce a lot of log output, especially when something goes wrong.  Here\\u0026#39;s how to reroute reddit log output to their own logs.  Create \\u003Ccode\\u003E/etc/rsyslog.d/20-reddit.conf\\u003C/code\\u003E and populate with the following content:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003E# Send reddit messages to dedicated logfiles\\n:syslogtag, contains, \\u0026quot;sutro.source\\u0026quot; /var/log/reddit/sutro.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;reddit\\u0026quot; /var/log/reddit/reddit.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;automoderator_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;butler_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;commentstree_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;del_account_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;event_collector_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;log_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;markread_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;modmail_email_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;newcomments_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;scraper_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;search_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;vote_comment_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;vote_fastlane_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n:syslogtag, contains, \\u0026quot;vote_link_q\\u0026quot; /var/log/reddit/queue-runners.log\\n\\u0026amp;~\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003ENB: I\\u0026#39;m not using HAProxy so if that generates its own log messages (I\\u0026#39;m guessing it doesn\\u0026#39;t), they\\u0026#39;ll still end up wherever the currently go.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003EThen, as root, execute:\\u003C/p\\u003E\\n\\n\\u003Cpre\\u003E\\u003Ccode\\u003Emkdir /var/log/reddit\\nchown syslog.adm /var/log/reddit\\nchmod 775 /var/log/reddit\\nservice rsyslog restart\\n\\u003C/code\\u003E\\u003C/pre\\u003E\\n\\n\\u003Cp\\u003EYou probably should consider creating a suitable entry in \\u003Ccode\\u003E/etc/logrotate.d\\u003C/code\\u003E.  I haven\\u0026#39;t done this yet, and will update the post when I have.\\u003C/p\\u003E\\n\\n\\u003Cp\\u003ELogs should now appear in \\u003Ccode\\u003E/var/log/syslog\\u003C/code\\u003E.  This may be helpful, especially when you\\u0026#39;re getting weird errors from reddit.\\u003C/p\\u003E\\n\\u003C/div\\u003E\\u003C!-- SC_ON --\\u003E\", \"selftext\": \"Reddit can produce a lot of log output, especially when something goes wrong.  Here's how to reroute reddit log output to their own logs.  Create `/etc/rsyslog.d/20-reddit.conf` and populate with the following content:\\n\\n    # Send reddit messages to dedicated logfiles\\n    :syslogtag, contains, \\\"sutro.source\\\" /var/log/reddit/sutro.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"reddit\\\" /var/log/reddit/reddit.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"automoderator_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"butler_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"commentstree_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"del_account_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"event_collector_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"log_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"markread_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"modmail_email_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"newcomments_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"scraper_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"search_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"vote_comment_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"vote_fastlane_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n    :syslogtag, contains, \\\"vote_link_q\\\" /var/log/reddit/queue-runners.log\\n    \\u0026~\\n\\nNB: I'm not using HAProxy so if that generates its own log messages (I'm guessing it doesn't), they'll still end up wherever the currently go.\\n\\nThen, as root, execute:\\n\\n    mkdir /var/log/reddit\\n    chown syslog.adm /var/log/reddit\\n    chmod 775 /var/log/reddit\\n    service rsyslog restart\\n\\nYou probably should consider creating a suitable entry in `/etc/logrotate.d`.  I haven't done this yet, and will update the post when I have.\\n\\nLogs should now appear in `/var/log/syslog`.  This may be helpful, especially when you're getting weird errors from reddit.\", \"likes\": null, \"suggested_sort\": null, \"user_reports\": [], \"secure_media\": null, \"link_flair_text\": null, \"id\": \"4k2lhm\", \"from_kind\": null, \"gilded\": 0, \"archived\": false, \"clicked\": false, \"report_reasons\": null, \"author\": \"StrixTechnica\", \"media\": null, \"score\": 9, \"approved_by\": null, \"over_18\": false, \"hidden\": false, \"num_comments\": 0, \"thumbnail\": \"\", \"subreddit_id\": \"t5_2qizd\", \"hide_score\": false, \"edited\": false, \"link_flair_css_class\": null, \"author_flair_css_class\": null, \"downs\": 0, \"secure_media_embed\": {}, \"saved\": false, \"removal_reason\": null, \"stickied\": false, \"from\": null, \"is_self\": true, \"from_id\": null, \"permalink\": \"/r/redditdev/comments/4k2lhm/howto_separate_reddit_logging_from_varlogsyslog/\", \"locked\": false, \"name\": \"t3_4k2lhm\", \"created\": 1463695413.0, \"url\": \"https://www.reddit.com/r/redditdev/comments/4k2lhm/howto_separate_reddit_logging_from_varlogsyslog/\", \"author_flair_text\": null, \"quarantine\": false, \"title\": \"HOWTO: Separate reddit logging from /var/log/syslog\", \"created_utc\": 1463666613.0, \"distinguished\": null, \"mod_reports\": [], \"visited\": false, \"num_reports\": null, \"ups\": 9}}], \"after\": \"t3_4k2lhm\", \"before\": null}}"
        },
        "headers": {
          "CF-RAY": "2b59b988e1ff227c-LAX",
          "Connection": "keep-alive",
          "Content-Type": "application/json; charset=UTF-8",
          "Date": "Sun, 19 Jun 2016 20:27:59 GMT",
          "Server": "cloudflare-nginx",
          "Strict-Transport-Security": "max-age=15552000; includeSubDomains; preload",
          "Transfer-Encoding": "chunked",
          "Vary": "accept-encoding",
          "X-Moose": "majestic",
          "cache-control": "private, s-maxage=0, max-age=0, must-revalidate",
          "expires": "-1",
          "x-content-type-options": "nosniff",
          "x-frame-options": "SAMEORIGIN",
          "x-ratelimit-remaining": "587.0",
          "x-ratelimit-reset": "122",
          "x-ratelimit-used": "13",
          "x-reddit-tracking": "https://pixel.redditmedia.com/pixel/of_destiny.png?v=zigEojDZRPpvypBF9p84ZZh5jT7r%2FSqGUOnYrAq2a5%2FSLeNom9Zq89I9WMRxyJs448NxXfxKerwJtkxxSi9xu7dlFicLevV2",
          "x-ua-compatible": "IE=edge",
          "x-xss-protection": "1; mode=block"
        },
        "status": {
          "code": 200,
          "message": "OK"
        },
        "url": "https://oauth.reddit.com/r/redditdev/new?limit=1024&raw_json=1"
      }
    }
  ],
  "recorded_with": "betamax/0.5.1"
}